<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>blog</title>
  
  
  <link href="https://0914ds.github.io/atom.xml" rel="self"/>
  
  <link href="https://0914ds.github.io/"/>
  <updated>2023-06-22T07:12:23.552Z</updated>
  <id>https://0914ds.github.io/</id>
  
  <author>
    <name>albert dong</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mysql的锁机制</title>
    <link href="https://0914ds.github.io/2025/01/07/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6/"/>
    <id>https://0914ds.github.io/2025/01/07/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6/</id>
    <published>2025-01-07T00:02:32.967Z</published>
    <updated>2023-06-22T07:12:23.552Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>mysql的锁机制</h1><h3 id="1、MySQL锁的基本介绍">1、MySQL锁的基本介绍</h3><p>​        **锁是计算机协调多个进程或线程并发访问某一资源的机制。**在数据库中，除传统的 计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一 个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。</p><p>​        相对其他数据库而言，MySQL的锁机制比较简单，其最 显著的特点是不同的<strong>存储引擎</strong>支持不同的锁机制。比如，MyISAM和MEMORY存储引擎采用的是表级锁（table-level locking）；InnoDB存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。</p><p>​        **表级锁：**开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。<br>​        **行级锁：**开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p><p>​        从上述特点可见，很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适！仅从锁的角度 来说：表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有 并发查询的应用，如一些在线事务处理（OLTP）系统。</p><h3 id="2、MyISAM表锁">2、MyISAM表锁</h3><p>MySQL的表级锁有两种模式：<strong>表共享读锁（Table Read Lock）<strong>和</strong>表独占写锁（Table Write Lock）</strong>。</p><p>对MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；对 MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作；MyISAM表的读操作与写操作之间，以及写操作之间是串行的！</p><p>建表语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `mylock` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `NAME` <span class="type">varchar</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>MyISAM <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `mylock` (`id`, `NAME`) <span class="keyword">VALUES</span> (<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;a&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `mylock` (`id`, `NAME`) <span class="keyword">VALUES</span> (<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `mylock` (`id`, `NAME`) <span class="keyword">VALUES</span> (<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;c&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `mylock` (`id`, `NAME`) <span class="keyword">VALUES</span> (<span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;d&#x27;</span>);</span><br></pre></td></tr></table></figure><p><strong>MyISAM写锁阻塞读的案例：</strong></p><p>​        当一个线程获得对一个表的写锁之后，只有持有锁的线程可以对表进行更新操作。其他线程的读写操作都会等待，直到锁释放为止。</p><table><thead><tr><th style="text-align:center">session1</th><th style="text-align:center">session2</th></tr></thead><tbody><tr><td style="text-align:center">获取表的write锁定<br>lock table mylock write;</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">当前session对表的查询，插入，更新操作都可以执行<br>select * from mylock;<br>insert into mylock values(5,‘e’);</td><td style="text-align:center">当前session对表的查询会被阻塞<br>select * from mylock；</td></tr><tr><td style="text-align:center">释放锁：<br>unlock tables；</td><td style="text-align:center">当前session能够立刻执行，并返回对应结果</td></tr></tbody></table><p><strong>MyISAM读阻塞写的案例：</strong></p><p>​        一个session使用lock table给表加读锁，这个session可以锁定表中的记录，但更新和访问其他表都会提示错误，同时，另一个session可以查询表中的记录，但更新就会出现锁等待。</p><table><thead><tr><th style="text-align:center">session1</th><th style="text-align:center">session2</th></tr></thead><tbody><tr><td style="text-align:center">获得表的read锁定<br>lock table mylock read;</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">当前session可以查询该表记录：<br>select * from mylock;</td><td style="text-align:center">当前session可以查询该表记录：<br>select * from mylock;</td></tr><tr><td style="text-align:center">当前session不能查询没有锁定的表<br>select * from person<br>Table ‘person’ was not locked with LOCK TABLES</td><td style="text-align:center">当前session可以查询或者更新未锁定的表<br>select * from mylock<br>insert into person values(1,‘zhangsan’);</td></tr><tr><td style="text-align:center">当前session插入或者更新表会提示错误<br>insert into mylock values(6,‘f’)<br>Table ‘mylock’ was locked with a READ lock and can’t be updated<br>update mylock set name=‘aa’ where id = 1;<br>Table ‘mylock’ was locked with a READ lock and can’t be updated</td><td style="text-align:center">当前session插入数据会等待获得锁<br>insert into mylock values(6,‘f’);</td></tr><tr><td style="text-align:center">释放锁<br>unlock tables;</td><td style="text-align:center">获得锁，更新成功</td></tr></tbody></table><h3 id="注意">注意:</h3><p><strong>MyISAM在执行查询语句之前，会自动给涉及的所有表加读锁，在执行更新操作前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此用户一般不需要使用命令来显式加锁，上例中的加锁时为了演示效果。</strong></p><p><strong>MyISAM的并发插入问题</strong></p><p>MyISAM表的读和写是串行的，这是就总体而言的，在一定条件下，MyISAM也支持查询和插入操作的并发执行</p><table><thead><tr><th style="text-align:center">session1</th><th style="text-align:center">session2</th></tr></thead><tbody><tr><td style="text-align:center">获取表的read local锁定<br>lock table mylock read local</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">当前session不能对表进行更新或者插入操作<br>insert into mylock values(6,‘f’)<br>Table ‘mylock’ was locked with a READ lock and can’t be updated<br>update mylock set name=‘aa’ where id = 1;<br>Table ‘mylock’ was locked with a READ lock and can’t be updated</td><td style="text-align:center">其他session可以查询该表的记录<br>select* from mylock</td></tr><tr><td style="text-align:center">当前session不能查询没有锁定的表<br>select * from person<br>Table ‘person’ was not locked with LOCK TABLES</td><td style="text-align:center">其他session可以进行插入操作，但是更新会阻塞<br>update mylock set name = ‘aa’ where id = 1;</td></tr><tr><td style="text-align:center">当前session不能访问其他session插入的记录；</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">释放锁资源：unlock tables</td><td style="text-align:center">当前session获取锁，更新操作完成</td></tr><tr><td style="text-align:center">当前session可以查看其他session插入的记录</td><td style="text-align:center"></td></tr></tbody></table><p>可以通过检查table_locks_waited和table_locks_immediate状态变量来分析系统上的表锁定争夺：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> status <span class="keyword">like</span> <span class="string">&#x27;table%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name         <span class="operator">|</span> <span class="keyword">Value</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Table_locks_immediate <span class="operator">|</span> <span class="number">352</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Table_locks_waited    <span class="operator">|</span> <span class="number">2</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+-------+</span></span><br><span class="line"><span class="comment">--如果Table_locks_waited的值比较高，则说明存在着较严重的表级锁争用情况。</span></span><br></pre></td></tr></table></figure><p><strong>InnoDB锁</strong></p><p><strong>1、事务及其ACID属性</strong></p><p>事务是由一组SQL语句组成的逻辑处理单元，事务具有4属性，通常称为事务的ACID属性。</p><p>原子性（Actomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。<br>一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。<br>隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。<br>持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。</p><p><strong>2、并发事务带来的问题</strong></p><p>相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持更多用户的并发操作，但与此同时，会带来一下问题：</p><p><strong>脏读</strong>： 一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”的数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做“脏读”</p><p><strong>不可重复读</strong>：一个事务在读取某些数据已经发生了改变、或某些记录已经被删除了！这种现象叫做“不可重复读”。</p><p><strong>幻读</strong>： 一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”</p><p>上述出现的问题都是数据库读一致性的问题，可以通过事务的隔离机制来进行保证。</p><p>数据库的事务隔离越严格，并发副作用就越小，但付出的代价也就越大，因为事务隔离本质上就是使事务在一定程度上串行化，需要根据具体的业务需求来决定使用哪种隔离级别</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">脏读</th><th style="text-align:center">不可重复读</th><th style="text-align:center">幻读</th></tr></thead><tbody><tr><td style="text-align:center">read uncommitted</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">read committed</td><td style="text-align:center"></td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">repeatable read</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">√</td></tr><tr><td style="text-align:center">serializable</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table><p>可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> status <span class="keyword">like</span> <span class="string">&#x27;innodb_row_lock%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name                 <span class="operator">|</span> <span class="keyword">Value</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_current_waits <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time          <span class="operator">|</span> <span class="number">18702</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time_avg      <span class="operator">|</span> <span class="number">18702</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_time_max      <span class="operator">|</span> <span class="number">18702</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Innodb_row_lock_waits         <span class="operator">|</span> <span class="number">1</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+-------+</span></span><br><span class="line"><span class="comment">--如果发现锁争用比较严重，如InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高</span></span><br></pre></td></tr></table></figure><p><strong>3、InnoDB的行锁模式及加锁方法</strong></p><p>​        <strong>共享锁（s）</strong>：又称读锁。允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。<br>​        <strong>排他锁（x）</strong>：又称写锁。允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。</p><p>​        mysql InnoDB引擎默认的修改数据语句：<strong>update,delete,insert都会自动给涉及到的数据加上排他锁，select语句默认不会加任何锁类型</strong>，如果加排他锁可以使用select …for update语句，加共享锁可以使用select … lock in share mode语句。<strong>所以加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select …from…查询数据，因为普通查询没有任何锁机制。</strong></p><p><strong>InnoDB行锁实现方式</strong></p><p>​        InnoDB行锁是通过给<strong>索引</strong>上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，<strong>否则，InnoDB将使用表锁！</strong></p><p>1、在不通过索引条件查询的时候，innodb使用的是表锁而不是行锁</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tab_no_index(id <span class="type">int</span>,name <span class="type">varchar</span>(<span class="number">10</span>)) engine<span class="operator">=</span>innodb;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tab_no_index <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">&#x27;1&#x27;</span>),(<span class="number">2</span>,<span class="string">&#x27;2&#x27;</span>),(<span class="number">3</span>,<span class="string">&#x27;3&#x27;</span>),(<span class="number">4</span>,<span class="string">&#x27;4&#x27;</span>);</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center">session1</th><th style="text-align:center">session2</th></tr></thead><tbody><tr><td style="text-align:center">set autocommit=0<br>select * from tab_no_index where id = 1;</td><td style="text-align:center">set autocommit=0<br>select * from tab_no_index where id =2</td></tr><tr><td style="text-align:center">select * from tab_no_index where id = 1 for update</td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">select * from tab_no_index where id = 2 for update;</td></tr></tbody></table><p>session1只给一行加了排他锁，但是session2在请求其他行的排他锁的时候，会出现锁等待。原因是在没有索引的情况下，innodb只能使用表锁。</p><p>2、创建带索引的表进行条件查询，innodb使用的是行锁</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tab_with_index(id <span class="type">int</span>,name <span class="type">varchar</span>(<span class="number">10</span>)) engine<span class="operator">=</span>innodb;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> tab_with_index <span class="keyword">add</span> index id(id);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tab_with_index <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">&#x27;1&#x27;</span>),(<span class="number">2</span>,<span class="string">&#x27;2&#x27;</span>),(<span class="number">3</span>,<span class="string">&#x27;3&#x27;</span>),(<span class="number">4</span>,<span class="string">&#x27;4&#x27;</span>);</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center">session1</th><th style="text-align:center">session2</th></tr></thead><tbody><tr><td style="text-align:center">set autocommit=0<br>select * from tab_with_indexwhere id = 1;</td><td style="text-align:center">set autocommit=0<br>select * from tab_with_indexwhere id =2</td></tr><tr><td style="text-align:center">select * from tab_with_indexwhere id = 1 for update</td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">select * from tab_with_indexwhere id = 2 for update;</td></tr></tbody></table><p>3、由于mysql的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是依然无法访问到具体的数据</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tab_with_index  <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">&#x27;4&#x27;</span>);</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center">session1</th><th style="text-align:center">session2</th></tr></thead><tbody><tr><td style="text-align:center">set autocommit=0</td><td style="text-align:center">set autocommit=0</td></tr><tr><td style="text-align:center">select * from tab_with_index where id = 1 and name=‘1’ for update</td><td style="text-align:center"></td></tr><tr><td style="text-align:center"></td><td style="text-align:center">select * from tab_with_index where id = 1 and name=‘4’ for update<br>虽然session2访问的是和session1不同的记录，但是因为使用了相同的索引，所以需要等待锁</td></tr></tbody></table><h3 id="总结">总结</h3><p><strong>对于MyISAM的表锁，主要讨论了以下几点：</strong><br>（1）共享读锁（S）之间是兼容的，但共享读锁（S）与排他写锁（X）之间，以及排他写锁（X）之间是互斥的，也就是说读和写是串行的。<br>（2）在一定条件下，MyISAM允许查询和插入并发执行，我们可以利用这一点来解决应用中对同一表查询和插入的锁争用问题。<br>（3）MyISAM默认的锁调度机制是写优先，这并不一定适合所有应用，用户可以通过设置LOW_PRIORITY_UPDATES参数，或在INSERT、UPDATE、DELETE语句中指定LOW_PRIORITY选项来调节读写锁的争用。<br>（4）由于表锁的锁定粒度大，读写之间又是串行的，因此，如果更新操作较多，MyISAM表可能会出现严重的锁等待，可以考虑采用InnoDB表来减少锁冲突。</p><p><strong>对于InnoDB表，本文主要讨论了以下几项内容：</strong><br>（1）InnoDB的行锁是基于索引实现的，如果不通过索引访问数据，InnoDB会使用表锁。<br>（2）在不同的隔离级别下，InnoDB的锁机制和一致性读策略不同。</p><p>在了解InnoDB锁特性后，用户可以通过设计和SQL调整等措施减少锁冲突和死锁，包括：</p><ul><li>尽量使用较低的隔离级别； 精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会；</li><li>选择合理的事务大小，小事务发生锁冲突的几率也更小；</li><li>给记录集显式加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁；</li><li>不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会；</li><li>尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响； 不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁；</li><li>对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。</li></ul></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;mysql的锁机制&lt;/h1&gt;
&lt;h3 id=&quot;1、MySQL锁的基本介绍&quot;&gt;1、MySQL锁的基本介绍&lt;/h3&gt;
&lt;p&gt;​        **锁是计算机协调多个进程或线程并发访问某一资源的机制。**在数据库中，除</summary>
      
    
    
    
    <category term="数据库" scheme="https://0914ds.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>mysql执行计划</title>
    <link href="https://0914ds.github.io/2024/02/24/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E4%BC%98%E5%8C%96/"/>
    <id>https://0914ds.github.io/2024/02/24/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E4%BC%98%E5%8C%96/</id>
    <published>2024-02-23T18:45:12.000Z</published>
    <updated>2024-02-24T05:34:03.124Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>mysql调优</h1><h2 id="回顾-mysql执行过程">回顾:mysql执行过程</h2><p>（1）客户端发送一条查询语句到服务器；</p><p>（2）服务器先查询缓存，如果命中缓存，则立即返回存储在缓存中的数据；</p><p>（3）未命中缓存后，MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树，MySQL解析器将使用MySQL语法进行验证和解析。</p><p>​ 例如，验证是否使用了错误的关键字，或者关键字的使用是否正确；</p><p>（4）预处理是根据一些MySQL规则检查解析树是否合理，比如检查表和列是否存在，还会解析名字和别名，然后预处理器会验证权限；</p><p>​ 根据执行计划查询执行引擎，调用API接口调用存储引擎来查询数据；</p><p>（5）将结果返回客户端，并进行缓存；</p><h3 id="P8大佬的62条-SQL语句性能优化策略">P8大佬的62条 SQL语句性能优化策略</h3><p>1、 为 WHERE 及 ORDER BY 涉及的列上建立索引<br>对查询进行优化，应尽量避免全表扫描，首先应考虑在 WHERE 及 ORDER BY 涉及的列上建立索引。</p><p>2、where中使用默认值代替null<br>应尽量避免在 WHERE 子句中对字段进行 NULL 值判断，创建表时 NULL 是默认值，但大多数时候应该使用 NOT NULL，或者使用一个特殊的值，如 0，-1 作为默认值。</p><p>为啥建议where中使用默认值代替null，四个原因：</p><p>（1）并不是说使用了is null或者 is not null就会不走索引了，这个跟mysql版本以及查询成本都有关；</p><p>（2）如果mysql优化器发现，走索引比不走索引成本还要高，就会放弃索引，这些条件 !=，&lt;&gt;，is null，is not null经常被认为让索引失效；</p><p>（3）其实是因为一般情况下，查询的成本高，优化器自动放弃索引的；</p><p>（4）如果把null值，换成默认值，很多时候让走索引成为可能，同时，表达意思也相对清晰一点；</p><p>3、慎用 != 或 &lt;&gt; 操作符。<br>MySQL 只有对以下操作符才使用索引：&lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN，以及某些时候的 LIKE。</p><p>所以：应尽量避免在 WHERE 子句中使用 != 或 &lt;&gt; 操作符， 会导致全表扫描。</p><p>4、慎用 OR 来连接条件<br>使用or可能会使索引失效，从而全表扫描；</p><p>应尽量避免在 WHERE 子句中使用 OR 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，</p><p>可以使用 UNION 合并查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> num<span class="operator">=</span><span class="number">10</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> num<span class="operator">=</span><span class="number">20</span></span><br></pre></td></tr></table></figure><p>一个关键的问题是否用到索引。</p><p>他们的速度只同是否使用索引有关，如果查询需要用到联合索引，用 UNION all 执行的效率更高。</p><p>多个 OR 的字句没有用到索引，改写成 UNION 的形式再试图与索引匹配。<br>5、慎用 IN 和 NOT IN<br>IN 和 NOT IN 也要慎用，否则会导致全表扫描。对于连续的数值，能用 BETWEEN 就不要用 IN：select id from t where num between 1 and 3。</p><p>6、慎用 左模糊like ‘%…’<br>模糊查询，程序员最喜欢的就是使用like，like很可能让索引失效。</p><p>比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> name <span class="keyword">like</span>‘<span class="operator">%</span>abc<span class="operator">%</span>’ </span><br><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> name <span class="keyword">like</span>‘<span class="operator">%</span>abc’</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>而select id from t where name like‘abc%’才用到索引。<br>所以：<br>首先尽量避免模糊查询，如果必须使用，不采用全模糊查询，也应尽量采用右模糊查询， 即like ‘…%’，是会使用索引的；<br>左模糊like ‘%…’无法直接使用索引，但可以利用reverse + function index的形式，变化成 like ‘…%’；<br>全模糊查询是无法优化的，一定要使用的话建议使用搜索引擎，比如 ElasticSearch</p><p>如下面语句将进行全表扫描：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> num<span class="operator">=</span><span class="variable">@num</span></span><br></pre></td></tr></table></figure><p>因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推 迟到 运行时；</p><p>它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。</p><p>所以， 可以改为强制查询使用索引：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select id from t with(index(索引名)) where num=@num</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>8、应避免WHERE 表达式操作/对字段进行函数操作<br>任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，</p><p>应尽量避免在 WHERE 子句中对字段进行表达式操作，应尽量避免在 WHERE 子句中对字段进行函数操作。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> num<span class="operator">/</span><span class="number">2</span><span class="operator">=</span><span class="number">100</span></span><br><span class="line">应改为:</span><br><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> num<span class="operator">=</span><span class="number">100</span><span class="operator">*</span><span class="number">2</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。<br>如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> <span class="built_in">substring</span>(name,<span class="number">1</span>,<span class="number">3</span>)<span class="operator">=</span>‘abc’</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> datediff(<span class="keyword">day</span>,createdate,‘<span class="number">2005</span><span class="number">-11</span><span class="number">-30</span>’)<span class="operator">=</span><span class="number">0</span></span><br><span class="line"></span><br><span class="line">应改为:</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> name <span class="keyword">like</span> ‘abc<span class="operator">%</span>’</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> createdate<span class="operator">&gt;=</span>‘<span class="number">2005</span><span class="number">-11</span><span class="number">-30</span>’ <span class="keyword">and</span> createdate<span class="operator">&lt;</span>‘<span class="number">2005</span><span class="number">-12</span><span class="number">-1</span>’</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>9、用 EXISTS 代替 IN 是一个好的选择<br>很多时候用exists 代替in 是一个好的选择：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> num <span class="keyword">from</span> a <span class="keyword">where</span> num <span class="keyword">in</span>(<span class="keyword">select</span> num <span class="keyword">from</span> b)</span><br><span class="line">用下面的语句替换：</span><br><span class="line"><span class="keyword">select</span> num <span class="keyword">from</span> a <span class="keyword">where</span> <span class="keyword">exists</span>(<span class="keyword">select</span> <span class="number">1</span> <span class="keyword">from</span> b <span class="keyword">where</span> num<span class="operator">=</span>a.num)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>10、索引并不是越多越好<br>索引固然可以提高相应的 SELECT 的效率，但同时也降低了 INSERT 及 UPDATE 的效。</p><p>因为 INSERT 或 UPDATE 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。</p><p>一个表的索引数最好不要超过 6 个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。</p><p>11、应尽可能的避免更新 clustered 索引数据列<br>应尽可能的避免更新 clustered 索引数据列， 因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，</p><p>一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。</p><p>若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。</p><p>12、尽量使用数字型字段<br>（1）因为引擎在处理查询和连接时会逐个比较字符串中每一个字符；</p><p>（2）而对于数字型而言只需要比较一次就够了；</p><p>（3）字符会降低查询和连接的性能，并会增加存储开销；</p><p>所以：</p><p>尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。</p><p>13、尽可能的使用 varchar, nvarchar 代替 char, nchar<br>（1）varchar变长字段按数据内容实际长度存储，存储空间小，可以节省存储空间；</p><p>（2）char按声明大小存储，不足补空格；</p><p>（3）其次对于查询来说，在一个相对较小的字段内搜索，效率更高；</p><p>因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。</p><p>14、查询SQL尽量不要使用select <em>，而是具体字段<br>最好不要使用返回所有：select * from t ，用具体的字段列表代替 “</em>”，不要返回用不到的任何字段。</p><p>select *的弊端：</p><p>（1）增加很多不必要的消耗，比如CPU、IO、内存、网络带宽；</p><p>（2）增加了使用覆盖索引的可能性；</p><p>（3）增加了回表的可能性；</p><p>（4）当表结构发生变化时，前端也需要更改；</p><p>（5）查询效率低；</p><p>15、尽量避免向客户端返回大数据量<br>大数据量增加很多不必要的消耗，比如CPU、IO、内存、网络带宽</p><p>尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。</p><p>16、使用表的别名（Alias）：<br>当在 SQL 语句中连接多个表时，请使用表的别名并把别名前缀于每个 Column 上。</p><p>这样一来，就可以减少解析的时间并减少那些由 Column 歧义引起的语法错误。</p><p>17、使用“临时表”暂存中间结果 ：<br>简化 SQL 语句的重要方法就是采用临时表暂存中间结果。</p><p>但是临时表的好处远远不止这些，将临时结果暂存在临时表，后面的查询就在 tempdb 中了，这可以避免程序中多次扫描主表，也大大减少了程序执行中“共享锁”阻塞“更新锁”，减少了阻塞，提高了并发性能。</p><p>18、一些 SQL 查询语句应加上 nolock。<br>一些 SQL 查询语句应加上 nolock，读、写是会相互阻塞的，为了提高并发性能。</p><p>对于一些查询，可以加上 nolock，这样读的时候可以允许写，但缺点是可能读到未提交的脏数据。</p><p>使用 nolock 有3条原则：</p><p>查询的结果用于“插、删、改”的不能加 nolock；<br>查询的表属于频繁发生页分裂的，慎用 nolock ；<br>使用临时表一样可以保存“数据前影”，起到类似 Oracle 的 undo 表空间的功能，能采用临时表提高并发性能的，不要用 nolock。<br>19、常见的简化规则如下：<br>不要有超过 5 个以上的表连接（JOIN），考虑使用临时表或表变量存放中间结果。</p><p>少用子查询，视图嵌套不要过深，一般视图嵌套不要超过 2 个为宜。</p><p>20、将需要查询的结果预先计算好<br>将需要查询的结果预先计算好放在表中，查询的时候再Select，而不是查询的时候进行计算。</p><p>这在SQL7.0以前是最重要的手段，例如医院的住院费计算。</p><p>21、IN后出现最频繁的值放在最前面<br>如果一定用IN，那么：</p><p>在IN后面值的列表中，将出现最频繁的值放在最前面，出现得最少的放在最后面，减少判断的次数。</p><p>22、使用存储过程进行数据处理<br>尽量将数据的处理工作放在服务器上，减少网络的开销，如使用存储过程。</p><p>存储过程是编译好、优化过、并且被组织到一个执行规划里、且存储在数据库中的 SQL 语句，是控制流语言的集合，速度当然快。反复执行的动态 SQL，可以使用临时存储过程，该过程（临时表）被放在 Tempdb 中。</p><p>23、尽量使用 EXISTS 代替 select count(1) 来判断是否存在记录。<br>count 函数只有在统计表中所有行数时使用，而且 count(1) 比 count(*) 更有效率。</p><p>24、索引的使用规范：<br>索引的创建要与应用结合考虑，建议大的 OLTP 表不要超过 6 个索引；<br>尽可能的使用索引字段作为查询条件，尤其是聚簇索引，必要时可以通过 index index_name 来强制指定索引；<br>避免对大表查询时进行 table scan，必要时考虑新建索引；<br>在使用索引字段作为条件时，如果该索引是联合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用；<br>要注意索引的维护，周期性重建索引，重新编译存储过程。</p><p>25、下列 SQL 条件语句中的列都建有恰当的索引，但执行速度却非常慢：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> record <span class="keyword">WHERE</span> <span class="built_in">substrINg</span>(card_no, <span class="number">1</span>, <span class="number">4</span>) <span class="operator">=</span> <span class="string">&#x27;5378&#x27;</span> <span class="comment">--13秒 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> record <span class="keyword">WHERE</span> amount<span class="operator">/</span><span class="number">30</span> <span class="operator">&lt;</span> <span class="number">1000</span> <span class="comment">--11秒 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> record <span class="keyword">WHERE</span> <span class="keyword">convert</span>(<span class="type">char</span>(<span class="number">10</span>), <span class="type">date</span>, <span class="number">112</span>) <span class="operator">=</span> <span class="string">&#x27;19991201&#x27;</span> <span class="comment">--10秒</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>分析：</p><p>WHERE 子句中对列的任何操作结果都是在 SQL 运行时逐列计算得到的，因此它不得不进行表搜索，而没有使用该列上面的索引。</p><p>如果这些结果在查询编译时就能得到，那么就可以被 SQL 优化器优化，使用索引，避免表搜索，因此将 SQL 重写成下面这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> record <span class="keyword">WHERE</span> card_no <span class="keyword">like</span> <span class="string">&#x27;5378%&#x27;</span> <span class="comment">-- &lt; 1秒 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> record <span class="keyword">WHERE</span> amount <span class="operator">&lt;</span> <span class="number">1000</span><span class="operator">*</span><span class="number">30</span> <span class="comment">-- &lt; 1秒 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> record <span class="keyword">WHERE</span> <span class="type">date</span> <span class="operator">=</span> <span class="string">&#x27;1999/12/01&#x27;</span> <span class="comment">-- &lt; 1秒</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>26、用批量插入或批量更新<br>当有一批处理的插入或更新时，用批量插入或批量更新，绝不会一条条记录的去更新。</p><p>（1）多条提交</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">user</span> (id,username) <span class="keyword">VALUES</span>(<span class="number">1</span>,<span class="string">&#x27;技术自由圈&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">user</span> (id,username) <span class="keyword">VALUES</span>(<span class="number">2</span>,<span class="string">&#x27;疯狂创客圈&#x27;</span>);</span><br></pre></td></tr></table></figure><p>（2）批量提交</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">user</span> (id,username) <span class="keyword">VALUES</span>(<span class="number">1</span>,<span class="string">&#x27;技术自由圈&#x27;</span>),(<span class="number">2</span>,<span class="string">&#x27;疯狂创客圈&#x27;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>默认新增SQL有事务控制，导致每条都需要事务开启和事务提交，而批量处理是一次事务开启和提交，效率提升明显，达到一定量级，效果显著，平时看不出来。</p><p>27、存储过程中慎用循环<br>在所有的存储过程中，能够用 SQL 语句的，我绝不会用循环去实现。</p><p>例如：列出上个月的每一天，我会用 connect by 去递归查询一下，绝不会去用循环从上个月第一天到最后一天。</p><p>28、选择最有效率的表名顺序<br>选择最有效率的表名顺序（只在基于规则的优化器中有效）： Oracle 的解析器按照从右到左的顺序处理 FROM 子句中的表名，FROM 子句中写在最后的表（基础表 driving table）将被最先处理，在 FROM 子句中包含多个表的情况下，你必须选择记录条数最少的表作为基础表。</p><p>如果有 3 个以上的表连接查询，那就需要选择交叉表（interp table）作为基础表，交叉表是指那个被其他表所引用的表。</p><p>29、将不需要的记录在 GROUP BY 之前过滤掉<br>提高 GROUP BY 语句的效率，可以通过将不需要的记录在 GROUP BY 之前过滤掉。</p><p>下面两个查询返回相同结果，但第二个明显就快了许多。<br>低效：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> JOB, <span class="built_in">AVG</span>(SAL) </span><br><span class="line"><span class="keyword">FROM</span> EMP </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> JOB </span><br><span class="line"><span class="keyword">HAVING</span> JOB <span class="operator">=</span> <span class="string">&#x27;PRESIDENT&#x27;</span> </span><br><span class="line"><span class="keyword">OR</span> JOB <span class="operator">=</span> <span class="string">&#x27;MANAGER&#x27;</span> </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>高效：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> JOB, <span class="built_in">AVG</span>(SAL) </span><br><span class="line"><span class="keyword">FROM</span> EMP</span><br><span class="line"><span class="keyword">WHERE</span> JOB <span class="operator">=</span> <span class="string">&#x27;PRESIDENT&#x27;</span> </span><br><span class="line"><span class="keyword">OR</span> JOB <span class="operator">=</span> <span class="string">&#x27;MANAGER&#x27;</span> </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> JOB</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>30、别名的使用，<br>别名是大型数据库的应用技巧，就是表名、列名在查询中以一个字母为别名，查询速度要比建连接表快 1.5 倍。</p><p>31、避免死锁，<br>在你的存储过程和触发器中访问同一个表时总是以相同的顺序；事务应经可能地缩短，在一个事务中应尽可能减少涉及到的数据量；永远不要在事务中等待用户输入。</p><p>32、避免使用临时表，可以使用表变量代替<br>避免使用临时表，除非却有需要，否则应尽量避免使用临时表，相反，可以使用表变量代替。</p><p>大多数时候（99%），表变量驻扎在内存中，因此速度比临时表更快，</p><p>临时表驻扎在 TempDb 数据库中，因此临时表上的操作需要跨数据库通信，速度自然慢。</p><p>33、最好不要使用触发器：<br>触发一个触发器，执行一个触发器事件本身就是一个耗费资源的过程；<br>如果能够使用约束实现的，尽量不要使用触发器；<br>不要为不同的触发事件（Insert、Update 和 Delete）使用相同的触发器；<br>不要在触发器中使用事务型代码。<br>34、索引创建规则：<br>表的主键、外键必须有索引；<br>数据量超过 300 的表应该有索引；<br>经常与其他表进行连接的表，在连接字段上应该建立索引；<br>经常出现在 WHERE 子句中的字段，特别是大表的字段，应该建立索引；<br>索引应该建在选择性高的字段上；<br>索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引；<br>复合索引的建立需要进行仔细分析，尽量考虑用单字段索引代替；<br>正确选择复合索引中的主列字段，一般是选择性较好的字段；<br>复合索引的几个字段是否经常同时以 AND 方式出现在 WHERE 子句中？单字段查询是否极少甚至没有？如果是，则可以建立复合索引；否则考虑单字段索引；<br>如果复合索引中包含的字段经常单独出现在 WHERE 子句中，则分解为多个单字段索引；<br>如果复合索引所包含的字段超过 3 个，那么仔细考虑其必要性，考虑减少复合的字段；<br>如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引；<br>频繁进行数据操作的表，不要建立太多的索引；<br>删除无用的索引，避免对执行计划造成负面影响；<br>表上建立的每个索引都会增加存储开销，索引对于插入、删除、更新操作也会增加处理上的开销。另外，过多的复合索引，在有单字段索引的情况下，一般都是没有存在价值的；相反，还会降低数据增加删除时的性能，特别是对频繁更新的表来说，负面影响更大。<br>尽量不要对数据库中某个含有大量重复的值的字段建立索引。<br>35、在写 SQL 语句时，应尽量减少空格的使用<br>查询缓冲并不自动处理空格，</p><p>因此，在写 SQL 语句时，应尽量减少空格的使用，尤其是在 SQL 首和尾的空格（因为查询缓冲并不自动截取首尾空格）。</p><p>36、member 用 mid 做标准进行分表方便查询么？<br>member 用 mid 做标准进行分表方便查询么？</p><p>一般的业务需求中基本上都是以 username 为查询依据，正常应当是 username 做 hash 取模来分表。</p><p>而分表的话 MySQL 的 partition 功能就是干这个的，对代码是透明的；在代码层面去实现貌似是不合理的。</p><p>37、每张表都设置一个 ID 做为其主键<br>我们应该为数据库里的每张表都设置一个 ID 做为其主键，而且最好的是一个 INT 型的（推荐使用 UNSIGNED），并设置上自动增加的 AUTO_INCREMENT 标志。</p><p>38、在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON<br>在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON，在结束时设置 SET NOCOUNT OFF。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。</p><p>39、MySQL 查询可以启用高速查询缓存。<br>这是提高数据库性能的有效MySQL优化方法之一。当同一个查询被执行多次时，从缓存中提取数据和直接从数据库中返回数据快很多。</p><p>40、EXPLAIN SELECT 查询用来跟踪查看效果：<br>使用 EXPLAIN 关键字可以让你知道 MySQL 是如何处理你的 SQL 语句的。</p><p>这可以帮你分析你的查询语句或是表结构的性能瓶颈。</p><p>EXPLAIN 的查询结果还会告诉你你的索引主键被如何利用的，你的数据表是如何被搜索和排序的。</p><p>41、当只要一行数据时使用 LIMIT 1 ：<br>当你查询表的有些时候，你已经知道结果只会有一条结果，但因为你可能需要去fetch游标，或是你也许会去检查返回的记录数。</p><p>在这种情况下，加上 LIMIT 1 可以增加性能。</p><p>这样一来，MySQL 数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据。</p><p>42、选择表合适存储引擎：<br>myisam：应用时以读和插入操作为主，只有少量的更新和删除，并且对事务的完整性，并发性要求不是很高的。<br>InnoDB：事务处理，以及并发条件下要求数据的一致性。除了插入和查询外，包括很多的更新和删除。（InnoDB 有效地降低删除和更新导致的锁定）。<br>对于支持事务的 InnoDB类 型的表来说，影响速度的主要原因是 AUTOCOMMIT 默认设置是打开的，而且程序没有显式调用 BEGIN 开始事务，导致每插入一条都自动提交，严重影响了速度。可以在执行 SQL 前调用 begin，多条 SQL 形成一个事物（即使 autocommit 打开也可以），将大大提高性能。</p><p>43、优化表的数据类型，选择合适的数据类型：<br>**原则：**更小通常更好，简单就好，所有字段都得有默认值，尽量避免 NULL。</p><p>例如：数据库表设计时候更小的占磁盘空间尽可能使用更小的整数类型。(mediumint 就比 int 更合适)</p><p>比如时间字段：datetime 和 timestamp。datetime 占用8个字节，timestamp 占用4个字节，只用了一半。而 timestamp 表示的范围是 1970—2037 适合做更新时间。</p><p>MySQL可以很好的支持大数据量的存取，但是一般说来，数据库中的表越小，在它上面执行的查询也就会越快。</p><p>因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。</p><p>例如：在定义邮政编码这个字段时，如果将其设置为 CHAR(255)，显然给数据库增加了不必要的空间。甚至使用VARCHAR 这种类型也是多余的，因为 CHAR(6) 就可以很好的完成任务了。</p><p>同样的，如果可以的话，我们应该使用 MEDIUMINT 而不是 BIGIN 来定义整型字段，应该尽量把字段设置为 NOT NULL，这样在将来执行查询的时候，数据库不用去比较 NULL 值。</p><p>对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为 ENUM 类型。因为在 MySQL 中，ENUM 类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多。这样，我们又可以提高数据库的性能。</p><p>44、将大的DELETE，UPDATE、INSERT 查询变成多个小查询<br>能写一个几十行、几百行的SQL语句是不是显得逼格很高？然而，为了达到更好的性能以及更好的数据控制，你可以将他们变成多个小查询。</p><p>45、关于临时表<br>（1）避免频繁创建和删除临时表，以减少系统表资源的消耗；</p><p>（2）在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log；</p><p>（3）如果数据量不大，为了缓和系统表的资源，应先create table，然后insert；</p><p>（4）如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除。先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。</p><p>46、使用explain分析你SQL执行计划<br>（1）type</p><p>system：表仅有一行，基本用不到；<br>const：表最多一行数据配合，主键查询时触发较多；<br>eq_ref：对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型；<br>ref：对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取；<br>range：只检索给定范围的行，使用一个索引来选择行。当使用=、&lt;&gt;、&gt;、&gt;=、&lt;、&lt;=、IS NULL、&lt;=&gt;、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range；<br>index：该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小；<br>all：全表扫描；<br>性能排名：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all。<br>实际sql优化中，最后达到ref或range级别。<br>（2）Extra常用关键字</p><p>Using index：只从索引树中获取信息，而不需要回表查询；<br>Using where：WHERE子句用于限制哪一个行匹配下一个表或发送到客户。除非你专门从表中索取或检查所有行，如果Extra值不为Using where并且表联接类型为ALL或index，查询可能会有一些错误。需要回表查询。<br>Using temporary：mysql常建一个临时表来容纳结果，典型情况如查询包含可以按不同情况列出列的GROUP BY和ORDER BY子句时；</p><p>47、使用合理的分页方式以提高分页的效率</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,name <span class="keyword">from</span> <span class="keyword">user</span> limit <span class="number">100000</span>, <span class="number">20</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用上述SQL语句做分页的时候，随着表数据量的增加，直接使用limit语句会越来越慢。</p><p>此时，可以通过取前一页的最大ID，以此为起点，再进行limit操作，效率提升显著。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,name <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id<span class="operator">&gt;</span> <span class="number">100000</span> limit <span class="number">20</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>48、尽量控制单表数据量的大小，建议控制在500万以内<br>500万并不是MySQL数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。</p><p>可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小。</p><p>49、谨慎使用Mysql分区表<br>（1）分区表在物理上表现为多个文件，在逻辑上表现为一个表；</p><p>（2）谨慎选择分区键，跨分区查询效率可能更低；</p><p>（3）建议采用物理分表的方式管理大数据。</p><p>50、尽量做到冷热数据分离，减小表的宽度<br>Mysql限制每个表最多存储4096列，并且每一行数据的大小不能超过65535字节。</p><p>减少磁盘IO,保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的IO）；</p><p>更有效的利用缓存，避免读入无用的冷数据；</p><p>经常一起使用的列放到一个表中（避免更多的关联操作）。</p><p>51、禁止在表中建立预留字段<br>（1）预留字段的命名很难做到见名识义；</p><p>（2）预留字段无法确认存储的数据类型，所以无法选择合适的类型；</p><p>（3）对预留字段类型的修改，会对表进行锁定；</p><p>52、禁止在数据库中存储图片，文件等大的二进制数据<br>通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机IO操作，文件很大时，IO操作很耗时。</p><p>通常存储于文件服务器，数据库只存储文件地址信息。</p><p>53、建议把BLOB或是TEXT列分离到单独的扩展表中<br>Mysql内存临时表不支持TEXT、BLOB这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，Mysql还是要进行二次查询，会使sql性能变得很差，但是不是说一定不能使用这样的数据类型。</p><p>如果一定要使用，建议把BLOB或是TEXT列分离到单独的扩展表中，查询时一定不要使用select * 而只需要取出必要的列，不需要TEXT列的数据时不要对该列进行查询。</p><p>54、TEXT或BLOB类型只能使用前缀索引<br>因为MySQL对索引字段长度是有限制的，所以TEXT类型只能使用前缀索引，并且TEXT列上是不能有默认值的。</p><p>55、建议使用预编译语句进行数据库操作<br>预编译语句可以重复使用这些计划，减少SQL编译所需要的时间，还可以解决动态SQL所带来的SQL注入的问题。</p><p>只传参数，比传递SQL语句更高效。</p><p>相同语句可以一次解析，多次使用，提高处理效率。</p><p>56、表连接不宜太多，索引不宜太多，一般5个以内<br>（1）表连接不宜太多，一般5个以内</p><p>关联的表个数越多，编译的时间和开销也就越大<br>每次关联内存中都生成一个临时表<br>应该把连接表拆开成较小的几个执行，可读性更高<br>如果一定需要连接很多表才能得到数据，那么意味着这是个糟糕的设计了<br>阿里规范中，建议多表联查三张表以下<br>（2）索引不宜太多，一般5个以内</p><p>索引并不是越多越好，虽其提高了查询的效率，但却会降低插入和更新的效率；<br>索引可以理解为一个就是一张表，其可以存储数据，其数据就要占空间；<br>索引表的数据是排序的，排序也是要花时间的；<br>insert或update时有可能会重建索引，如果数据量巨大，重建将进行记录的重新排序，所以建索引需要慎重考虑，视具体情况来定；<br>一个表的索引数最好不要超过5个，若太多需要考虑一些索引是否有存在的必要；<br>57、数据库和表的字符集统一使用UTF8<br>兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储emoji表情的需要，字符集需要采用utf8mb4字符集。</p><p>58、合理选择索引列的顺序<br>建立索引的目的是：</p><p>希望通过索引进行数据查找，减少随机IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。</p><p>区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）。</p><p>尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO性能也就越好）。</p><p>使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）。</p><p>59、对于频繁的查询优先考虑使用覆盖索引<br>覆盖索引：就是包含了所有查询字段(where,select,ordery by,group by包含的字段)的索引。</p><p>覆盖索引的好处：</p><p>（1）避免Innodb表进行索引的二次查询</p><p>Innodb是以聚集索引的顺序来存储的，对于Innodb来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。</p><p>而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了IO操作，提升了查询效率。</p><p>（2）可以把随机IO变成顺序IO加快查询效率</p><p>由于覆盖索引是按键值的顺序存储的，对于IO密集型的范围查找来说，对比随机从磁盘读取每一行的数据IO要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的IO转变成索引查找的顺序IO。</p><p>60、MySQL 查询优化的一般策略：<br>使用慢查询日志去发现慢查询，使用执行计划去判断查询是否正常运行，总是去测试你的查询看看是否他们运行在最佳状态下。</p><p>久而久之性能总会变化，避免在整个表上使用 count(*)，它可能锁住整张表，使查询保持一致以便后续相似的查询可以使用查询缓存，在适当的情形下使用 GROUP BY 而不是 DISTINCT，在 WHERE、GROUP BY 和 ORDER BY 子句中使用有索引的列，保持索引简单，不在多个索引中包含同一个列。</p><p>有时候 MySQL 会使用错误的索引，对于这种情况使用 USE INDEX，检查使用 SQL_MODE=STRICT 的问题，对于记录数小于5的索引字段，在 UNION 的时候使用LIMIT不是是用OR。</p><p>为了避免在更新之前进行一次 SELECT，使用 INSERT ON DUPLICATE KEY 或者 INSERT IGNORE；</p><p>不要用 UPDATE 去实现，不要使用 MAX；</p><p>使用索引字段和 ORDER BY子句 LIMIT M，N 实际上可以减缓查询在某些情况下，有节制地使用，在 WHERE 子句中使用 UNION 代替子查询，在重新启动的 MySQL，记得来温暖你的数据库，以确保数据在内存和查询速度快，考虑持久连接，而不是多个连接，以减少开销。</p><p>基准查询，包括使用服务器上的负载，有时一个简单的查询可以影响其他查询，当负载增加在服务器上，使用 SHOW PROCESSLIST 查看慢的和有问题的查询，在开发环境中产生的镜像数据中测试的所有可疑的查询。</p><p>61、定期的进行 MySQL 数据库的备份：<br>前段时间，有小伙伴来找尼恩，说他的数据库被黑客挟持了，要支付1个比特币才能要回来，我问他有定期的备份了吗，他说没有。</p><p>MySQL 数据库的备份流程：</p><p>从二级复制服务器上进行备份；<br>在进行备份期间停止复制，以避免在数据依赖和外键约束上出现不一致；<br>彻底停止 MySQL，从数据库文件进行备份；<br>如果使用 MySQL dump 进行备份，请同时备份二进制日志文件 – 确保复制没有中断；<br>不要信任 LVM 快照，这很可能产生数据不一致，将来会给你带来麻烦；<br>为了更容易进行单表恢复，以表为单位导出数据——如果数据是与其他表隔离的。<br>当使用 mysqldump 时请使用 –opt；<br>在备份之前检查和优化表；<br>为了更快的进行导入，在导入时临时禁用外键约束。；<br>为了更快的进行导入，在导入时临时禁用唯一性检测；<br>在每一次备份后计算数据库，表以及索引的尺寸，以便更够监控数据尺寸的增长；<br>通过自动调度脚本监控复制实例的错误和延迟；<br>定期执行备份。<br>62、分库分表与NOSqL结合使用<br>当数据量达到一定的数量之后，限制数据库存储性能的就不再是数据库层面的优化就能够解决的；</p><p>这个时候往往采用的是读写分离与分库分表同时也会结合缓存一起使用，而这个时候数据库层面的优化只是基础。</p><p>一般的演进规则是：</p><p>读写分离适用于较小一些的数据量；<br>分表适用于中等数据量；<br>而分库与分表一般是结合着用，这就适用于大数据量的存储了，<br>这也是现在大型互联网公司解决数据存储的方法之一。</p><p>尼恩备注：</p><p>分库分表与NOSqL结合使用，一般建议 ElasticSearch+Hbase架构。<br>左手大数据，右手云原生， 要掌握高并发架构达到技术自由， 大数据、云原生的技术必不可少。</p></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;mysql调优&lt;/h1&gt;
&lt;h2 id=&quot;回顾-mysql执行过程&quot;&gt;回顾:mysql执行过程&lt;/h2&gt;
&lt;p&gt;（1）客户端发送一条查询语句到服务器；&lt;/p&gt;
&lt;p&gt;（2）服务器先查询缓存，如果命中缓存，则立即返</summary>
      
    
    
    
    <category term="数据库" scheme="https://0914ds.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>梯度下降</title>
    <link href="https://0914ds.github.io/2023/08/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <id>https://0914ds.github.io/2023/08/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/</id>
    <published>2023-08-17T17:13:16.000Z</published>
    <updated>2023-08-17T23:42:27.451Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><meta name="referrer" content="no-referrer"><h2 id="梯度下降">梯度下降</h2><h3 id="线性回归预测房价">线性回归预测房价</h3><ul><li>数据加载</li><li>数据介绍</li><li>数据拆分</li><li>数据建模</li><li>数据预测</li><li>数据评估</li></ul><h3 id="1、无约束最优化问题">1、无约束最优化问题</h3><h4 id="1-1、无约束最优化">1.1、无约束最优化</h4><p> <strong>  无约束最优化问题</strong>（unconstrained optimization problem）指的是从一个问题的所有<strong>可能</strong>的备选方案中，选择出依某种指标来说是<strong>最优</strong>的解决方案。从数学上说，最优化是研究在一个给定的集合S上泛函$J(\theta)$的极小化或极大化问题：<strong>广义上</strong>，最优化包括数学规划、图和网络、组合最优化、库存论、决策论、排队论、最优控制等。<strong>狭义上</strong>，最优化仅指数学规划。</p><h4 id="1-2、梯度下降">1.2、梯度下降</h4><p>  <strong>梯度下降法</strong>(Gradient Descent)是一个算法，但不是像多元线性回归那样是一个具体做回归任务的算法，而是一个非常<strong>通用</strong>的优化算法来帮助一些机器学习算法（都是无约束最优化问题）求解出<strong>最优解</strong>， 所谓的通用就是很多机器学习算法都是用梯度下降，甚至<strong>深度学习</strong>也是用它来求解最优解。所有优化算法的目的都是期望以<strong>最快</strong>的速度把模型参数θ求解出来，梯度下降法就是一种<strong>经典</strong>常用的优化算法。</p><p>  之前利用正规方程求解的 θ 是最优解的原因是 MSE 这个损失函数是凸函数。但是，机器学习的损失函数并非都是凸函数，设置导数为 0 会得到很多个极值，不能确定唯一解。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/ac185dc9b60d4411b6d0c9ae9dc15543.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/ac185dc9b60d4411b6d0c9ae9dc15543.jpg" alt="image.png"></a></p><p>  使用正规方程 $\theta = (X^TX)^{-1}X^Ty$ 求解的另一个限制是特征维度（$X_1、X_2……、X_n$）不能太多，矩阵逆运算的时间复杂度通常为 $O(n^3)$ 。换句话说，就是如果特征数量翻$ 2^3$倍，你的计算时间大致为原来的倍，也就是之前时间的8倍。举个例子，2 个特征 1 秒，4 个特征就是 8 秒，8 个特征就是 64 秒，16 个特征就是 512 秒，当特征更多的时候呢？运行时间会非常漫长~</p><p>  所以正规方程求出最优解<strong>并不是</strong>机器学习甚至深度学习常用的手段。</p><p>  之前我们令导数为 0，反过来求解最低点 θ 是多少，而梯度下降法是<strong>一点点</strong>去逼近最优解!</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/6e97ba09e2694bf69d2919cd159a6a59.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/6e97ba09e2694bf69d2919cd159a6a59.jpeg" alt="image.png"></a></p><p>  其实这就跟生活中的情形很像，比如你问一个朋友的工资是多少，他说你猜？那就很难了，他说你猜完我告诉你是猜高了还是猜低了，这样你就可以奔着对的方向一直猜下去，最后总会猜对！梯度下降法就是这样的，多次尝试。并且，在试的过程中还得想办法知道是不是在猜对的路上，说白了就是得到正确的反馈再调整然后继续猜才有意义~</p><p>  这个就好比道士下山，我们把 Loss （或者称为Cost，即损失）曲线看成是<strong>山谷</strong>，如果走过了，就再 往回返，所以是一个迭代的过程。</p><h4 id="1-3、梯度下降公式">1.3、梯度下降公式</h4><p>  这里梯度下降法的公式就是一个式子指导计算机迭代过程中如何去调整$\theta$，可以通过泰勒公式一阶展开来进行推导和证明：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/680d3e456f084caa87d35c55ece68b98.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/680d3e456f084caa87d35c55ece68b98.png" alt="image.png"></a></p><p>  这里的 $w_j$ 就是 $\theta$ 中的某一个 j = 0…m，这里的 $\eta$ 就是梯度下降图里的 learning step，很多时候也叫学习率 learning rate，很多时候也用 $\alpha$ 表示，这个学习率我们可以看作是下山迈的<strong>步子</strong>的大小，步子迈的大下山就快。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/22d31ba2d7c348bca74593141837f569.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/22d31ba2d7c348bca74593141837f569.jpeg" alt="image.png"></a></p><p>  学习率一般都是<strong>正数</strong>，如果在山左侧（曲线<strong>左半边</strong>）梯度是负的，那么这个负号就会把 $w_j$ 往大了调， 如果在山右侧（曲线右半边）梯度就是正的，那么负号就会把 $w_j$ 往小了调。每次 $w_j$ 调整的幅度就是 $\eta * gradient$，就是横轴上移动的距离。</p><p>  因此，无论在左边，还是在右边，梯度下降都可以快速找到最优解，实现快速<strong>下山</strong>~</p><p>  如果特征或维度越多，那么这个公式用的次数就越多，也就是每次迭代要应用的这个式子多次（多少特征，就应用多少次），所以其实上面的图不是特别准，因为 $\theta$ 对应的是很多维度，应该每一个维度都可以画一个这样的图，或者是一个多维空间的图。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/66ce3adba54149a382512476bf1da237.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/66ce3adba54149a382512476bf1da237.png" alt="image.png"></a></p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/9f2ec32dd16d40ceb75d032cbe6d3ea9.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/9f2ec32dd16d40ceb75d032cbe6d3ea9.jpeg" alt="image.png"></a></p><p>  所以观察上图我们可以发现不是某一个 $\theta_0$ 或 $\theta_1$ 找到最小值就是最优解，而是它们一起找到 $J(\theta)$ 最小值才是最优解。</p><h4 id="1-4、学习率">1.4、学习率</h4><p>  根据我们上面讲的梯度下降公式，我们知道 $\eta$ 是学习率，设置大的学习率 $w_j$ 每次调整的幅度就大，设置小的学习率 $w_j$ 每次调整的幅度就小，然而如果步子迈的太大也会有问题，俗话说步子大了容易扯着蛋！学习率大，可能一下子迈过了，到另一边去了（从曲线左半边跳到右半边），继续梯度下降又迈回来， 使得来来回回震荡。步子太小呢，就像蜗牛一步步往前挪，也会使得整体迭代次数增加。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/83476c288f4d4e84951997fc776a8fa1.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/83476c288f4d4e84951997fc776a8fa1.jpeg" alt="image.png"></a></p><p>  学习率的设置是门一门学问，一般我们会把它设置成一个比较小的正整数，0.1、0.01、0.001、0.0001，都是常见的设定数值（然后根据情况调整）。一般情况下学习率在整体迭代过程中是不变，但是也可以设置成随着迭代次数增多学习率逐渐变小，因为越靠近山谷我们就可以步子迈小点，可以更精准的走入最低点，同时防止走过。还有一些深度学习的优化算法会自己控制调整学习率这个值，后面学习过程中这些策略在讲解代码中我们会一一讲到。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/c782a1c81fb240c89ef39bf55d74d3e1.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/c782a1c81fb240c89ef39bf55d74d3e1.jpeg" alt="image.png"></a></p><h4 id="1-5、全局最优化">1.5、全局最优化</h4><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/7d59daf9da474ef9b1716191f47064c8.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/7d59daf9da474ef9b1716191f47064c8.png" alt="image.png"></a></p><p>上图显示了梯度下降的两个主要挑战：</p><ul><li>若随机初始化，算法从左侧起步，那么会收敛到一个局部最小值，而不是全局最小值；</li><li>若随机初始化，算法从右侧起步，那么需要经过很长时间才能越过Plateau（函数停滞带，梯度很小），如果停下得太早，则永远达不到全局最小值；</li></ul><p>  而线性回归的模型MSE损失函数恰好是个凸函数，凸函数保证了只有一个全局最小值，其次是个连续函数，斜率不会发生陡峭的变化，因此即便是乱走，梯度下降都可以趋近全局最小值。</p><p>  上图损失函数是非凸函数，梯度下降法是有可能落到局部最小值的，所以其实步长不能设置的太小太稳健，那样就很容易落入局部最优解，虽说局部最小值也没大问题， 因为模型只要是<strong>堪用</strong>的就好嘛，但是我们肯定还是尽量要奔着全局最优解去！</p><h4 id="1-6、梯度下降步骤">1.6、梯度下降步骤</h4><p>梯度下降流程就是“猜”正确答案的过程:</p><ul><li><p>1、“瞎蒙”，Random 随机数生成  $\theta$，随机生成一组数值 $w_0、w_1……w_n$ ，期望 $\mu$ 为 0 方差 $\sigma$ 为 1 的正太分布数据。</p></li><li><p>2、求梯度 g ，梯度代表曲线某点上的切线的斜率，沿着切线往下就相当于沿着坡度最陡峭的方向下降</p></li><li><p>3、if  g &lt; 0, $\theta$  变大，if g &gt; 0, $\theta$ 变小</p></li><li><p>4、判断是否收敛，如果收敛跳出迭代，如果没有达到收敛，回第 2 步再次执行2~4步</p><p>收敛的判断标准是：随着迭代进行损失函数Loss，变化非常微小甚至不再改变，即认为达到收敛</p></li></ul><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/51536cae3e524a419ab6feff64e5df31.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/51536cae3e524a419ab6feff64e5df31.jpeg" alt="image.png"></a></p><h4 id="1-7、代码模拟梯度下降">1.7、代码模拟梯度下降</h4><ul><li><p>梯度下降优化算法，比正规方程，应用更加广泛</p></li><li><p>什么是梯度？</p><ul><li>梯度就是导数对应的值！</li></ul></li><li><p>下降？</p><ul><li>涉及到优化问题，最小二乘法</li></ul></li><li><p>梯度下降呢？</p><ul><li>梯度方向下降，速度最快的~</li></ul></li></ul><p>  接下来，我们使用代码来描述上面梯度下降的过程：</p><p>方程如下：</p><p>$f(x) = (x - 3.5)^2 - 4.5x + 10$</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/9d04508431a94e4f9a54bed4c6e01dc8.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/9d04508431a94e4f9a54bed4c6e01dc8.jpg" alt="image.png"></a></p><p>使用梯度下降的思想，来一步步逼近，函数的最小值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">f = <span class="keyword">lambda</span> x : (x - <span class="number">3.5</span>)**<span class="number">2</span> -<span class="number">4.5</span>*x + <span class="number">10</span></span><br><span class="line"><span class="comment"># 导函数</span></span><br><span class="line">d = <span class="keyword">lambda</span> x :<span class="number">2</span>*(x - <span class="number">3.5</span>) - <span class="number">4.5</span> <span class="comment"># 梯度 == 导数</span></span><br><span class="line"><span class="comment"># 梯度下降的步幅，比例，（学习率，幅度）</span></span><br><span class="line">step = <span class="number">0.1</span></span><br><span class="line"><span class="comment"># 求解当x等于多少的时候，函数值最小。求解目标值：随机生成的</span></span><br><span class="line"><span class="comment"># 相等于：&#x27;瞎蒙&#x27; ----&gt; 方法 ----&gt; 优化</span></span><br><span class="line">x = np.random.randint(<span class="number">0</span>,<span class="number">12</span>,size = <span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 梯度下降，每下降一步，每走一步，目标值，都会更新。</span></span><br><span class="line"><span class="comment"># 更新的这个新值和上一步的值，差异，如果差异很小（万分之一）</span></span><br><span class="line"><span class="comment"># 梯度下降退出</span></span><br><span class="line">last_x = x + <span class="number">0.02</span> <span class="comment"># 记录上一步的值，首先让last_x和x有一定的差异！！！</span></span><br><span class="line"><span class="comment"># 精确率，真实计算，都是有误差，自己定义</span></span><br><span class="line">precision = <span class="number">1e-4</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;+++++++++++++++++++++&#x27;</span>, x)</span><br><span class="line">x_ = [x]</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># 退出条件，精确度，满足了</span></span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">abs</span>(x - last_x) &lt; precision:</span><br><span class="line">        <span class="keyword">break</span>   </span><br><span class="line">    <span class="comment"># 更新</span></span><br><span class="line">    last_x = x</span><br><span class="line">    x -= step*d(x) <span class="comment"># 更新，减法：最小值</span></span><br><span class="line">    x_.append(x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;--------------------&#x27;</span>,x)</span><br><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;Kaiti SC&#x27;</span></span><br><span class="line">plt.figure(figsize=(<span class="number">9</span>,<span class="number">6</span>))</span><br><span class="line">x = np.linspace(<span class="number">5.75</span> - <span class="number">5</span>, <span class="number">5.75</span> + <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">y = f(x)</span><br><span class="line">plt.plot(x,y,color = <span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;梯度下降&#x27;</span>,size = <span class="number">24</span>,pad = <span class="number">15</span>)</span><br><span class="line">x_ = np.array(x_)</span><br><span class="line">y_ = f(x_)</span><br><span class="line">plt.scatter(x_, y_,color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;./图片/5-梯度下降.jpg&#x27;</span>,dpi = <span class="number">200</span>)</span><br></pre></td></tr></table></figure><p>函数的最优解是：<strong>5.75</strong>。你可以发现，随机赋值的变量 x ，无论<strong>大于</strong>5.75，还是<strong>小于</strong>5.75，经过梯度下降，最终都慢慢靠近5.75这个最优解！</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/c3a7bf82304d4cd990306bccc9e33e98.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/c3a7bf82304d4cd990306bccc9e33e98.jpg" alt="image.png"></a></p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/29a4d4047fa24ea495f55630a6c6d174.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/29a4d4047fa24ea495f55630a6c6d174.jpg" alt="image.png"></a></p><p><strong>注意：</strong></p><ol><li>梯度下降存在一定误差，不是完美解~</li><li>在误差允许的范围内，梯度下降所求得的机器学习模型，是堪用的！</li><li>梯度下降的步幅step，不能太大，俗话说步子不能迈的太大！</li><li>精确度，可以根据实际情况调整</li><li>while True循环里面，持续进行梯度下降：</li></ol><p>   $\theta = \theta - \eta \frac{\partial}{\partial \theta}J(\theta)$ 其中的 $\eta $ 叫做学习率</p><p>  $x = x - \eta\frac{\partial}{\partial x}f(x)$</p><p>  $x = x - step*\frac{\partial}{\partial x} f(x)$ 其中的 $step $ 叫做学习率</p><p>  $x = x - step * f’(x)$</p><ol start="6"><li>while 循环退出条件是：x更新之后和上一次相差绝对值小于特定精确度！</li></ol><h3 id="2、梯度下降方法">2、梯度下降方法</h3><h4 id="2-1、三种梯度下降不同">2.1、三种梯度下降不同</h4><p>梯度下降分三类：批量梯度下降BGD（<strong>Batch Gradient Descent</strong>）、小批量梯度下降MBGD（<strong>Mini-Batch Gradient Descent</strong>）、随机梯度下降SGD（<strong>Stochastic Gradient Descent</strong>）。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/83b78948c0074a17b4334e1ca691b8fc.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/83b78948c0074a17b4334e1ca691b8fc.jpeg" alt="image.png"></a></p><p>三种梯度下降有什么不同呢？我们从梯度下降步骤开始讲起，梯度下降步骤分一下四步：</p><ul><li><p>1、随机赋值，Random 随机数生成  $\theta$，随机一组数值 $w_0、w_1……w_n$</p></li><li><p>2、求梯度 g ，梯度代表曲线某点上的切线的斜率，沿着切线往下就相当于沿着坡度最陡峭的方向下降</p></li><li><p>3、if  g &lt; 0, $\theta$  变大，if g &gt; 0, $\theta$ 变小</p></li><li><p>4、判断是否收敛 convergence，如果收敛跳出迭代，如果没有达到收敛，回第 2 步再次执行2~4步</p><p>收敛的判断标准是：随着迭代进行损失函数Loss，变化非常微小甚至不再改变，即认为达到收敛</p></li></ul><p>三种梯度下降不同，体现在第二步中：</p><ul><li>BGD是指在<strong>每次迭代</strong>使用<strong>所有样本</strong>来进行梯度的更新</li><li>MBGD是指在<strong>每次迭代</strong>使用<strong>一部分样本</strong>（所有样本500个，使用其中32个样本）来进行梯度的更新</li><li>SGD是指<strong>每次迭代</strong>随机选择<strong>一个样本</strong>来进行梯度更新</li></ul><h4 id="2-2、线性回归梯度更新公式">2.2、线性回归梯度更新公式</h4><p>回顾上一讲公式！</p><p>最小二乘法公式如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/49c3dfaf8c4b4a54ab80a7e51f90cfa6.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/49c3dfaf8c4b4a54ab80a7e51f90cfa6.png" alt="image.png"></a></p><p>矩阵写法：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/670e2e063398461e9143ae13b7c4709a.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/670e2e063398461e9143ae13b7c4709a.png" alt="image.png"></a></p><p>接着我们来讲解如何求解上面梯度下降的第 2 步，即我们要推导出损失函数的导函数来。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/038487f53e8f4c47af75de156a2e98c4.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/038487f53e8f4c47af75de156a2e98c4.png" alt="image.png"></a></p><p>  $x^2$的导数就是 2x，根据链式求导法则，我们可以推出上面第（1）步。然后是多元线性回归，所以 $h_{\theta}(x)$ 就 是 $\theta^Tx$ 即是$w_0x_0 + w_1x_1 + …… + w_nx_n$ 即$\sum\limits_{i = 0}^n\theta_ix_i$。到这里我们是对 $\theta_j$ 来求偏导，那么和 $w_j$ 没有关系的可以忽略不计，所以只剩下 $x_j$。</p><p>  我们可以得到结论就是 $\theta_j$ 对应的梯度与预测值 $\hat{y}$ 和真实值 y 有关，这里 $\hat{y}$ 和 y 是列向量（即多个数据），同时还与 $\theta_j$ 对应的特征维度 $x_j$ 有关，这里 $x_j$ 是原始数据集矩阵的第 j 列。如果我们分别去对每个维度 $\theta_0、\theta_1……\theta_n$ 求偏导，即可得到所有维度对应的梯度值。</p><ul><li>$g_0 = (h_{\theta}(x) - y)x_0$</li><li>$g_1 = (h_{\theta}(x) - y)x_1$</li><li>……</li><li>$g_j = (h_{\theta}(x) - y)x_j$</li></ul><p><strong>总结：</strong></p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/1e745bd465d542cc8593e12977a6cb26.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/1e745bd465d542cc8593e12977a6cb26.png" alt="image.png"></a></p><h4 id="2-3、批量梯度下降BGD">2.3、批量梯度下降BGD</h4><p>  <strong>批量梯度下降法</strong>是最原始的形式，它是指在<strong>每次迭代</strong>使用<strong>所有样本</strong>来进行梯度的更新。每次迭代参数更新公式如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/bd716fec62c2485e831263b5d84f8197.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/bd716fec62c2485e831263b5d84f8197.png" alt="image.png"></a></p><p>去掉 $\frac{1}{n}$ 也可以，因为它是一个常量，可以和 $\eta$  合并</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/52e7aec970ae4be887f2b6eb059e5a54.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/52e7aec970ae4be887f2b6eb059e5a54.png" alt="image.png"></a></p><p>矩阵写法：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/f983d092c8914a60876c80853bd08b43.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/f983d092c8914a60876c80853bd08b43.png" alt="image.png"></a></p><p>其中 𝑖 = 1, 2, …, n 表示样本数， 𝑗 = 0, 1……表示特征数，<strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。</p><p><strong>注意这里更新时存在一个求和函数，即为对所有样本进行计算处理！</strong></p><p><strong>优点：</strong><br>  （1）一次迭代是对所有样本进行计算，此时利用矩阵进行操作，实现了并行。<br>  （2）由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。当目标函数为凸函数时，BGD一定能够得到全局最优。<br><strong>缺点：</strong><br>  （1）当样本数目 n 很大时，每迭代一步都需要对所有样本计算，训练过程会很慢。</p><p>从迭代的次数上来看，BGD迭代的次数相对较少。其迭代的收敛曲线示意图可以表示如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/b23d78b73e8c4a88813c02917ff33853.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/b23d78b73e8c4a88813c02917ff33853.jpeg" alt="image.png"></a></p><h4 id="2-4、随机梯度下降SGD">2.4、随机梯度下降SGD</h4><p><strong>随机梯度下降法</strong>不同于批量梯度下降，随机梯度下降是<strong>每次迭代</strong>使用<strong>一个样本</strong>来对参数进行更新。使得训练速度加快。每次迭代参数更新公式如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/4e0a2d7309a2482882c7c641014a98af.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/4e0a2d7309a2482882c7c641014a98af.png" alt="image.png"></a></p><p><strong>批量梯度下降</strong>算法每次都会使用<strong>全部</strong>训练样本，因此这些计算是冗余的，因为每次都使用完全相同的样本集。而<strong>随机梯度下降</strong>算法每次只随机选择<strong>一个</strong>样本来更新模型参数，因此每次的学习是非常快速的。</p><p><strong>优点：</strong><br>  （1）由于不是在全部训练数据上的更新计算，而是在每轮迭代中，随机选择一条数据进行更新计算，这样每一轮参数的更新速度大大加快。<br>  <strong>缺点：</strong><br>  （1）准确度下降。由于即使在目标函数为强凸函数的情况下，SGD仍旧无法做到线性收敛。<br>  （2）可能会收敛到局部最优，由于单个样本并不能代表全体样本的趋势。</p><p><strong>解释一下为什么SGD收敛速度比BGD要快：</strong><br>  * 这里我们假设有30W个样本，对于BGD而言，每次迭代需要计算30W个样本才能对参数进行一次更新，需要求得最小值可能需要多次迭代（假设这里是10）。<br>  * 而对于SGD，每次更新参数只需要一个样本，因此若使用这30W个样本进行参数更新，则参数会被迭代30W次，而这期间，SGD就能保证能够收敛到一个合适的最小值上了。<br>  * 也就是说，在收敛时，BGD计算了 10×30W 次，而SGD只计算了 1×30W 次。</p><p>从迭代的次数上来看，SGD迭代的次数较多，在解空间的搜索过程就会盲目一些。其迭代的收敛曲线示意图可以表示如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/25e11b29bcdc48df880924c7e75c1b16.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/25e11b29bcdc48df880924c7e75c1b16.jpeg" alt="image.png"></a></p><h4 id="2-5、小批量梯度下降MBGD">2.5、小批量梯度下降MBGD</h4><p><strong>小批量梯度下降</strong>，是对批量梯度下降以及随机梯度下降的一个<strong>折中</strong>办法。其思想是：<strong>每次迭代</strong>使用总样本中的一部分（batch_size）样本来对参数进行更新。这里我们假设 batch_size = 32，样本数 n = 1000 。实现了更新速度与更新次数之间的平衡。每次迭代参数更新公式如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/608f1025518842188c8c47350e5e8ce8.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/608f1025518842188c8c47350e5e8ce8.png" alt="image.png"></a></p><p>相对于随机梯度下降算法，小批量梯度下降算法降低了收敛波动性， 即降低了参数更新的方差，使得更新更加稳定。相对于全量梯度下降，其提高了每次学习的速度。并且其不用担心内存瓶颈从而可以利用矩阵运算进行高效计算。</p><p>一般情况下，小批量梯度下降是梯度下降的推荐变体，特别是在深度学习中。每次随机选择2的幂数个样本来进行学习，例如：8、16、32、64、128、256。因为计算机的结构就是二进制的。但是也要根据具体问题而选择，实践中可以进行多次试验， 选择一个更新速度与更次次数都较适合的样本数。</p><p>MBGD梯度下降迭代的收敛曲线更加温柔一些：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/fa690fe760284383b198810802e82995.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/fa690fe760284383b198810802e82995.jpeg" alt="image.png"></a></p><h4 id="2-6、梯度下降优化">2.6、梯度下降优化</h4><p>虽然梯度下降算法效果很好，并且广泛使用，但是不管用上面三种哪一种，都存在一些挑战与问题，我们可以从以下几点进行优化:</p><ol><li><p>选择一个合理的学习速率很难。如果学习速率过小，则会导致收敛速度很慢。如果学习速率过大，那么其会阻碍收敛，即在极值点附近会振荡。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/0bbe5b04ddf24a78a71c4700cbde90a5.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/0bbe5b04ddf24a78a71c4700cbde90a5.jpeg" alt="image.png"></a></p></li><li><p>学习速率调整，试图在每次更新过程中， 改变学习速率。从经验上看，**学习率在一开始要保持大些来保证收敛速度，在收敛到最优点附近时要小些以避免来回震荡。**比较简单的学习率调整可以通过 **学习率衰减（Learning Rate Decay）**的方式来实现。假设初始化学习率为 $\eta_0$，在第 t 次迭代时的学习率 $\eta_t$。常用的衰减方式为可以设置为 <strong>按迭代次数</strong> 进行衰减，迭代次数越大，学习率越小！<br><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/da9eec25972249f1a587a10d5723320f.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/da9eec25972249f1a587a10d5723320f.jpeg" alt="image.png"></a></p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/def103855dc34212bd5cfda1686a73bb.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/def103855dc34212bd5cfda1686a73bb.jpeg" alt="image.png"></a></p></li><li><p>模型所有的参数每次更新都是使用相同的学习速率。如果数据特征是稀疏的，或者每个特征有着不同的统计特征与空间，那么便不能在每次更新中每个参数使用相同的学习速率，那些很少出现的特征应该使用一个相对较大的学习速率。<a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/f95707a6d51948c3a6aa7fcb61b5c055.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/f95707a6d51948c3a6aa7fcb61b5c055.jpg" alt="image.png"></a></p></li><li><p>对于非凸目标函数，容易陷入那些次优的局部极值点中，如在神经网路中。那么如何避免呢。<a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/ab1758d6f7504c128eee9bdb71045e4d.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652339399091/ab1758d6f7504c128eee9bdb71045e4d.png" alt="image.png"></a></p><p>简单的问题，一般使用随机梯度下降即可解决。在深度学习里，对梯度下降进行了很多改进，比如：自适应梯度下降。在深度学习章节，我们会具体介绍。</p></li><li><p>轮次和批次</p><p>轮次：epoch，轮次顾名思义是把我们已有的训练集数据学习多少轮，迭代多少次。</p><p>批次：batch，批次这里指的的我们已有的训练集数据比较多的时候，一轮要学习太多数据， 那就把一轮次要学习的数据分成多个批次，一批一批数据的学习。</p><p>就好比，你要背诵一片《赤壁赋》，很长。你在背诵的时候，一段段的背诵，就是批次batch。花费了一天终于背诵下来了，以后的9天，每天都进行一轮背诵复习，这就是轮次epoch。这样，《赤壁赋》的背诵效果，就非常牢固了。</p><p>在进行，机器学习训练时，我们也要合理选择轮次和批次~</p></li></ol><h3 id="3、代码实战梯度下降">3、代码实战梯度下降</h3><h4 id="3-1、批量梯度下降BGD">3.1、批量梯度下降BGD</h4><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。一元一次线性回归问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = np.random.rand(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">w,b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">2</span>)</span><br><span class="line">y = w * X  + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、使用偏置项x_0 = 1，更新X</span></span><br><span class="line">X = np.c_[X,np.ones((<span class="number">100</span>, <span class="number">1</span>))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、创建超参数轮次</span></span><br><span class="line">epoches = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、定义一个函数来调整学习率，逆时衰减</span></span><br><span class="line">t0, t1 = <span class="number">5</span>, <span class="number">1000</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">learning_rate_schedule</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="keyword">return</span> t0/(t+t1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、初始化 W0...Wn，标准正太分布创建W</span></span><br><span class="line">θ = np.random.randn(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、判断是否收敛，一般不会去设定阈值，而是直接采用设置相对大的迭代次数保证可以收敛</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoches):</span><br><span class="line">    <span class="comment"># 根据公式计算梯度</span></span><br><span class="line">    g = X.T.dot(X.dot(θ) - y)</span><br><span class="line">    <span class="comment"># 应用梯度下降的公式去调整 θ 值</span></span><br><span class="line">    learning_rate = learning_rate_schedule(i)</span><br><span class="line">    θ = θ - learning_rate * g</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实斜率和截距是：&#x27;</span>,w,b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;梯度下降计算斜率和截距是：&#x27;</span>,θ)</span><br></pre></td></tr></table></figure><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。多元一次线性回归问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = np.random.rand(<span class="number">100</span>, <span class="number">3</span>)</span><br><span class="line">w = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = (<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line">y = X.dot(w)  + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、使用偏置项x_0 = 1，更新X</span></span><br><span class="line">X = np.c_[X,np.ones((<span class="number">100</span>, <span class="number">1</span>))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、创建超参数轮次</span></span><br><span class="line">epoches = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、定义一个函数来调整学习率</span></span><br><span class="line">t0, t1 = <span class="number">5</span>, <span class="number">500</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">learning_rate_schedule</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="keyword">return</span> t0/(t+t1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、初始化 W0...Wn，标准正太分布创建W</span></span><br><span class="line">θ = np.random.randn(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、判断是否收敛，一般不会去设定阈值，而是直接采用设置相对大的迭代次数保证可以收敛</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoches):</span><br><span class="line">    <span class="comment"># 根据公式计算梯度</span></span><br><span class="line">    g = X.T.dot(X.dot(θ) - y)</span><br><span class="line">    <span class="comment"># 应用梯度下降的公式去调整 θ 值</span></span><br><span class="line">    learning_rate = learning_rate_schedule(i)</span><br><span class="line">    θ = θ - learning_rate * g</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实斜率和截距是：&#x27;</span>,w,b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;梯度下降计算斜率和截距是：&#x27;</span>,θ)</span><br></pre></td></tr></table></figure><h4 id="3-2、随机梯度下降SGD">3.2、随机梯度下降SGD</h4><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。一元一次线性回归问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = <span class="number">2</span>*np.random.rand(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">w,b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">2</span>)</span><br><span class="line">y = w * X + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、使用偏置项x_0 = 1，更新X</span></span><br><span class="line">X = np.c_[X, np.ones((<span class="number">100</span>, <span class="number">1</span>))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、创建超参数轮次、样本数量</span></span><br><span class="line">epochs = <span class="number">10000</span></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、定义一个函数来调整学习率</span></span><br><span class="line">t0, t1 = <span class="number">5</span>, <span class="number">500</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">learning_rate_schedule</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="keyword">return</span> t0/(t+t1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、初始化 W0...Wn，标准正太分布创建W</span></span><br><span class="line">θ = np.random.randn(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、多次for循环实现梯度下降，最终结果收敛</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># 在双层for循环之间，每个轮次开始分批次迭代之前打乱数据索引顺序</span></span><br><span class="line">    index = np.arange(n) <span class="comment"># 0 ~99</span></span><br><span class="line">    np.random.shuffle(index)</span><br><span class="line">    X = X[index] <span class="comment"># 打乱顺序</span></span><br><span class="line">    y = y[index]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        X_i = X[[i]]</span><br><span class="line">        y_i = y[[i]]</span><br><span class="line">        g = X_i.T.dot(X_i.dot(θ)-y_i)</span><br><span class="line">        learning_rate = learning_rate_schedule(epoch*n + i)</span><br><span class="line">        θ = θ - learning_rate * g</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实斜率和截距是：&#x27;</span>,w,b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;梯度下降计算斜率和截距是：&#x27;</span>,θ)</span><br></pre></td></tr></table></figure><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。多元一次线性回归问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = <span class="number">2</span>*np.random.rand(<span class="number">100</span>, <span class="number">5</span>)</span><br><span class="line">w = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = (<span class="number">5</span>,<span class="number">1</span>))</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line">y = X.dot(w) + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、使用偏置项x_0 = 1，更新X</span></span><br><span class="line">X = np.c_[X, np.ones((<span class="number">100</span>, <span class="number">1</span>))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、创建超参数轮次、样本数量</span></span><br><span class="line">epochs = <span class="number">10000</span></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、定义一个函数来调整学习率</span></span><br><span class="line">t0, t1 = <span class="number">5</span>, <span class="number">500</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">learning_rate_schedule</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="keyword">return</span> t0/(t+t1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、初始化 W0...Wn，标准正太分布创建W</span></span><br><span class="line">θ = np.random.randn(<span class="number">6</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、多次for循环实现梯度下降，最终结果收敛</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># 在双层for循环之间，每个轮次开始分批次迭代之前打乱数据索引顺序</span></span><br><span class="line">    index = np.arange(n) <span class="comment"># 0 ~99</span></span><br><span class="line">    np.random.shuffle(index)</span><br><span class="line">    X = X[index] <span class="comment"># 打乱顺序</span></span><br><span class="line">    y = y[index]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        X_i = X[[i]]</span><br><span class="line">        y_i = y[[i]]</span><br><span class="line">        g = X_i.T.dot(X_i.dot(θ)-y_i)</span><br><span class="line">        learning_rate = learning_rate_schedule(epoch*n + i)</span><br><span class="line">        θ = θ - learning_rate * g</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实斜率和截距是：&#x27;</span>,w,b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;梯度下降计算斜率和截距是：&#x27;</span>,θ)</span><br></pre></td></tr></table></figure><h4 id="3-3、小批量梯度下降MBGD">3.3、小批量梯度下降MBGD</h4><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。一元一次线性回归问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = np.random.rand(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">w,b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">2</span>)</span><br><span class="line">y = w * X + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、使用偏置项x_0 = 1，更新X</span></span><br><span class="line">X = np.c_[X, np.ones((<span class="number">100</span>, <span class="number">1</span>))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、定义一个函数来调整学习率</span></span><br><span class="line">t0, t1 = <span class="number">5</span>, <span class="number">500</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">learning_rate_schedule</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="keyword">return</span> t0/(t+t1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、创建超参数轮次、样本数量、小批量数量</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">num_batches = <span class="built_in">int</span>(n / batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、初始化 W0...Wn，标准正太分布创建W</span></span><br><span class="line">θ = np.random.randn(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、多次for循环实现梯度下降，最终结果收敛</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># 在双层for循环之间，每个轮次开始分批次迭代之前打乱数据索引顺序</span></span><br><span class="line">    index = np.arange(n)</span><br><span class="line">    np.random.shuffle(index)</span><br><span class="line">    X = X[index]</span><br><span class="line">    y = y[index]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">        <span class="comment"># 一次取一批数据16个样本</span></span><br><span class="line">        X_batch = X[i * batch_size : (i + <span class="number">1</span>)*batch_size]</span><br><span class="line">        y_batch = y[i * batch_size : (i + <span class="number">1</span>)*batch_size]</span><br><span class="line">        g = X_batch.T.dot(X_batch.dot(θ)-y_batch)</span><br><span class="line">        learning_rate = learning_rate_schedule(epoch * n + i)</span><br><span class="line">        θ = θ - learning_rate * g</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实斜率和截距是：&#x27;</span>,w,b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;梯度下降计算斜率和截距是：&#x27;</span>,θ)</span><br></pre></td></tr></table></figure><p><strong>这里我们使用了偏置项，即解决$x_0^{(i)} = 1$</strong>。多元一次线性回归问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = np.random.rand(<span class="number">100</span>, <span class="number">3</span>)</span><br><span class="line">w = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = (<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line">y = X.dot(w) + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、使用偏置项 X_0 = 1，更新X</span></span><br><span class="line">X = np.c_[X, np.ones((<span class="number">100</span>, <span class="number">1</span>))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、定义一个函数来调整学习率</span></span><br><span class="line">t0, t1 = <span class="number">5</span>, <span class="number">500</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">learning_rate_schedule</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="keyword">return</span> t0/(t+t1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、创建超参数轮次、样本数量、小批量数量</span></span><br><span class="line">epochs = <span class="number">10000</span></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">num_batches = <span class="built_in">int</span>(n / batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、初始化 W0...Wn，标准正太分布创建W</span></span><br><span class="line">θ = np.random.randn(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、多次for循环实现梯度下降，最终结果收敛</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># 在双层for循环之间，每个轮次开始分批次迭代之前打乱数据索引顺序</span></span><br><span class="line">    index = np.arange(n)</span><br><span class="line">    np.random.shuffle(index)</span><br><span class="line">    X = X[index]</span><br><span class="line">    y = y[index]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">        <span class="comment"># 一次取一批数据16个样本</span></span><br><span class="line">        X_batch = X[i * batch_size : (i + <span class="number">1</span>)*batch_size]</span><br><span class="line">        y_batch = y[i * batch_size : (i + <span class="number">1</span>)*batch_size]</span><br><span class="line">        g = X_batch.T.dot(X_batch.dot(θ)-y_batch)</span><br><span class="line">        learning_rate = learning_rate_schedule(epoch * n + i)</span><br><span class="line">        θ = θ - learning_rate * g</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实斜率和截距是：&#x27;</span>,w,b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;梯度下降计算斜率和截距是：&#x27;</span>,θ)</span><br></pre></td></tr></table></figure></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;
&lt;h2 id=&quot;梯度下降&quot;&gt;梯度下降&lt;/h2&gt;
&lt;h3 id=&quot;线性回归预测房价&quot;&gt;线性回归预测房价&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://0914ds.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>多元线性回归</title>
    <link href="https://0914ds.github.io/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>https://0914ds.github.io/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</id>
    <published>2023-08-17T05:13:16.000Z</published>
    <updated>2023-08-17T17:12:30.799Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><meta name="referrer" content="no-referrer"><h2 id="多元线性回归">多元线性回归</h2><h3 id="1、基本概念">1、基本概念</h3><p>​    线性回归是机器学习中<strong>有监督</strong>机器学习下的一种算法。 <strong>回归问题</strong>主要关注的是<strong>因变量</strong>(需要预测的值，可以是一个也可以是多个)和一个或多个数值型的<strong>自变量</strong>(预测变量)之间的关系。</p><p>需要预测的值:即目标变量，target，y，<strong>连续值</strong>预测变量。</p><p>影响目标变量的因素：$X_1$…$X_n$，可以是连续值也可以是离散值。</p><p>因变量和自变量之间的关系:即<strong>模型</strong>，model，是我们要求解的。</p><h4 id="1-1、连续值">1.1、连续值</h4><p><a href="b.png" title="b" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//b.png" alt="b"></a></p><h4 id="1-2、离散值">1.2、离散值</h4><p><a href="a.png" title="a" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//a.png" alt="a"></a></p><h4 id="1-3、简单线性回归">1.3、简单线性回归</h4><p>前面提到过，算法说白了就是公式，简单线性回归属于一个算法，它所对应的公式。</p><p>$$y = wx + b$$</p><p>这个公式中，y 是目标变量即未来要预测的值，x 是影响 y 的因素，w,b 是公式上的参数即要求的模型。其实 b 就是咱们的截距，w 就是斜率嘛！ 所以很明显如果模型求出来了，未来影响 y 值的未知数就是一个 x 值，也可以说影响 y 值 的因素只有一个，所以这是就叫<strong>简单</strong>线性回归的原因。</p><p>同时可以发现从 x 到 y 的计算，x 只是一次方，所以这是算法叫<strong>线性</strong>回归的原因。 其实，大家上小学时就已经会解这种一元一次方程了。为什么那个时候不叫人工智能算法呢？因为人工智能算法要求的是最优解！</p><h4 id="1-4、最优解">1.4、最优解</h4><p>Actual value:<strong>真实值</strong>，一般使用 y 表示。</p><p>Predicted value:<strong>预测值</strong>，是把已知的 x 带入到公式里面和<strong>猜</strong>出来的参数 w,b 计算得到的，一般使用 $\hat{y}$ 表示。</p><p>Error:<strong>误差</strong>，预测值和真实值的差距，一般使用 $\varepsilon$ 表示。</p><p><strong>最优解</strong>:尽可能的找到一个模型使得整体的误差最小，整体的误差通常叫做损失 Loss。</p><p>Loss:整体的误差，Loss 通过损失函数 Loss function 计算得到。</p><p><a href="c.png" title="c" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//c.png" alt="c"></a></p><h4 id="1-5、多元线性回归">1.5、多元线性回归</h4><p>现实生活中，往往影响结果 y 的因素不止一个，这时 x 就从一个变成了 n 个，$x_1$…$x_n$ 同时简单线性回归的公式也就不在适用了。<strong>多元线性回归</strong>公式如下：</p><p>$\hat{y} = w_1x_1 + w_2x_2 + …… + w_nx_n + b$</p><p>b是截距，也可以使用$w_0$来表示</p><p>$\hat{y} = w_1x_1 + w_2x_2 + …… + w_nx_n + w_0$</p><p>$\hat{y} = w_1x_1 + w_2x_2 + …… + w_nx_n + w_0 * 1$</p><p>使用向量来表示，$\vec{X}$表示所有的变量，是一维向量；$\vec{W}$表示所有的系数（包含$w_0$），是一维向量，根据向量乘法规律，可以这么写：</p><p>$\hat{y} = W^TX$【默认情况下，向量都是列向量】</p><p><a href="d.png" title="d" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//d.png" alt="d"></a></p><h3 id="2、正规方程">2、正规方程</h3><h4 id="2-1、最小二乘法矩阵表示">2.1、最小二乘法矩阵表示</h4><p><strong>最小二乘法</strong>可以将误差方程转化为有确定解的<strong>代数方程组</strong>（其方程式数目正好等于未知数的个数），从而可求解出这些未知参数。这个有确定解的代数方程组称为最小二乘法估计的<strong>正规方程</strong>。公式如下：</p><p>$\theta = (X^TX)^{-1}X^Ty$ 或者 $W = (X^TX)^{-1}X^Ty$ ，其中的$W、\theta$ 即使方程的解！</p><p><a href="e.png" title="e" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//e.png" alt="e"></a></p><p>公式是如何<strong>推导</strong>的？</p><p>最小二乘法公式如下：</p><p>$J(\theta) = \frac{1}{2}\sum\limits_{i = 0}^n(h_{\theta}(x_i) - y_i)^2$</p><p>使用矩阵表示：</p><p><a href="f.png" title="f" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//f.png" alt="f"></a></p><p>之所以要使用转置T，是因为，矩阵运算规律是：矩阵A的一行乘以矩阵B的一列！</p><p><a href="g.png" title="g" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//g.png" alt="g"></a></p><h4 id="2-2、多元一次方程举例">2.2、多元一次方程举例</h4><p>1、二元一次方程</p><p><a href="h.png" title="h" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//h.png" alt="h"></a></p><p>2、三元一次方程</p><p><a href="i.png" title="i" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//i.png" alt="i"></a></p><p>3、八元一次方程</p><p><a href="j.png" title="j" class="gallery-item" style="box-shadow: none;"> <img src="/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92//j.png" alt="j"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上面八元一次方程对应的X数据</span></span><br><span class="line">X = np.array([[  <span class="number">0</span> ,<span class="number">14</span> , <span class="number">8</span> ,  <span class="number">0</span> ,  <span class="number">5</span>,  -<span class="number">2</span>,   <span class="number">9</span>,  -<span class="number">3</span>],</span><br><span class="line"> [ -<span class="number">4</span> , <span class="number">10</span> ,  <span class="number">6</span> ,  <span class="number">4</span> ,-<span class="number">14</span> , -<span class="number">2</span> ,-<span class="number">14</span>  , <span class="number">8</span>],</span><br><span class="line"> [ -<span class="number">1</span> , -<span class="number">6</span>  , <span class="number">5</span> ,-<span class="number">12</span> ,  <span class="number">3</span> , -<span class="number">3</span> ,  <span class="number">2</span> , -<span class="number">2</span>],</span><br><span class="line"> [  <span class="number">5</span> , -<span class="number">2</span>  , <span class="number">3</span> , <span class="number">10</span>  , <span class="number">5</span> , <span class="number">11</span> ,  <span class="number">4</span>  ,-<span class="number">8</span>],</span><br><span class="line"> [-<span class="number">15</span> ,-<span class="number">15</span>  ,-<span class="number">8</span> ,-<span class="number">15</span> ,  <span class="number">7</span> , -<span class="number">4</span>, -<span class="number">12</span> ,  <span class="number">2</span>],</span><br><span class="line"> [ <span class="number">11</span> ,-<span class="number">10</span> , -<span class="number">2</span> ,  <span class="number">4</span>  , <span class="number">3</span> , -<span class="number">9</span> , -<span class="number">6</span> ,  <span class="number">7</span>],</span><br><span class="line"> [-<span class="number">14</span> ,  <span class="number">0</span> ,  <span class="number">4</span> , -<span class="number">3</span>  , <span class="number">5</span> , <span class="number">10</span> , <span class="number">13</span> ,  <span class="number">7</span>],</span><br><span class="line"> [ -<span class="number">3</span> , -<span class="number">7</span> , -<span class="number">2</span> , -<span class="number">8</span>  , <span class="number">0</span> , -<span class="number">6</span> , -<span class="number">5</span> , -<span class="number">9</span>]])</span><br><span class="line"><span class="comment"># 对应的y</span></span><br><span class="line">y = np.array([ <span class="number">339</span> ,-<span class="number">114</span>  , <span class="number">30</span> , <span class="number">126</span>, -<span class="number">395</span> , -<span class="number">87</span> , <span class="number">422</span>, -<span class="number">309</span>])</span><br><span class="line">display(X,y)</span><br></pre></td></tr></table></figure><h4 id="2-3、矩阵转置公式与求导公式：">2.3、矩阵转置公式与求导公式：</h4><p><strong>转置公式如下：</strong></p><ul><li>$(mA)^T = mA^T$，其中m是常数</li><li>$(A + B)^T = A^T + B^T$</li><li>$(AB)^T = B^TA^T$</li><li>$(A^T)^T = A$</li></ul><p><strong>求导公式如下：</strong></p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f8edeac442294ed5a1ab4a03f0de6cfe.png" title="f8edeac442294ed5a1ab4a03f0de6cfe" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f8edeac442294ed5a1ab4a03f0de6cfe.png" alt="f8edeac442294ed5a1ab4a03f0de6cfe"></a></p><h4 id="2-4、推导正规方程-theta-的解：">2.4、推导正规方程 $\theta$ 的解：</h4><ol><li><strong>矩阵乘法公式展开</strong></li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/77b1210b3bfa43cca35b0e3a79565c83.png" title="77b1210b3bfa43cca35b0e3a79565c83" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/77b1210b3bfa43cca35b0e3a79565c83.png" alt="77b1210b3bfa43cca35b0e3a79565c83"></a></p><ol start="2"><li><strong>进行求导（注意X、y是已知量，$\theta$ 是未知数）：</strong></li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/7a36e5110d1246a9b535921c2c943b16.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/7a36e5110d1246a9b535921c2c943b16.png" alt="image.png"></a></p><p>根据<strong>2.3、矩阵转置公式与求导公式</strong>可知</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/c58118e586de408aa3ab7f5e28566a24.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/c58118e586de408aa3ab7f5e28566a24.png" alt="image.png"></a></p><ol start="3"><li><strong>根据上面求导公式进行运算：</strong></li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/81180de05e0e44fab748f77ec5b45365.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/81180de05e0e44fab748f77ec5b45365.png" alt="image.png"></a></p><ol start="4"><li><strong>令导数$J’(\theta) = 0：$</strong></li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/3934cd63cbf1444fb836cf3d5e70fe64.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/3934cd63cbf1444fb836cf3d5e70fe64.png" alt="image.png"></a></p><ol start="5"><li><strong>矩阵没有除法，使用逆矩阵进行转化：</strong></li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/56641d424c9945a2a8452708cd8e27b3.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/56641d424c9945a2a8452708cd8e27b3.png" alt="image.png"></a></p><p>到此为止，公式推导出来了~</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/98a7d8c20ba14fa1867937e75d1e29b7.gif" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/98a7d8c20ba14fa1867937e75d1e29b7.gif" alt="image.png"></a></p><h4 id="2-5、凸函数判定">2.5、凸函数判定</h4><p>判定损失函数是凸函数的好处在于我们可能很肯定的知道我们求得的极值即最优解，一定是全局最优解。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/fb6a9e9787304b58b096720379e9421f.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/fb6a9e9787304b58b096720379e9421f.png" alt="image.png"></a></p><p>如果是非凸函数，那就不一定可以获取全局最优解~</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f60f1e2ea73148719cf19a255044a975.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f60f1e2ea73148719cf19a255044a975.png" alt="image.png"></a></p><p>来一个更加立体的效果图：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/9822098f45bf4b4fa37eb859d361cce6.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/9822098f45bf4b4fa37eb859d361cce6.png" alt="image.png"></a></p><p>判定凸函数的方式: 判定凸函数的方式非常多，其中一个方法是看<strong>黑塞矩阵</strong>是否是<strong>半正定</strong>的。</p><p>黑塞矩阵(hessian matrix)是由目标函数在点 X 处的二阶偏导数组成的对称矩阵。</p><p>对于我们的式子来说就是在导函数的基础上再次对θ来求偏导，结果就是 $X^TX$。所谓正定就是 $X^TX$ 的特征值全为正数，半正定就是 $X^TX$ 的特征值大于等于 0， 就是半正定。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/eda2806b9e5246e4bae439711efa5f55.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/eda2806b9e5246e4bae439711efa5f55.png" alt="image.png"></a></p><p>这里我们对 $J(\theta)$ 损失函数求二阶导数的黑塞矩阵是 $X^TX$ ，得到的一定是半正定的，自己和自己做点乘嘛！</p><p>这里不用数学推导证明这一点。在机器学习中往往损失函数都是<strong>凸函数</strong>，到<strong>深度学习</strong>中损失函数往往是<strong>非凸函数</strong>，即找到的解<strong>未必</strong>是全局最优，只要模型堪用就好！机器学习特点是：不强调模型 100% 正确，只要是有价值的，堪用的，就Okay！</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/b8d27b44461d447b8a0a4fda0f87f22f.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/b8d27b44461d447b8a0a4fda0f87f22f.jpeg" alt="image.png"></a></p><h3 id="3、线性回归算法推导">3、线性回归算法推导</h3><p><a href="https://blog.csdn.net/Soft_Po/article/details/118731058">最小二乘推导</a></p><h4 id="3-1、深入理解回归">3.1、深入理解回归</h4><p><strong>回归</strong>简单来说就是“回归平均值”(regression to the mean)。但是这里的 mean 并不是把 历史数据直接当成未来的预测值，而是会把期望值当作预测值。 追根溯源<strong>回归</strong>这个词是一个叫高尔顿的人发明的，他通过大量观察数据发现:父亲比较高，儿子也比较高；父亲比较矮，那么儿子也比较矮！正所谓“龙生龙凤生凤老鼠的儿子会打洞”！但是会存在一定偏差~</p><p>父亲是 1.98，儿子肯定很高，但有可能不会达到1.98<br>父亲是 1.69，儿子肯定不高，但是有可能比 1.69 高</p><p>大自然让我们<strong>回归</strong>到一定的区间之内，这就是<strong>大自然神奇</strong>的力量。</p><p>高尔顿是谁？<strong>达尔文</strong>的表弟，这下可以相信他说的十有八九是<strong>对的</strong>了吧！</p><p>人类社会很多事情都被大自然这种神奇的力量只配置：身高、体重、智商、相貌……</p><p>这种神秘的力量就叫<strong>正态分布</strong>。大数学家高斯，深入研究了正态分布，最终推导出了线性回归的原理：<strong>最小二乘法</strong>！</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/b187c8d76451404fb86d799444d0e950.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/b187c8d76451404fb86d799444d0e950.jpg" alt="image.png"></a></p><p>接下来，我们跟着高斯的足迹继续向下走~</p><h4 id="3-2、误差分析">3.2、误差分析</h4><p>误差 $\varepsilon_i$ 等于第 i 个样本实际的值 $y_i$ 减去预测的值 $\hat{y}$ ，公式可以表达为如下：</p><p>$\varepsilon_i = |y_i - \hat{y}|$</p><p>$\varepsilon_i = |y_i - W^Tx_i|$</p><p>假定所有的样本的误差都是<strong>独立的</strong>，有上下的震荡，震荡认为是随机变量，足够多的随机变量叠加之后形成的分布，它服从的就是正态分布，因为它是正常状态下的分布，也就是高斯分布！<strong>均值</strong>是某一个值，<strong>方差</strong>是某一个值。 方差我们先不管，均值我们总有办法让它去等于零 0 的，因为我们这里是有截距b， 所有误差我们就可以认为是独立分布的，1&lt;=i&lt;=n，服从均值为 0，方差为某定值的<strong>高斯分布</strong>。机器学习中我们<strong>假设</strong>误差符合均值为0，方差为定值的正态分布！！！</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/17e2809b4c85410e948cffe3643ad34d.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/17e2809b4c85410e948cffe3643ad34d.jpeg" alt="image.png"></a></p><h4 id="3-3、最大似然估计">3.3、最大似然估计</h4><p>最大似然估计(maximum likelihood estimation, MLE)一种重要而普遍的求估计量的方法。<strong>最大似然估计</strong>明确地使用概率模型，其目标是寻找能够以较高概率产生观察数据的系统发生树。最大似然估计是一类完全基于<strong>统计</strong>的系统发生树重建方法的代表。</p><p>是不是，有点看不懂，<strong>太学术</strong>了，我们举例说明~</p><p>假如有一个罐子，里面有<strong>黑白</strong>两种颜色的球，数目多少不知，两种颜色的<strong>比例</strong>也不知。我们想知道罐中白球和黑球的比例，但我们<strong>不能</strong>把罐中的球全部拿出来数。现在我们可以每次任意从已经<strong>摇匀</strong>的罐中拿一个球出来，<strong>记录</strong>球的颜色，然后把拿出来的球再<strong>放回</strong>罐中。这个过程可以<strong>重复</strong>，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例<strong>最有可能</strong>是多少？</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/5c0148f54cc344b6baec29a716498990.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/5c0148f54cc344b6baec29a716498990.jpeg" alt="image.png"></a></p><p>请告诉我答案！</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/b5c23fbbefd84607abd1c614c68313e1.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/b5c23fbbefd84607abd1c614c68313e1.jpeg" alt="image.png"></a></p><p>很多小伙伴，甚至不用算，凭感觉，就能给出答案：<strong>70%</strong>！</p><p><strong>下面是详细推导过程：</strong></p><ul><li><p>最大似然估计，计算</p></li><li><p>白球概率是p，黑球是1-p（罐子中非黑即白）</p></li><li><p>罐子中取一个请问是白球的概率是多少？</p><p>$$<br>p<br>$$</p></li><li><p>罐子中取两个球，两个球都是白色，概率是多少？</p><p>$$<br>p^2<br>$$</p></li><li><p>罐子中取5个球都是白色，概率是多少？</p><p>$$<br>p^5<br>$$</p></li><li><p>罐子中取10个球，9个是白色，一个是黑色，概率是多少呢？</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/71a9684cd4564aef96591431bbaa1a27.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/71a9684cd4564aef96591431bbaa1a27.jpeg" alt="image.png"></a></p><ul><li>$C_{10}^1 = C_{10}^1$ 这个两个排列组合公式是<strong>相等的</strong>~</li><li>$$<br>C_{10}^9p^9(1-p) = C_{10}^1p^9(1-p)<br>$$</li></ul></li><li><p>罐子取100个球，70次是白球，30次是黑球，概率是多少？</p></li><li><p>$$<br>P = C_{100}^{30}p^{70}(1-p)^{30}<br>$$</p></li><li><p>最大似然估计，什么时候P最大呢？</p><p>$C_{100}^{30}$是常量，可以<strong>去掉</strong>！</p><p>p &gt; 0，1- p &gt; 0，所以上面概率想要求最大值，那么求<strong>导数</strong>即可！</p></li><li><p>$$<br>P’ = 70<em>p^{69}</em>(1-p)^{30} + p^{70}<em>30</em>(1-p)^{29}*(-1)<br>$$</p><p><strong>令导数为0：</strong></p></li><li><p>$$<br>0 = 70<em>p^{69}</em>(1-p)^{30} +p^{70}<em>30</em>(1-p)^{29}*(-1)<br>$$</p><p><strong>公式化简：</strong></p></li><li><p>$$<br>0 = 70*(1-p) - p*30<br>$$</p></li><li><p>$$<br>0 = 70 - 100*p<br>$$</p></li><li><p><strong>p = 70%</strong></p></li></ul><h4 id="3-4、高斯分布-概率密度函数">3.4、高斯分布-概率密度函数</h4><p>最常见的连续概率分布是<strong>正态分布</strong>，也叫<strong>高斯分布</strong>，而这正是我们所需要的，其概率密度函数如下:</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f6bddf6943174fc88718cdad4cc3ce7e.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f6bddf6943174fc88718cdad4cc3ce7e.jpeg" alt="image.png"></a></p><p>公式如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/4b353b48bba34cf9820ddcad0ef9548b.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/4b353b48bba34cf9820ddcad0ef9548b.png" alt="image.png"></a></p><p>随着参数μ和σ<strong>变化</strong>，概率分布也产生变化。 下面重要的步骤来了，我们要把一组数据误差出现的<strong>总似然</strong>，也就是一组数据之所以对应误差出现的<strong>整体可能性</strong>表达出来了，因为数据的误差我们假设服从一个高斯分布，并且通过<strong>截距</strong>项来平移整体分布的位置从而使得<strong>μ=0</strong>，所以样本的误差我们可以表达其概率密度函数的值如下:</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/c1e8d58d707c4d65ba03cc873204f8d3.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/c1e8d58d707c4d65ba03cc873204f8d3.png" alt="image.png"></a></p><p><strong>简化</strong>如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/8270a090b4fa4cbeb6cdc7214211c213.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/8270a090b4fa4cbeb6cdc7214211c213.png" alt="image.png"></a></p><h4 id="3-5、误差总似然">3.5、误差总似然</h4><p>和前面黑球白球问题<strong>类似</strong>，也是一个<strong>累乘</strong>问题~</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/d9636ac44e0f48fdac68b382c4f219c0.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/d9636ac44e0f48fdac68b382c4f219c0.png" alt="image.png"></a></p><p>根据前面公式$\varepsilon_i = |y_i - W^Tx_i|$可以推导出来如下公式：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f1b113438f234395b9524456a89c7006.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f1b113438f234395b9524456a89c7006.png" alt="image.png"></a></p><p>公式中的<strong>未知变量</strong>就是$W^T$，即方程的系数，系数包含截距~如果，把上面当成一个方程，就是概率P关于W的方程！其余符号，都是常量！</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/1a4d510c461b478bac25f6abdbc68e5e.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/1a4d510c461b478bac25f6abdbc68e5e.png" alt="image.png"></a></p><p>现在问题，就变换成了，求<strong>最大似然</strong>问题了！不过，等等~</p><p>累乘的最大似然，求解是非常麻烦的！</p><p>接下来，我们通过，求<strong>对数</strong>把<strong>累乘</strong>问题，转变为<strong>累加</strong>问题（加法问题，无论多复杂，都难不倒我了！）</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/a9518e4542fa44668535a7e33809239c.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/a9518e4542fa44668535a7e33809239c.jpeg" alt="image.png"></a></p><h4 id="3-6、最小二乘法MSE">3.6、最小二乘法MSE</h4><p>$P_W = \prod\limits_{i = 0}^{n}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y_i - W^Tx_i)^2}{2\sigma^2}}$</p><p>根据对数，单调性，对上面公式求自然底数e的对数，效果不变~</p><p>$log_e(P_W) = log_e(\prod\limits_{i = 0}^{n}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y_i - W^Tx_i)^2}{2\sigma^2}})$</p><p>接下来 log 函数继续为你带来惊喜，数学上连乘是个大麻烦，即使交给计算机去求解它也得<strong>哭出声来</strong>。惊喜是:</p><ul><li>$log_a(XY) = log_aX + log_aY$</li><li>$log_a\frac{X}{Y} = log_aX - log_aY$</li><li>$log_aX^n = n*log_aX$</li><li>$log_a(X_1X_2……X_n) = log_aX_1 + log_aX_2 + …… + log_aX_n$</li><li>$log_xx^n = n(n\in R)$</li><li>$log_a\frac{1}{X} = -log_aX$</li><li>$log_a\sqrt[x]{N^y} = \frac{y}{x}log_aN$</li></ul><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/5a0de92b4e974103b61936748a72bd88.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/5a0de92b4e974103b61936748a72bd88.png" alt="image.png"></a></p><p><strong>乘风破浪，继续推导—&gt;</strong></p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/10425befead44d74a162d56db3586232.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/10425befead44d74a162d56db3586232.png" alt="image.png"></a></p><p>上面公式是最大似然求对数后的变形，其中$\pi、\sigma$都是常量，而$(y_i - W^Tx_i)^2$肯定大于<strong>零</strong>！上面求最大值问题，即可转变为如下求<strong>最小值</strong>问题：</p><p>$L(W) = \frac{1}{2}\sum\limits_{i = 0}^n(y^{(i)} - W^Tx^{(i)})^2$   L代表Loss，表示损失函数，损失函数<strong>越小</strong>，那么上面最大似然就<strong>越大</strong>~</p><p>有的书本上公式，也可以这样写，用$J(\theta)$表示一个意思，$\theta$ 的角色就是W：</p><p>$J(\theta) = \frac{1}{2}\sum\limits_{i = 1}^n(y^{(i)} - \theta^Tx^{(i)})^2 = \frac{1}{2}\sum\limits_{i = 1}^n(\theta^Tx^{(i)} - y^{(i)})^2$</p><p><strong>进一步提取：</strong></p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/9cd20d0c4c8548e0be72f2e5899f24cc.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/9cd20d0c4c8548e0be72f2e5899f24cc.png" alt="image.png"></a></p><p>其中：</p><p>$\hat{y} = h_{\theta}(X) =X \theta$ 表示全部数据，是矩阵，X表示多个数据，进行矩阵乘法时，放在前面</p><p>$\hat{y}<em>i = h</em>{\theta}(x^{(i)}) = \theta^Tx^{(i)}$ 表示第i个数据，是向量，所以进行乘法时，其中一方需要转置</p><p>因为最大似然公式中有个<strong>负号</strong>，所以最大总似然变成了<strong>最小化</strong>负号后面的部分。 到这里，我们就已经推导出来了 MSE 损失函数$J(\theta)$，从公式我们也可以看出来 MSE 名字的来 历，mean squared error，上式也叫做最小二乘法！</p><h4 id="3-7、归纳总结升华">3.7、归纳总结升华</h4><p>这种最小二乘法估计，其实我们就可以认为，假定了误差服从正太分布，认为样本误差的出现是随机的，独立的，使用最大似然估计思想，利用损失函数最小化 MSE 就能求出最优解！所以反过来说，如果我们的数据误差不是互相独立的，或者不是随机出现的，那么就不适合去假设为正太分布，就不能去用正太分布的概率密度函数带入到总似然的函数中，故而就不能用 MSE 作为损失函数去求解最优解了！所以，最小二乘法不是万能的~</p><p>还有譬如假设误差服从泊松分布，或其他分布那就得用其他分布的概率密度函数去推导出损失函数了。</p><p>所以有时我们也可以把线性回归看成是广义线性回归。比如，逻辑回归，泊松回归都属于广义线性回归的一种，这里我们线性回归可以说是最小二乘线性回归。</p><h3 id="4、线性回归实战">4、线性回归实战</h3><h4 id="4-1、使用正规方程进行求解">4.1、使用正规方程进行求解</h4><h5 id="4-1-1、简单线性回归">4.1.1、简单线性回归</h5><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/739367b9a160496c9545b6d3aa157527.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/739367b9a160496c9545b6d3aa157527.png" alt="image.png"></a></p><p>一元一次方程，在机器学习中一元表示一个特征，b表示截距，y表示目标值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 转化成矩阵</span></span><br><span class="line">X = np.linspace(<span class="number">0</span>,<span class="number">10</span>,num = <span class="number">30</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 斜率和截距，随机生成</span></span><br><span class="line">w = np.random.randint(<span class="number">1</span>,<span class="number">5</span>,size = <span class="number">1</span>)</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 根据一元一次方程计算目标值y，并加上“噪声”，数据有上下波动~</span></span><br><span class="line">y = X * w + b + np.random.randn(<span class="number">30</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(X,y)</span><br><span class="line"><span class="comment"># 重新构造X，b截距，相当于系数w0，前面统一乘以1</span></span><br><span class="line">X = np.concatenate([X,np.full(shape = (<span class="number">30</span>,<span class="number">1</span>),fill_value= <span class="number">1</span>)],axis = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 正规方程求解</span></span><br><span class="line">θ = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y).<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;一元一次方程真实的斜率和截距是：&#x27;</span>,w, b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;通过正规方程求解的斜率和截距是：&#x27;</span>,θ)</span><br><span class="line"><span class="comment"># 根据求解的斜率和截距绘制线性回归线型图</span></span><br><span class="line">plt.plot(X[:,<span class="number">0</span>],X.dot(θ),color = <span class="string">&#x27;green&#x27;</span>)</span><br></pre></td></tr></table></figure><p>效果如下（random.randn是随机生成正太分布数据，所以每次执行图形会有所不同）：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/e8786d05d012485ea92c2f26bd67679e.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/e8786d05d012485ea92c2f26bd67679e.jpg" alt="image.png"></a></p><h5 id="4-1-2、多元线性回归">4.1.2、多元线性回归</h5><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/59b917be60864200a61f60b3388cca1d.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/59b917be60864200a61f60b3388cca1d.png" alt="image.png"></a></p><p>二元一次方程，$x_1、x_2$ 相当于两个特征，b是方程截距</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d.axes3d <span class="keyword">import</span> Axes3D <span class="comment"># 绘制三维图像</span></span><br><span class="line"><span class="comment"># 转化成矩阵</span></span><br><span class="line">x1 = np.random.randint(-<span class="number">150</span>,<span class="number">150</span>,size = (<span class="number">300</span>,<span class="number">1</span>))</span><br><span class="line">x2 = np.random.randint(<span class="number">0</span>,<span class="number">300</span>,size = (<span class="number">300</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 斜率和截距，随机生成</span></span><br><span class="line">w = np.random.randint(<span class="number">1</span>,<span class="number">5</span>,size = <span class="number">2</span>)</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 根据二元一次方程计算目标值y，并加上“噪声”，数据有上下波动~</span></span><br><span class="line">y = x1 * w[<span class="number">0</span>] + x2 * w[<span class="number">1</span>] + b + np.random.randn(<span class="number">300</span>,<span class="number">1</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">9</span>,<span class="number">6</span>))</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.scatter(x1,x2,y) <span class="comment"># 三维散点图</span></span><br><span class="line">ax.view_init(elev=<span class="number">10</span>, azim=-<span class="number">20</span>) <span class="comment"># 调整视角</span></span><br><span class="line"><span class="comment"># 重新构造X，将x1、x2以及截距b，相当于系数w0，前面统一乘以1进行数据合并</span></span><br><span class="line">X = np.concatenate([x1,x2,np.full(shape = (<span class="number">300</span>,<span class="number">1</span>),fill_value=<span class="number">1</span>)],axis = <span class="number">1</span>)</span><br><span class="line">w = np.concatenate([w,b])</span><br><span class="line"><span class="comment"># 正规方程求解</span></span><br><span class="line">θ = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y).<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;二元一次方程真实的斜率和截距是：&#x27;</span>,w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;通过正规方程求解的斜率和截距是：&#x27;</span>,θ.reshape(-<span class="number">1</span>))</span><br><span class="line"><span class="comment"># # 根据求解的斜率和截距绘制线性回归线型图</span></span><br><span class="line">x = np.linspace(-<span class="number">150</span>,<span class="number">150</span>,<span class="number">100</span>)</span><br><span class="line">y = np.linspace(<span class="number">0</span>,<span class="number">300</span>,<span class="number">100</span>)</span><br><span class="line">z = x * θ[<span class="number">0</span>] + y * θ[<span class="number">1</span>] + θ[<span class="number">2</span>]</span><br><span class="line">ax.plot(x,y,z ,color = <span class="string">&#x27;red&#x27;</span>)</span><br></pre></td></tr></table></figure><p>效果如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/b7615df8b1624df78b5168fc58a66475.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/b7615df8b1624df78b5168fc58a66475.jpg" alt="image.png"></a></p><h4 id="4-2、机器学习库scikit-learn">4.2、机器学习库scikit-learn</h4><h5 id="4-2-1、scikit-learn简介">4.2.1、<a href="https://scikit-learn.org/stable/index.html">scikit-learn简介</a></h5><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/e813979dfefc4f0caaed58f922d6d587.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/e813979dfefc4f0caaed58f922d6d587.jpeg" alt="image.png"></a></p><h5 id="4-2-2、scikit-learn实现简单线性回归">4.2.2、scikit-learn实现简单线性回归</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 转化成矩阵</span></span><br><span class="line">X = np.linspace(<span class="number">0</span>,<span class="number">10</span>,num = <span class="number">30</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 斜率和截距，随机生成</span></span><br><span class="line">w = np.random.randint(<span class="number">1</span>,<span class="number">5</span>,size = <span class="number">1</span>)</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 根据一元一次方程计算目标值y，并加上“噪声”，数据有上下波动~</span></span><br><span class="line">y = X * w + b + np.random.randn(<span class="number">30</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(X,y)</span><br><span class="line"><span class="comment"># 使用scikit-learn中的线性回归求解</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(X,y)</span><br><span class="line">w_ = model.coef_</span><br><span class="line">b_ = model.intercept_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;一元一次方程真实的斜率和截距是：&#x27;</span>,w, b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;通过scikit-learn求解的斜率和截距是：&#x27;</span>,w_,b_)</span><br><span class="line">plt.plot(X,X.dot(w_) + b_,color = <span class="string">&#x27;green&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f06d7439704f4d2a95254d6be0222b36.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/f06d7439704f4d2a95254d6be0222b36.jpg" alt="image.png"></a></p><h5 id="4-2-3、scikit-learn实现多元线性回归">4.2.3、scikit-learn实现多元线性回归</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d.axes3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="comment"># 转化成矩阵</span></span><br><span class="line">x1 = np.random.randint(-<span class="number">150</span>,<span class="number">150</span>,size = (<span class="number">300</span>,<span class="number">1</span>))</span><br><span class="line">x2 = np.random.randint(<span class="number">0</span>,<span class="number">300</span>,size = (<span class="number">300</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 斜率和截距，随机生成</span></span><br><span class="line">w = np.random.randint(<span class="number">1</span>,<span class="number">5</span>,size = <span class="number">2</span>)</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 根据二元一次方程计算目标值y，并加上“噪声”，数据有上下波动~</span></span><br><span class="line">y = x1 * w[<span class="number">0</span>] + x2 * w[<span class="number">1</span>] + b + np.random.randn(<span class="number">300</span>,<span class="number">1</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">9</span>,<span class="number">6</span>))</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.scatter(x1,x2,y) <span class="comment"># 三维散点图</span></span><br><span class="line">ax.view_init(elev=<span class="number">10</span>, azim=-<span class="number">20</span>) <span class="comment"># 调整视角</span></span><br><span class="line"><span class="comment"># 重新构造X，将x1、x2以及截距b，相当于系数w0，前面统一乘以1进行数据合并</span></span><br><span class="line">X = np.concatenate([x1,x2],axis = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 使用scikit-learn中的线性回归求解</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(X,y)</span><br><span class="line">w_ = model.coef_.reshape(-<span class="number">1</span>)</span><br><span class="line">b_ = model.intercept_</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;二元一次方程真实的斜率和截距是：&#x27;</span>,w,b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;通过scikit-learn求解的斜率和截距是：&#x27;</span>,w_,b_)</span><br><span class="line"><span class="comment"># # 根据求解的斜率和截距绘制线性回归线型图</span></span><br><span class="line">x = np.linspace(-<span class="number">150</span>,<span class="number">150</span>,<span class="number">100</span>)</span><br><span class="line">y = np.linspace(<span class="number">0</span>,<span class="number">300</span>,<span class="number">100</span>)</span><br><span class="line">z = x * w_[<span class="number">0</span>] + y * w_[<span class="number">1</span>] + b_</span><br><span class="line">ax.plot(x,y,z ,color = <span class="string">&#x27;green&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/0066efeb6e5e4bfbaba999022d3009bd.jpg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1651232743056/0066efeb6e5e4bfbaba999022d3009bd.jpg" alt="image.png"></a></p></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;
&lt;h2 id=&quot;多元线性回归&quot;&gt;多元线性回归&lt;/h2&gt;
&lt;h3 id=&quot;1、基本概念&quot;&gt;1、基本概念&lt;/h3&gt;
&lt;p&gt;​    线</summary>
      
    
    
    
    <category term="机器学习" scheme="https://0914ds.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>梯度下降优化</title>
    <link href="https://0914ds.github.io/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BC%98%E5%8C%96/"/>
    <id>https://0914ds.github.io/2023/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BC%98%E5%8C%96/</id>
    <published>2023-08-16T17:30:16.000Z</published>
    <updated>2023-08-17T17:48:53.577Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><meta name="referrer" content="no-referrer"><h2 id="梯度下降优化">梯度下降优化</h2><h3 id="1、归一化-Normalization">1、归一化 Normalization</h3><h4 id="1-1、归一化目的">1.1、归一化目的</h4><p>  梯度下降的原理和应用，我们已经在前面课程中进行了学习，大家仔细观察下图。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/c361fdfa8946471c97c40e111bc4c17d.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/c361fdfa8946471c97c40e111bc4c17d.jpeg" alt="image.png"></a></p><p>  不同方向的<strong>陡峭度</strong>是不一样的，即不同维度的数值大小是不同。也就是说梯度下降的快慢是不同的：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/83a1603692cc44d4ab90672dc31b2fde.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/83a1603692cc44d4ab90672dc31b2fde.png" alt="image.png"></a></p><p> 如果维度多了，就是<strong>超平面</strong>（了解一下霍金所说的宇宙十一维空间），很难画出来了，感受一下下面这张图的空间维度情况。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/60843367a65a49dcb8f61bd689aa7e68.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/60843367a65a49dcb8f61bd689aa7e68.jpeg" alt="image.png"></a></p><p>  如果拿多元线性回归举例的话，因为多元线性回归的损失函数 MSE 是凸函数，所以我们可以把损失函数看成是一个碗。然后下面的图就是从碗上方去俯瞰！哪里是损失最小的地方呢？当然对应的就是碗底的地方！所以下图碗中心的地方颜色较浅的区域就是损失函数最小的地方。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/8577307ca13a44b29a344ed49bde7704.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/8577307ca13a44b29a344ed49bde7704.jpeg" alt="image.png"></a></p><p>  上面两张图都是进行梯度下降，你有没有发现，略有不同啊？两张图形都是鸟瞰图，左边的图形做了归一化处理，右边是没有做归一化的俯瞰图。</p><p>  啥是归一化呢？请带着疑问跟我走~</p><p>  我们先来说一下为什么没做归一化是右侧图示，举个例子假如我们客户数据信息，有两个维度，一个是用户的年龄，一个是用户的月收入，目标变量是快乐程度。</p><table><thead><tr><th style="text-align:center">name</th><th style="text-align:center">age</th><th style="text-align:center">salary</th><th style="text-align:center">happy</th></tr></thead><tbody><tr><td style="text-align:center">路博通</td><td style="text-align:center">36</td><td style="text-align:center">7000</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">马老师</td><td style="text-align:center">42</td><td style="text-align:center">20000</td><td style="text-align:center">180</td></tr><tr><td style="text-align:center">赵老师</td><td style="text-align:center">22</td><td style="text-align:center">30000</td><td style="text-align:center">164</td></tr><tr><td style="text-align:center">……</td><td style="text-align:center">……</td><td style="text-align:center">……</td><td style="text-align:center">……</td></tr></tbody></table><p>  我们可以里面写出线性回归公式， $y = \theta_1x_1 + \theta_2x_2 + b$ ，那么这样每一条样本不同维度对应的数量级不同，原因是每个维度对应的物理含义不同嘛，但是计算机能理解 36 和 7000 分别是年龄和收入吗？计算机只是拿到一堆数字而已。</p><p>  我们把 $x_1$ 看成是年龄，$x_2$ 看成是收入， y 对应着快乐程度。机器学习就是在知道 X，y的情况下解方程组调整出最优解的过程。根据公式我们也可以发现 y 是两部分贡献之和，按常理来说，一开始并不知道两个部分谁更重要的情况下，可以想象为两部分对 y 的贡献是一样的即 $\theta_1x_1 = \theta_2x_2$ ，如果 $x_1 \ll x_2$ ，那么最终 $\theta_1 \gg \theta_2$ （远大于）。</p><p>  这样是不是就比较好理解为什么之前右侧示图里为什么 $\theta_1 &gt; \theta_2$ ，看起来就是椭圆。再思考一下，梯度下降第 1 步的操作，是不是所有的维度 $\theta$ 都是根据在期望 $\mu$ 为 0 方差 $\sigma$ 为 1 的正太分布随机生成的，说白了就是一开始的 $\theta_1$ 和 $\theta_2$ 数值是差不多的。所以可以发现 $\theta_1$ 从初始值到目标位置 $\theta_1^{target}$ 的距离要远大于 $\theta_2$ 从初始值到目标位置$\theta_2^{target}$。</p><p>  因为 $x_1 \ll x_2$，根据梯度公式 $g_j= (h_{\theta}(x) - y)x_j$ ，得出 $g_1 \ll g_2$。根据梯度下降公式：$\theta_j^{n+1} = \theta_j^n - \eta * g_j$ 可知，每次调整 $\theta_1$ 的幅度 $\ll$ （远小于）  $\theta_2$ 的调整幅度。</p><p>  总结一下 ，根据上面得到的两个结论 ，它俩之间是互相矛盾的 ，意味着最后 $\theta_2$ 需要比 $\theta_1$ 更少的迭代次数就可以收敛，而我们要最终求得最优解，就必须每个维度 $\theta$ 都收敛才可以，所以会出现 $\theta_2$ 等待 $\theta_1$ 收敛的情况。讲到这里对应图大家应该可以理解为什么右图是先顺着 $\theta_2$ 的坐标轴往下走再往右走的原因了吧。</p><p><strong>结论:</strong></p><p>  归一化的一个目的是，使得梯度下降在不同维度 $\theta$ 参数（不同数量级）上，可以步调一致协同的进行梯度下降。这就好比社会主义，一小部分人先富裕起来了，先富带后富，这需要一定的时间，先富的这批人等待其他的人富裕起来；但是，更好途经是实现共同富裕，最后每个人都不能落下， 优化的步伐是一致的。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/46723e3f15054b108136b59fa0836252.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/46723e3f15054b108136b59fa0836252.jpeg" alt="image.png"></a></p><p>经过归一化处理，收敛的速度，明显快了！</p><h4 id="1-2、归一化本质">1.2、归一化本质</h4><p>  做归一化的目的是要实现<strong>共同富裕</strong>，而之所以梯度下降优化时不能达到步调一致的根本原因其实还是 $x_1$ 和 $x_2$ 的数量级不同。所以什么是归一化？</p><p>  答案自然就出来了，就是把 $x_1$ 和 $x_2$ 的数量级统一，扩展一点说，如果有更多特征维度，就要把各个特征维度 $x_1、x_2、……、x_n$ 的数量级统一，来做到无量纲化。</p><h4 id="1-3、最大值最小值归一化">1.3、最大值最小值归一化</h4><p>  也称为离差标准化，是对原始数据的线性变换，<strong>使结果值映射到[0 - 1]之间</strong>。转换函数如下：</p><p>$X^* = \frac{X - X_min}{X_max -X_min}$</p><p>  其实我们很容易发现使用最大值最小值归一化（min-max标准化）的时候，优点是一定可以把数值归一到 0 ~ 1 之间，缺点是如果有一个离群值（比如马云的财富），正如我们举的例子一样，会使得一个数值为 1，其它数值都几乎为 0，所以受离群值的影响比较大！</p><p><strong>代码演示：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x_1 = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">10</span>)</span><br><span class="line">x_2 = np.random.randint(<span class="number">100</span>,<span class="number">300</span>,size = <span class="number">10</span>)</span><br><span class="line">x = np.c_[x_1,x_2]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;归一化之前的数据：&#x27;</span>)</span><br><span class="line">display(x)</span><br><span class="line">x_ = (x - x.<span class="built_in">min</span>(axis = <span class="number">0</span>)) / (x.<span class="built_in">max</span>(axis = <span class="number">0</span>) - x.<span class="built_in">min</span>(axis = <span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;归一化之后的数据：&#x27;</span>)</span><br><span class="line">display(x_)</span><br></pre></td></tr></table></figure><p><strong>使用scikit-learn函数：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">x_1 = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">10</span>)</span><br><span class="line">x_2 = np.random.randint(<span class="number">100</span>,<span class="number">300</span>,size = <span class="number">10</span>)</span><br><span class="line">x = np.c_[x_1,x_2]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;归一化之前的数据：&#x27;</span>)</span><br><span class="line">display(x)</span><br><span class="line">min_max_scaler = MinMaxScaler()</span><br><span class="line">x_ = min_max_scaler.fit_transform(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;归一化之后的数据：&#x27;</span>)</span><br><span class="line">display(x_)</span><br></pre></td></tr></table></figure><h4 id="1-4、0-均值标准化">1.4、0-均值标准化</h4><p>  这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化，也叫做Z-score标准化。经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为：</p><p>$X^* = \frac{X - \mu}{\sigma}$</p><p>其中μ为所有样本数据的均值，σ为所有样本数据的标准差。</p><p>$\mu = \frac{1}{n}\sum\limits_{i = 1}^nx_i$</p><p>$\sigma = \sqrt{\frac{1}{n}\sum\limits_{i = 1}^n(x_i - \mu)^2}$</p><p>  相对于最大值最小值归一化来说，因为标准归一化除以了标准差，而标准差的计算会考虑到所有样本数据，所以受到离群值的影响会小一些，这就是除以方差的好处！但是，0-均值标准化不一定会把数据缩放到 0 ~ 1 之间了。既然是0均值，也就意味着，有正有负！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x_1 = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">10</span>)</span><br><span class="line">x_2 = np.random.randint(<span class="number">100</span>,<span class="number">300</span>,size = <span class="number">10</span>)</span><br><span class="line">x = np.c_[x_1,x_2]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;归一化之前的数据：&#x27;</span>)</span><br><span class="line">display(x)</span><br><span class="line">x_ = (x - x.mean(axis = <span class="number">0</span>)) / x.std(axis = <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;归一化之后的数据：&#x27;</span>)</span><br><span class="line">display(x_)</span><br></pre></td></tr></table></figure><p><strong>使用scikit-learn函数：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">x_1 = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">10</span>)</span><br><span class="line">x_2 = np.random.randint(<span class="number">100</span>,<span class="number">300</span>,size = <span class="number">10</span>)</span><br><span class="line">x = np.c_[x_1,x_2]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;归一化之前的数据：&#x27;</span>)</span><br><span class="line">display(x)</span><br><span class="line">standard_scaler = StandardScaler()</span><br><span class="line">x_ = standard_scaler.fit_transform(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;归一化之后的数据：&#x27;</span>)</span><br><span class="line">display(x_)</span><br></pre></td></tr></table></figure><p>  那为什么要减去均值呢？其实做均值归一化还有一个特殊的好处（对比最大值最小值归一化，全部是正数0~1），我们来看一下梯度下降的式子，你就会发现 $\alpha$ 是正数，不管 A 是正还是负（ A 就是 $\hat{y} - y = h_{\theta}(x) - y$），对于所有的维度 X，比如这里的 $x_1$ 和 $x_2$ 来说，$\alpha$ 乘上 A 都是一样的符号，那么每次迭代的时候 $w_1^{t+1}$ 和 $w_2^{t+1}$ 的更新幅度符号也必然是一样的，这样就会像下图有右侧所示：要想从 $w_t$ 更新到 $w^*$ 就必然要么 $w_1$ 和 $w_2$ 同时变大再同时变小，或者就 $w_1$ 和 $w_2$ 同时变小再同时变大。不能如图上所示蓝色的最优解路径，即 $w_1$ 变小的同时 $w_2$ 变大！</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/2cdaf2f432bb4e419ed2e690197df8b6.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/2cdaf2f432bb4e419ed2e690197df8b6.jpeg" alt="image.png"></a></p><p>  那我们如何才能做到让 $w_1$ 变小的时候 $w_2$ 变大呢？归其根本还是数据集 X 矩阵（经过min-max归一化）中的数据均为正数。所以如果我们可以让 $x_1$ 和 $x_2$ 它们符号不同，比如有正有负，其实就可以在做梯度下降的时候有更多的可能性去让更新尽可能沿着最优解路径去走。</p><p>  结论：<strong>0-均值标准化</strong>处理数据之后，属性有正有负，可以让梯度下降沿着最优路径进行~</p><p><strong>注意：</strong></p><p>  我们在做特征工程的时候，很多时候如果对训练集的数据进行了预处理，比如这里讲的归一化，那么未来对测试集的时候，和模型上线来新的数据的时候，都要进行<strong>相同的</strong>数据预处理流程，而且所使用的均值和方差是来自当时训练集的均值和方差!</p><p>  因为我们人工智能要干的事情就是从训练集数据中找规律，然后利用找到的规律去预测新产生的数据。这也就是说假设训练集和测试集以及未来新来的数据是属于同分布的！从代码上面来说如何去使用训练集的均值和方差呢？就需要把 scaler 对象持久化， 回头模型上线的时候再加载进来去对新来的数据进行处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(standard_scaler,<span class="string">&#x27;scale&#x27;</span>) <span class="comment"># 持久化</span></span><br><span class="line">standard_scaler = joblib.load(<span class="string">&#x27;scale&#x27;</span>) <span class="comment"># 加载</span></span><br><span class="line">standard_scaler.transform(x) <span class="comment"># 使用</span></span><br></pre></td></tr></table></figure><h3 id="2、正则化-Regularization">2、正则化 Regularization</h3><h4 id="2-1、过拟合欠拟合">2.1、过拟合欠拟合</h4><ol><li>欠拟合（under fit）：还没有拟合到位，训练集和测试集的准确率都还没有到达最高，学的还不到位。</li><li>过拟合（over fit）：拟合过度，训练集的准确率升高的同时，测试集的准确率反而降低。学的过度了（走火入魔），做过的卷子都能再次答对（死记硬背），考试碰到新的没见过的题就考不好（不会举一反三）。</li><li>恰到好处（just right）：过拟合前，训练集和测试集准确率都达到巅峰。好比，学习并不需要花费很多时间，理解的很好，考试的时候可以很好的把知识举一反三。</li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/793562d28f114fa5924bbcd3f6361786.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/793562d28f114fa5924bbcd3f6361786.jpeg" alt="image.png"></a></p><p>  正则化就是防止过拟合，增加模型的<strong>鲁棒性</strong>，鲁棒是 Robust 的音译，也就是强壮的意思。就像计算机软件在面临攻击、网络过载等情况下能够不死机不崩溃，这就是软件的鲁棒性。鲁棒性调优就是让模型拥有更好的鲁棒性，也就是让模型的泛化能力和推广 能力更加的强大。</p><p>  举例子说明：下面两个式子描述同一条直线那个更好？</p><p>$y = 0.3x_1 + 0.4x_2 + 0.5$</p><p>$y = 3x_1 + 4x_2 + 5$</p><p>  第一个更好，因为下面的公式是上面的十倍，当 w 越小公式的容错的能力就越好。因为把测试数据带入公式中如果测试集原来是 [32, 128] 在带入的时候发生了一些偏差，比如说变成 [30, 120] ，第二个模型结果就会比第一个模型结果的偏差大的多。公式中 $y = W^Tx$ ，当 x 有一点错误，这个错误会通过 w 放大。但是 w 不能太小，当 w 太小时（比如都趋近0），模型就没有意义了，无法应用。想要有一定的容错率又要保证正确率就要由正则项来发挥作用了！</p><p>  所以正则化(鲁棒性调优)的本质就是牺牲模型在训练集上的正确率来提高推广、泛化能力， W 在数值上越小越好，这样能抵抗数值的<strong>扰动</strong>。同时为了保证模型的正确率 W 又不能极小。 故而人们将原来的损失函数加上一个惩罚项，这里面损失函数就是原来固有的损失函数，比如回归的话通常是 MSE，分类的话通常是 cross entropy 交叉熵，然后在加上一部分惩罚项来使得计算出来的模型 W 相对小一些来带来泛化能力。</p><p>  常用的惩罚项有L1 正则项或者 L2 正则项：</p><ul><li>$L_1 = ||w||<em>1 = \sum\limits</em>{i = 1}^n|w_i|$              对应曼哈顿距离</li><li>$L_2 = ||w||<em>2 = \sqrt{\sum\limits</em>{i = 1}^n(w_i)^2}$        对应欧氏距离</li></ul><p>其实 L1 和 L2 正则的公式数学里面的意义就是范数，代表空间中向量到原点的距离：</p><p>$L_p = ||X||<em>p = \sqrt[p]{\sum\limits</em>{i = 1}^nx_i^p} , X = (x_1,x_2,……x_n)$</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/95727c537b1e41a39c1a698bae619d7d.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/95727c537b1e41a39c1a698bae619d7d.jpeg" alt="image.png"></a></p><p>  当我们把多元线性回归损失函数加上 L2 正则的时候，就诞生了 Ridge 岭回归。当我们把多元线性回归损失函数加上 L1 正则的时候，就孕育出来了 Lasso 回归。其实 L1 和 L2 正则项惩罚项可以加到任何算法的损失函数上面去提高计算出来模型的泛化能力的。</p><h4 id="2-2、套索回归（Lasso）">2.2、套索回归（Lasso）</h4><p>先从线性回归开始，其损失函数如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/3c449aa80d4d4b5cb02114ea1d347445.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/3c449aa80d4d4b5cb02114ea1d347445.png" alt="image.png"></a></p><p>L1正则化的损失函数，令$J_0 = J(\theta)$：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/bdb461ed1a6746258baf6fe48988627c.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/bdb461ed1a6746258baf6fe48988627c.png" alt="image.png"></a></p><p>令  $L_1 = \alpha * \sum\limits_{i = 1}^n|w_i|$ ：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/ac47115c4dcb437f8c96c799530a142d.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/ac47115c4dcb437f8c96c799530a142d.png" alt="image.png"></a></p><p>  其中 $J_0$ 是原始的损失函数，加号后面的一项是L1正则化项， $\alpha$ 是正则化系数。注意到 L1正则化是权值的绝对值之和。$J$ 是带有绝对值符号的函数，因此 $J$ 是不完全可微的。机器学习的任务就是要通过一些方法（比如梯度下降）求出损失函数的最小值。当我们在原始损失函数 $J_0$ 后面添加L1正则项时，相当于对 $J_0$ 做了一个约束。令$L_1 = \alpha * \sum\limits_{i = 1}^n|w_i|$ ，则 $J = J_0 + L_1$ ，此时我们的任务变成在 $L_1$ 约束下求出 $J_0$ 取最小值的解。<strong>考虑二维的情况</strong>，即只有两个权值 $w_1、w_2$ ，此时 $L_1 = |w_1| + |w_2|$。 对于梯度下降法，求解 $J_0$ 过程可以画出等值线，同时 L1 正则化的函数 $L_1$ 也可以在 $w_1、w_2$所在的平面上画出来：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/ebbe4decd1e7445c9df9085f85b26049.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/ebbe4decd1e7445c9df9085f85b26049.png" alt="image.png"></a></p><p>  图中等值线是$J_0$的等值线，是椭圆形。黑色方框是 $L_1$ 函数的图形，$L_1 = |w_1| + |w_2|$ 这个函数画出来，就是一个方框。</p><p>  在图中，当 $J_0$ 等值线与 $L_1$ 图形首次相交的地方就是最优解。上图中 $J_0$ 与 $L_1$ 在 $L_1$ 的一个顶点处相交，这个顶点就是最优解。注意到这个顶点的值是 $(w_1,w_2) = (0,w)$ 。可以直观想象，因为 $L_1$ 函数有很多『突出的角』（二维情况下四个，多维情况下更多）， $J_0$ 与这些角接触的机率会远大于与 $L_1$ 其它部位接触的机率（这是很直觉的想象，突出的角比直线的边离等值线更近写），而在这些角上，会有很多权值等于0（因为角就在坐标轴上），这就是为什么 L1 正则化可以产生稀疏模型（很多权重等于0了），进而可以用于特征选择。</p><p>  而正则化前面的系数 $\alpha$，可以控制 $L_1$ 图形的大小。$\alpha$ 越小，$L_1$ 的图形越大（上图中的黑色方框）；$\alpha$ 越大，$L_1$ 的图形就越小，可以小到黑色方框只超出原点范围一点点，这是最优解的值$(w_1,w_2) = (0,w)$ 中的 w 可以取到很小的值的原因所在。</p><p>代码演示 $\alpha$ 取值大小对黑色方框的尺寸影响：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># α 的值是：1</span></span><br><span class="line"><span class="comment"># 1 = x + y</span></span><br><span class="line"><span class="comment"># y = 1 -x</span></span><br><span class="line">f = <span class="keyword">lambda</span> x : <span class="number">1</span>- x</span><br><span class="line">x = np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;equal&#x27;</span>)</span><br><span class="line">plt.plot(x, f(x), color = <span class="string">&#x27;green&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># α 的值是：3</span></span><br><span class="line"><span class="comment"># 1 = 3 * x + 3 * y</span></span><br><span class="line"><span class="comment"># y = 1/3 -x</span></span><br><span class="line">f2 = <span class="keyword">lambda</span> x : <span class="number">1</span>/<span class="number">3</span> - x </span><br><span class="line">x2 = np.linspace(<span class="number">0</span>,<span class="number">1</span>/<span class="number">3</span>,<span class="number">100</span>)</span><br><span class="line">plt.plot(x2, f2(x2),color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一些列设置</span></span><br><span class="line">plt.xlim(-<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.ylim(-<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;None&#x27;</span>)  <span class="comment"># 将图片的右框隐藏</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;None&#x27;</span>)  <span class="comment"># 将图片的上边框隐藏</span></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>)) <span class="comment"># x轴出现在y轴的-1 位置</span></span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">plt.savefig(<span class="string">&#x27;./图片/13-alpha对方框影响.png&#x27;</span>,dpi = <span class="number">200</span>)</span><br></pre></td></tr></table></figure><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/36f894d8be794c7fb0cfd6655acc1e85.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/36f894d8be794c7fb0cfd6655acc1e85.png" alt="image.png"></a></p><p><strong>权重更新规则如下：</strong></p><ol><li>损失函数：</li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/873b8438cc4d46c39e88308f6fe63d6f.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/873b8438cc4d46c39e88308f6fe63d6f.png" alt="image.png"></a></p><ol start="2"><li>更新规则：</li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/deb751cc8eab47b0b620e2f8edae185c.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/deb751cc8eab47b0b620e2f8edae185c.png" alt="image.png"></a></p><p>其中 $J_0$ 即是线性回归的损失函数，$L_1$ 是添加的正则项。$sgn(w_i)$  表示符号函数、指示函数，值为：1 或 -1。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/18bf2efda1204dd08081f1cdc9198a0a.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/18bf2efda1204dd08081f1cdc9198a0a.png" alt="image.png"></a></p><p>注意当 $w_i = 0$ 时不可导。</p><p><strong>综上所述</strong>，L1正则化权重更新如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/05cfc081b4374d4aa32a3e76e5426f01.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/05cfc081b4374d4aa32a3e76e5426f01.png" alt="image.png"></a></p><ul><li>Lasso回归和线性回归相比，多了一项：$-\eta * \alpha * sgn(w_i)$</li><li>$\eta $ 大于零，表示梯度下降学习率</li><li>$\alpha$ 大于零，表示L1正则化系数</li><li>当$w_i$为正时候  $sgn(w_i) = 1$，直接减去 $\eta * \alpha$ （大于0），所以正的 $w_i$ 变小了</li><li>当$w_i$为负时候  $sgn(w_i) = -1$，相当于直接加上 $\eta * \alpha$ （大于0），所以负的 $w_i$ 变大了，绝对值变小，向0靠近</li></ul><p>有的书本上公式会这样写，其中 $\lambda$ 表示L1正则化系数：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/f271019eeee445a48346efbda1acca44.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/f271019eeee445a48346efbda1acca44.png" alt="image.png"></a></p><h4 id="2-3、岭回归（Ridge）">2.3、岭回归（Ridge）</h4><p>也是先从线性回归开始，其损失函数如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/1c5b0185a068410eb3f3c1a3f82f0c72.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/1c5b0185a068410eb3f3c1a3f82f0c72.png" alt="image.png"></a></p><p>L2正则化的损失函数（对L2范数，进行了平方运算），令$J_0 = J(\theta)$：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/b844b823dfcc4437ae7afd0f1f0b680c.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/b844b823dfcc4437ae7afd0f1f0b680c.png" alt="image.png"></a></p><p>令  $L_2 = \alpha * \sum\limits_{i = 1}^n(w_i)^2$ ：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/1cbddf3ce5da4e989c860fb392e93655.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/1cbddf3ce5da4e989c860fb392e93655.png" alt="image.png"></a></p><p>同样可以画出他们在二维平面上的图形，如下：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/ed5a6039416f48c1932f6565919d67f7.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/ed5a6039416f48c1932f6565919d67f7.png" alt="image.png"></a></p><p>二维平面下 L2 正则化的函数图形是个圆（绝对值的平方和，是个圆），与方形相比，被磨去了棱角。因此 $J_0$ 与  $L_2$ 相交时使得 $w_1、w_2$ 等于零的机率小了许多（这个也是一个很直观的想象），这就是为什么L2正则化不具有稀疏性的原因，因为不太可能出现多数 w 都为0的情况（这种情况就叫稀疏性）！</p><p><strong>权重更新规则如下：</strong></p><ol><li>损失函数：</li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/d13ef5f48f584dc28a629673647035a2.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/d13ef5f48f584dc28a629673647035a2.png" alt="image.png"></a></p><ol start="2"><li>更新规则：</li></ol><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/3bc2481fb852443a98553e4e95ad670b.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/3bc2481fb852443a98553e4e95ad670b.png" alt="image.png"></a></p><p>其中 $J_0$ 即是线性回归的损失函数，$L_2$ 是添加的正则项。</p><p><strong>综上所述</strong>，L2正则化权重更新如下（$ 2\alpha$  也是常数项，可以合并到一起用整体 $\alpha$  替代）：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/54a6992795ec49e8af1f268e3ab0f283.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/54a6992795ec49e8af1f268e3ab0f283.png" alt="image.png"></a></p><p>其中 $\alpha$ 就是正则化参数，$\eta$ 表示学习率。从上式可以看到，与未添加L2正则化的迭代公式相比，每一次迭代， $\theta_j$ 都要先乘以一个小于1的因子（即 $(1-\eta * \alpha)$ ），从而使得 $\theta_j$ 加速减小，因此总的来看，$\theta$ 相比不加L2正则项的线性回归可以获得更小的值。从而，实现了防止过拟合的效果，增加模型的鲁棒性~</p><p>有的书本上，公式写法可能<strong>不同</strong>：其中 $\lambda$ 表示正则化参数。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/0910c26576bd4e159e46c0770caa1995.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/0910c26576bd4e159e46c0770caa1995.png" alt="image.png"></a></p><h3 id="3、线性回归衍生算法">3、线性回归衍生算法</h3><p>  接下来，我们一起学习一下scikit-learn中为我们提供的线性回归衍生算法，根据上面所学的原理，对比线性回归加深理解。</p><h4 id="3-1、Ridge算法使用">3.1、Ridge算法使用</h4><p>这是scikit-learn官网给出的岭回归的，损失函数公式，注意，它用的矩阵表示，里面用到范数运算。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/c16bea0c68cd4e749269f2b4d089d73f.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/c16bea0c68cd4e749269f2b4d089d73f.png" alt="image.png"></a></p><p>L2正则化和普通线性回归系数对比：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = <span class="number">2</span>*np.random.rand(<span class="number">100</span>, <span class="number">5</span>)</span><br><span class="line">w = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = (<span class="number">5</span>,<span class="number">1</span>))</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line">y = X.dot(w) + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始方程的斜率：&#x27;</span>,w.ravel())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始方程的截距：&#x27;</span>,b)</span><br><span class="line"></span><br><span class="line">ridge = Ridge(alpha= <span class="number">1</span>, solver=<span class="string">&#x27;sag&#x27;</span>)</span><br><span class="line">ridge.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;岭回归求解的斜率：&#x27;</span>,ridge.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;岭回归求解的截距：&#x27;</span>,ridge.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性回归梯度下降方法</span></span><br><span class="line">sgd = SGDRegressor(penalty=<span class="string">&#x27;l2&#x27;</span>,alpha=<span class="number">0</span>,l1_ratio=<span class="number">0</span>)</span><br><span class="line">sgd.fit(X, y.reshape(-<span class="number">1</span>,))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;随机梯度下降求解的斜率是：&#x27;</span>,sgd.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;随机梯度下降求解的截距是：&#x27;</span>,sgd.intercept_)</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>和没有正则项约束线性回归对比，可知L2正则化，将方程系数进行了缩小</li><li>$\alpha$  增大求解出来的方程斜率变小</li><li>Ridge回归源码解析：<ul><li>alpha：正则项系数</li><li>fit_intercept：是否计算 $w_0$ 截距项</li><li>normalize：是否做归一化</li><li>max_iter：最大迭代次数</li><li>tol：结果的精确度</li><li>solver：优化算法的选择</li></ul></li></ul><h4 id="3-2、Lasso算法使用">3.2、Lasso算法使用</h4><p>这是scikit-learn官网给出的套索回归的，损失函数公式，注意，它用的矩阵表示，里面用到范数运算。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/b3deb13a7a55485d82e4417549bb8633.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/b3deb13a7a55485d82e4417549bb8633.png" alt="image.png"></a></p><p>公式中多了一项：$\frac{1}{2n_{samples}}$这是一个常数项，去掉之后，也不会影响损失函数公式计算。在岭回归中，就没有这项。</p><p>L1正则化和普通线性回归系数对比：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = <span class="number">2</span>*np.random.rand(<span class="number">100</span>, <span class="number">20</span>)</span><br><span class="line">w = np.random.randn(<span class="number">20</span>,<span class="number">1</span>)</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line">y = X.dot(w) + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始方程的斜率：&#x27;</span>,w.ravel())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始方程的截距：&#x27;</span>,b)</span><br><span class="line"></span><br><span class="line">lasso = Lasso(alpha= <span class="number">0.5</span>)</span><br><span class="line">lasso.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;套索回归求解的斜率：&#x27;</span>,lasso.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;套索回归求解的截距：&#x27;</span>,lasso.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性回归梯度下降方法</span></span><br><span class="line">sgd = SGDRegressor(penalty=<span class="string">&#x27;l2&#x27;</span>,alpha=<span class="number">0</span>, l1_ratio=<span class="number">0</span>)</span><br><span class="line">sgd.fit(X, y.reshape(-<span class="number">1</span>,))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;随机梯度下降求解的斜率是：&#x27;</span>,sgd.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;随机梯度下降求解的截距是：&#x27;</span>,sgd.intercept_)</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>和没有正则项约束线性回归对比，可知L1正则化，将方程系数进行了缩减，部分系数为0，产生稀疏模型</li><li>$\alpha$  越大，模型稀疏性越强，越多的参数为0</li><li>Lasso回归源码解析：<ul><li>alpha：正则项系数</li><li>fit_intercept：是否计算 $w_0$ 截距项</li><li>normalize：是否做归一化</li><li>precompute：bool 类型，默认值为False，决定是否提前计算Gram矩阵来加速计算</li><li>max_iter：最大迭代次数</li><li>tol：结果的精确度</li><li>warm_start：bool类型，默认值为False。如果为True，那么使⽤用前⼀次训练结果继续训练。否则从头开始训练</li></ul></li></ul><h4 id="3-3、Elastic-Net算法使用">3.3、Elastic-Net算法使用</h4><p>这是scikit-learn官网给出的弹性网络回归的，损失函数公式，注意，它用的矩阵表示，里面用到范数运算。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/91558aeaf118405085a6f799c1e2bcb4.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/91558aeaf118405085a6f799c1e2bcb4.png" alt="image.png"></a></p><p>  Elastic-Net 回归，即岭回归和Lasso技术的混合。弹性网络是一种使用 L1， L2 范数作为先验正则项训练的线性回归模型。 这种组合允许学习到一个只有少量参数是非零稀疏的模型，就像 Lasso 一样，但是它仍然保持一些像 Ridge 的正则性质。我们可利用 l1_ratio 参数控制 L1 和 L2 的凸组合。</p><p>  弹性网络在很多特征互相联系（相关性，比如<strong>身高</strong>和<strong>体重</strong>就很有关系）的情况下是非常有用的。Lasso 很可能只随机考虑这些特征中的一个，而弹性网络更倾向于选择两个。</p><p>  在实践中，Lasso 和 Ridge 之间权衡的一个优势是它允许在迭代过程中继承 Ridge 的稳定性。</p><p>弹性网络回归和普通线性回归系数对比：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据集X，y</span></span><br><span class="line">X = <span class="number">2</span>*np.random.rand(<span class="number">100</span>, <span class="number">20</span>)</span><br><span class="line">w = np.random.randn(<span class="number">20</span>,<span class="number">1</span>)</span><br><span class="line">b = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size = <span class="number">1</span>)</span><br><span class="line">y = X.dot(w) + b + np.random.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始方程的斜率：&#x27;</span>,w.ravel())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原始方程的截距：&#x27;</span>,b)</span><br><span class="line"></span><br><span class="line">model = ElasticNet(alpha= <span class="number">1</span>, l1_ratio = <span class="number">0.7</span>)</span><br><span class="line">model.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;弹性网络回归求解的斜率：&#x27;</span>,model.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;弹性网络回归求解的截距：&#x27;</span>,model.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性回归梯度下降方法</span></span><br><span class="line">sgd = SGDRegressor(penalty=<span class="string">&#x27;l2&#x27;</span>,alpha=<span class="number">0</span>, l1_ratio=<span class="number">0</span>)</span><br><span class="line">sgd.fit(X, y.reshape(-<span class="number">1</span>,))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;随机梯度下降求解的斜率是：&#x27;</span>,sgd.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;随机梯度下降求解的截距是：&#x27;</span>,sgd.intercept_)</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>和没有正则项约束线性回归对比，可知Elastic-Net网络模型，融合了L1正则化L2正则化</li><li>Elastic-Net 回归源码解析：<ul><li>alpha：混合惩罚项的常数</li><li>l1_ratio：弹性网混合参数，0 &lt;= l1_ratio &lt;= 1，对于 l1_ratio = 0，惩罚项是L2正则惩罚。对于 l1_ratio = 1是L1正则惩罚。对于 0</li><li>fit_intercept：是否计算 $w_0$ 截距项</li><li>normalize：是否做归一化</li><li>precompute：bool 类型，默认值为False，决定是否提前计算Gram矩阵来加速计算</li><li>max_iter：最大迭代次数</li><li>tol：结果的精确度</li><li>warm_start：bool类型，默认值为False。如果为True，那么使⽤用前⼀次训练结果继续训练。否则从头开始训练</li></ul></li></ul><h3 id="4、多项式回归">4、多项式回归</h3><h4 id="4-1、多项式回归基本概念">4.1、多项式回归基本概念</h4><p>  升维的目的是为了去解决欠拟合的问题的，也就是为了提高模型的准确率为目的的，因为当维度不够时，说白了就是对于预测结果考虑的因素少的话，肯定不能准确的计算出模型。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/4c50d109e36a4027bceef52123ba5a50.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/4c50d109e36a4027bceef52123ba5a50.png" alt="image.png"></a></p><p>  在做升维的时候，最常见的手段就是将已知维度进行相乘（或者自乘）来构建新的维度，如下图所示。普通线性方程，无法拟合规律，必须是多项式，才可以完美拟合曲线规律，图中是二次多项式。</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/0cb4bee00c86449892903be1bfdda1f0.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/0cb4bee00c86449892903be1bfdda1f0.jpeg" alt="image.png"></a></p><p>  对于多项式回归来说主要是为了扩展线性回归算法来适应更广泛的数据集，比如我们数据集有两个维度 $x_1、x_2$，那么用多元线性回归公式就是：$\hat{y} = w_0 + w_1x_1 + w_2x_2$，当我们使用二阶多项式升维的时候，数据集就从原来的 $x_1、x_2$扩展成了$x_1、x_2、x_1^2、x_2^2、x_1x_2$ 。因此多元线性回归就得去多计算三个维度所对应的w值：$\hat{y} = w_0 + w_1x_1 + w_2x_2 + w_3x_1^2 + w_4x_2^2 + w_5x_1x_2$ 。</p><p>  此时拟合出来的方程就是曲线，可以解决一些线性回归的欠拟合问题！</p><h4 id="4-2、多项式回归实战1-0">4.2、多项式回归实战1.0</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据，并进行可视化</span></span><br><span class="line">X = np.linspace(-<span class="number">1</span>,<span class="number">11</span>,num = <span class="number">100</span>)</span><br><span class="line">y = (X - <span class="number">5</span>)**<span class="number">2</span> + <span class="number">3</span>*X -<span class="number">12</span> + np.random.randn(<span class="number">100</span>)</span><br><span class="line">X = X.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、创建预测数据</span></span><br><span class="line">X_test = np.linspace(-<span class="number">2</span>,<span class="number">12</span>,num = <span class="number">200</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、不进行升维 + 普通线性回归</span></span><br><span class="line">model_1 = LinearRegression()</span><br><span class="line">model_1.fit(X,y)</span><br><span class="line">y_test_1 = model_1.predict(X_test)</span><br><span class="line">plt.plot(X_test,y_test,color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、多项式升维 + 普通线性回归</span></span><br><span class="line">X = np.concatenate([X,X**<span class="number">2</span>],axis = <span class="number">1</span>)</span><br><span class="line">model_2 = LinearRegression()</span><br><span class="line">model_2.fit(X,y)</span><br><span class="line"><span class="comment"># 5、测试数据处理，并预测</span></span><br><span class="line">X_test = np.concatenate([X_test,X_test**<span class="number">2</span>],axis = <span class="number">1</span>)</span><br><span class="line">y_test_2 = model_2.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、数据可视化，切片操作</span></span><br><span class="line">plt.plot(X_test[:,<span class="number">0</span>],y_test_2,color = <span class="string">&#x27;green&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>不进行多项式升维，拟合出来的曲线，是线性的直线，和目标曲线无法匹配</li><li>使用np.concatenate()进行简单的，幂次合并，注意数据合并的方向axis = 1</li><li>数据可视化时，注意切片，因为数据升维后，多了平方这一维</li></ul><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/d4264371bc9041d997ec84b09d77e6fe.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/d4264371bc9041d997ec84b09d77e6fe.png" alt="image.png"></a></p><h4 id="4-3、多项式回归实战2-0">4.3、多项式回归实战2.0</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures,StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据，并进行可视化</span></span><br><span class="line">X = np.linspace(-<span class="number">1</span>,<span class="number">11</span>,num = <span class="number">100</span>)</span><br><span class="line">y = (X - <span class="number">5</span>)**<span class="number">2</span> + <span class="number">3</span>*X -<span class="number">12</span> + np.random.randn(<span class="number">100</span>)</span><br><span class="line">X = X.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、创建预测数据</span></span><br><span class="line">X_test = np.linspace(-<span class="number">2</span>,<span class="number">12</span>,num = <span class="number">200</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、使用PolynomialFeatures进行特征升维</span></span><br><span class="line">poly = PolynomialFeatures()</span><br><span class="line">poly.fit(X,y)</span><br><span class="line">X = poly.transform(X)</span><br><span class="line">s = StandardScaler()</span><br><span class="line">X = s.fit_transform(X)</span><br><span class="line"><span class="comment"># model = SGDRegressor(penalty=&#x27;l2&#x27;,eta0 = 0.0001,max_iter = 10000)</span></span><br><span class="line">model = SGDRegressor(penalty=<span class="string">&#x27;l2&#x27;</span>,eta0 = <span class="number">0.01</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、预测数据</span></span><br><span class="line">X_test = poly.transform(X_test)</span><br><span class="line">X_test_norm = s.transform(X_test)</span><br><span class="line">y_test = model.predict(X_test_norm)</span><br><span class="line">plt.plot(X_test[:,<span class="number">1</span>],y_test,color = <span class="string">&#x27;green&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>eta0表示学习率，设置合适的学习率，才能拟合成功</li><li>多项式升维，需要对数据进行Z-score归一化处理，效果更佳出色</li><li>SGD随机梯度下降需要调整参数，以使模型适应数据</li></ul><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/8e8e751622bd4b10a6963673a8e3766b.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/8e8e751622bd4b10a6963673a8e3766b.png" alt="image.png"></a></p><h3 id="5、代码实战天猫双十一销量预测">5、代码实战天猫双十一销量预测</h3><p>  天猫双十一，从2009年开始举办，第一届成交额仅仅0.5亿，后面呈现了爆发式的增长，那么这些增长是否有规律呢？是怎么样的规律，该如何分析呢？我们使用多项式回归一探究竟！</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/31cb52d42edf43d6a46c382b4b40ce08.jpeg" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/31cb52d42edf43d6a46c382b4b40ce08.jpeg" alt="image.png"></a></p><p>数据可视化，历年天猫双十一销量数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.size&#x27;</span>] = <span class="number">18</span></span><br><span class="line">plt.figure(figsize=(<span class="number">9</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据，年份数据2009 ~ 2019</span></span><br><span class="line">X = np.arange(<span class="number">2009</span>,<span class="number">2020</span>)</span><br><span class="line">y = np.array([<span class="number">0.5</span>,<span class="number">9.36</span>,<span class="number">52</span>,<span class="number">191</span>,<span class="number">350</span>,<span class="number">571</span>,<span class="number">912</span>,<span class="number">1207</span>,<span class="number">1682</span>,<span class="number">2135</span>,<span class="number">2684</span>])</span><br><span class="line">plt.bar(X,y,width = <span class="number">0.5</span>,color = <span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.plot(X,y,color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">_ = plt.xticks(ticks = X)</span><br></pre></td></tr></table></figure><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/10d4dd476d8e40daba21a97d77866da8.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/10d4dd476d8e40daba21a97d77866da8.png" alt="image.png"></a></p><p>有图可知，在一定时间内，随着经济的发展，天猫双十一销量与年份的关系是多项式关系！假定，销量和年份之间关系是三次幂关系：</p><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/35f0479254104929b16b08ebb713fbc6.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/35f0479254104929b16b08ebb713fbc6.png" alt="image.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">9</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、创建数据，年份数据2009 ~ 2019</span></span><br><span class="line">X = np.arange(<span class="number">2009</span>,<span class="number">2020</span>)</span><br><span class="line">y = np.array([<span class="number">0.5</span>,<span class="number">9.36</span>,<span class="number">52</span>,<span class="number">191</span>,<span class="number">350</span>,<span class="number">571</span>,<span class="number">912</span>,<span class="number">1207</span>,<span class="number">1682</span>,<span class="number">2135</span>,<span class="number">2684</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、年份数据，均值移除，防止某一个特征列数据天然的数值太大而影响结果</span></span><br><span class="line">X = X - X.mean()</span><br><span class="line">X = X.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、构建多项式特征，3次幂</span></span><br><span class="line">poly = PolynomialFeatures(degree=<span class="number">3</span>)</span><br><span class="line">X = poly.fit_transform(X)</span><br><span class="line">s = StandardScaler()</span><br><span class="line">X_norm = s.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、创建模型</span></span><br><span class="line">model = SGDRegressor(penalty=<span class="string">&#x27;l2&#x27;</span>,eta0 = <span class="number">0.5</span>,max_iter = <span class="number">5000</span>)</span><br><span class="line">model.fit(X_norm,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、数据预测</span></span><br><span class="line">X_test = np.linspace(-<span class="number">5</span>,<span class="number">6</span>,<span class="number">100</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">X_test = poly.transform(X_test)</span><br><span class="line">X_test_norm = s.transform(X_test)</span><br><span class="line">y_test = model.predict(X_test_norm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、数据可视化</span></span><br><span class="line">plt.plot(X_test[:,<span class="number">1</span>],y_test,color = <span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.bar(X[:,<span class="number">1</span>],y)</span><br><span class="line">plt.bar(<span class="number">6</span>,y_test[-<span class="number">1</span>],color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">4096</span>)</span><br><span class="line">plt.text(<span class="number">6</span>,y_test[-<span class="number">1</span>] + <span class="number">100</span>,<span class="built_in">round</span>(y_test[-<span class="number">1</span>],<span class="number">1</span>),ha = <span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">_ = plt.xticks(np.arange(-<span class="number">5</span>,<span class="number">7</span>),np.arange(<span class="number">2009</span>,<span class="number">2021</span>))</span><br></pre></td></tr></table></figure><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/6a839d47304f4373b84be460374381a5.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/6a839d47304f4373b84be460374381a5.png" alt="image.png"></a></p><p><strong>结论：</strong></p><ul><li>数据预处理，均值移除。如果特征<strong>基准值和分散度</strong>不同在某些算法（例如回归算法，KNN等）上可能会大大影响了模型的预测能力。通过均值移除，大大增强数据的<strong>离散化</strong>程度。</li><li>多项式升维，需要对数据进行Z-score归一化处理，效果更佳出色</li><li>SGD随机梯度下降需要调整参数，以使模型适应多项式数据</li><li>从2020年开始，天猫双十一统计的成交额改变了规则为11.1日~11.11日的成交数据（之前的数据为双十一当天的数据），2020年成交额为<strong>4980</strong>亿元</li><li>可以，经济发展有其客观规律，前11年高速发展（曲线基本可以反应销售规律），到2020年是一个转折点</li></ul><h3 id="6、代码实战中国人寿保费预测">6、代码实战中国人寿保费预测</h3><h4 id="6-1、数据加载与介绍">6.1、数据加载与介绍</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;./中国人寿.xlsx&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(data.shape)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><p>数据介绍：</p><ul><li>共计1338条保险数据，每条数据7个属性</li><li>最后一列charges是保费</li><li>前面6列是特征，分别为：年龄、性别、体重指数、小孩数量、是否抽烟、所在地区</li></ul><h4 id="6-2、EDA数据探索">6.2、EDA数据探索</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="comment"># 性别对保费影响</span></span><br><span class="line">sns.kdeplot(data[<span class="string">&#x27;charges&#x27;</span>],shade = <span class="literal">True</span>,hue = data[<span class="string">&#x27;sex&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 地区对保费影响</span></span><br><span class="line">sns.kdeplot(data[<span class="string">&#x27;charges&#x27;</span>],shade = <span class="literal">True</span>,hue = data[<span class="string">&#x27;region&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 吸烟对保费影响</span></span><br><span class="line">sns.kdeplot(data[<span class="string">&#x27;charges&#x27;</span>],shade = <span class="literal">True</span>,hue = data[<span class="string">&#x27;smoker&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 孩子数量对保费影响</span></span><br><span class="line">sns.kdeplot(data[<span class="string">&#x27;charges&#x27;</span>],shade = <span class="literal">True</span>,hue = data[<span class="string">&#x27;children&#x27;</span>],palette=<span class="string">&#x27;Set1&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/93b4a181835c4083a9e43c3383583369.png" title="image.png" class="gallery-item" style="box-shadow: none;"> <img src="https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/463/1652344917096/93b4a181835c4083a9e43c3383583369.png" alt="image.png"></a></p><p>总结：</p><ul><li>不同性别对保费影响不大，不同性别的保费的概率分布曲线基本重合，因此这个特征无足轻重，可以删除</li><li>地区同理</li><li>吸烟与否对保费的概率分布曲线差别很大，整体来说不吸烟更加健康，那么保费就低，这个特征很重要</li><li>家庭孩子数量对保费有一定影响</li></ul><h4 id="6-3、特征工程">6.3、特征工程</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">data = data.drop([<span class="string">&#x27;region&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">data.head() <span class="comment"># 删除不重要特征</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 体重指数，离散化转换，体重两种情况：标准、肥胖</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert</span>(<span class="params">df,bmi</span>):</span><br><span class="line">    df[<span class="string">&#x27;bmi&#x27;</span>] = <span class="string">&#x27;fat&#x27;</span> <span class="keyword">if</span> df[<span class="string">&#x27;bmi&#x27;</span>] &gt;= bmi <span class="keyword">else</span> <span class="string">&#x27;standard&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line">data = data.apply(convert, axis = <span class="number">1</span>, args=(<span class="number">30</span>,))</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征提取，离散型数据转换为数值型数据</span></span><br><span class="line">data = pd.get_dummies(data)</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征和目标值抽取</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;charges&#x27;</span>, axis=<span class="number">1</span>) <span class="comment"># 训练数据</span></span><br><span class="line">y = data[<span class="string">&#x27;charges&#x27;</span>] <span class="comment"># 目标值</span></span><br><span class="line">X.head()</span><br></pre></td></tr></table></figure><h4 id="6-4、特征升维">6.4、特征升维</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error,mean_squared_log_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据拆分</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征升维</span></span><br><span class="line">poly = PolynomialFeatures(degree= <span class="number">2</span>, include_bias = <span class="literal">False</span>)</span><br><span class="line">X_train_poly = poly.fit_transform(X_train)</span><br><span class="line">X_test_poly = poly.fit_transform(X_test)</span><br></pre></td></tr></table></figure><h4 id="6-5、模型训练与评估">6.5、模型训练与评估</h4><p>普通线性回归：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model_1 = LinearRegression()</span><br><span class="line">model_1.fit(X_train_poly, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据得分：&#x27;</span>,model_1.score(X_train_poly,y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预测数据得分：&#x27;</span>,model_1.score(X_test_poly,y_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练数据均方误差：&#x27;</span>,np.sqrt(mean_squared_error(y_train,model_1.predict(X_train_poly))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据均方误差：&#x27;</span>,np.sqrt(mean_squared_error(y_test,model_1.predict(X_test_poly))))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练数据对数误差：&#x27;</span>,np.sqrt(mean_squared_log_error(y_train,model_1.predict(X_train_poly))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据对数误差：&#x27;</span>,np.sqrt(mean_squared_log_error(y_test,model_1.predict(X_test_poly))))</span><br></pre></td></tr></table></figure><p>弹性网络回归：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model_2 = ElasticNet(alpha = <span class="number">0.3</span>,l1_ratio = <span class="number">0.5</span>,max_iter = <span class="number">50000</span>)</span><br><span class="line">model_2.fit(X_train_poly,y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据得分：&#x27;</span>,model_2.score(X_train_poly,y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预测数据得分：&#x27;</span>,model_2.score(X_test_poly,y_test))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练数据均方误差为：&#x27;</span>,np.sqrt(mean_squared_error(y_train,model_2.predict(X_train_poly))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据均方误差为：&#x27;</span>,np.sqrt(mean_squared_error(y_test,model_2.predict(X_test_poly))))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练数据对数误差为：&#x27;</span>,np.sqrt(mean_squared_log_error(y_train,model_2.predict(X_train_poly))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据对数误差为：&#x27;</span>,np.sqrt(mean_squared_log_error(y_test,model_2.predict(X_test_poly))))</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>进行EDA数据探索，可以查看无关紧要特征</li><li>进行特征工程：删除无用特征、特征离散化、特征提取。这对机器学习都至关重要</li><li>对于简单的数据（特征比较少）进行线性回归，一般需要进行特征升维</li><li>选择不同的算法，进行训练和评估，从中筛选优秀算法</li></ul></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;
&lt;h2 id=&quot;梯度下降优化&quot;&gt;梯度下降优化&lt;/h2&gt;
&lt;h3 id=&quot;1、归一化-Normalization&quot;&gt;1、归一化 No</summary>
      
    
    
    
    <category term="机器学习" scheme="https://0914ds.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>kafka</title>
    <link href="https://0914ds.github.io/2023/06/17/%E6%B6%88%E6%81%AF/kafka/"/>
    <id>https://0914ds.github.io/2023/06/17/%E6%B6%88%E6%81%AF/kafka/</id>
    <published>2023-06-17T06:13:16.000Z</published>
    <updated>2023-08-17T17:09:44.126Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>kafka</h1><p><a href="https://so.csdn.net/so/search?q=Kafka&amp;spm=1001.2101.3001.7020">Kafka</a> 本质上是⼀个消息队列。与zeromq不同的是，Kafka是一个独立的框架而不是一个库。这里主要介绍其原理，至于具体的安装等操作不做介绍，只是提示一下，第一次运行时，先设置前台运行，看会不会报错。</p><h2 id="架构">架构</h2><p>注意下图没有画上zookeeper，请自行脑补。kafka需要连接到zookeeper，来完成注册发现等集群操作。broker都是由zookeeper管理。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230706220539.png" title="微信截图_20230706220539" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230706220539.png" alt="微信截图_20230706220539"></a></p><p>先给出 Kafka ⼀些重要概念，让⼤家对 Kafka 有个整体的认识和感知，后⾯还会详细的解析每⼀个概念的作⽤以及更深⼊的原理：</p><ul><li>Producer：消息⽣产者，向 Kafka Broker 发消息的客户端。</li><li>Consumer：消息消费者，从 Kafka Broker 取消息的客户端。Kafka支持持久化，生产者退出后，未消费的消息仍可被消费</li><li>Consumer Group：消费者组(CG），消费者组内每个消费者负责消费不同分区的数据，提⾼消费能⼒。⼀个分区只能由组内⼀个费者消费，消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的⼀个订阅者</li><li>Broker：⼀台 Kafka 机器就是⼀个 Broker。⼀个集群(kafka cluster)由多个 Broker 组成。⼀个 Broker 可以容纳多个 Topic</li><li>Controller：由zookeeper选举其中一个Broker产生。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。</li><li>Topic：可以理解为⼀个队列，Topic 将消息分类，⽣产者和消费者⾯向的是同⼀个 Topic。</li><li>Partition：为了实现扩展性，提⾼并发能⼒，⼀个⾮常⼤的 Topic 可以分布到多个 Broker上，⼀个 Topic 可以分为多个 Partition，同⼀个topic在不同的分区的数据是不重复的，每个 Partition 是⼀个有序的队列，其表现形式就是⼀个⼀个的⽂件夹。不同Partition可以部署在同一台机器上，但不建议这么做。</li><li>Replication：每⼀个分区都有多个副本，副本的作⽤是做备胎。当主分区(Leader）故障的时候会选择⼀个备胎(Follower）上位，成为Leader。在kafka中默认副本的最⼤数量是10个，且副本的数量不能⼤于Broker的数量，follower和leader绝对是在不同的机器，同⼀机器对同⼀个分区也只可能存放⼀个副本(包括⾃⼰）。</li><li>Message：每⼀条发送的消息主体。</li><li>Leader：每个分区多个副本的“主”副本，⽣产者发送数据的对象，以及消费者消费数据的对象，都是 Leader。</li><li>Follower：每个分区多个副本的“从”副本，使用发布订阅模式主动拉取Leader的数据(与redis不同），实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发⽣故障时，某个 Follower 还会成为新的 Leader。</li><li>Offset：消费者消费的位置信息，监控数据消费到什么位置，当消费者挂掉再重新恢复的时候，可以从消费位置继续消费。</li><li>ZooKeeper：Kafka 集群能够正常⼯作，需要依赖于 ZooKeeper，ZooKeeper 帮助 Kafka存储和管理集群信息。<br>High Level API 和Low Level API ：高水平API，kafka本身定义的行为，屏蔽细节管理，使用方便；低水平API细节需要自己处理，较为灵活但是复杂。</li><li>kafka 存储的消息来⾃任意多被称为 Producer ⽣产者的进程。数据从⽽可以被发布到不同的Topic 主题下的不同 Partition 分区。在⼀个分区内，这些消息被索引并连同时间戳存储在⼀起。其它被称为 Consumer 消费者的进程可以从分区订阅消息。<br>Kafka 运⾏在⼀个由⼀台或多台服务器组成的集群上，并且分区可以跨集群结点分布。</li></ul><h2 id="工作流程">工作流程</h2><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230706220948.png" title="微信截图_20230706220948" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230706220948.png" alt="微信截图_20230706220948"></a></p><p>Kafka集群将 Record 流存储在称为 Topic 的类中，每个记录由⼀个键、⼀个值和⼀个时间戳组成。<br>Kafka 中消息是以 Topic 进⾏分类的，⽣产者⽣产消息，消费者消费消息，⾯向的都是同⼀个Topic。Topic 是逻辑上的概念，⽽ Partition 是物理上的概念，每个 Partition 对应于⼀个 log ⽂件，该log ⽂件中存储的就是 Producer ⽣产的数据。Producer ⽣产的数据会不断追加到该 log ⽂件末端，且每条数据都有⾃⼰的 Offset。消费者组中的每个消费者，都会实时记录⾃⼰消费到了哪个 Offset，以便出错恢复时，从上次的位置继续消费。</p><p>Kafka集群将 Record 流存储在称为 Topic 的类中，每个记录由⼀个键、⼀个值和⼀个时间戳组成。<br>Kafka 中消息是以 Topic 进⾏分类的，⽣产者⽣产消息，消费者消费消息，⾯向的都是同⼀个Topic。Topic 是逻辑上的概念，⽽ Partition 是物理上的概念，每个 Partition 对应于⼀个 log ⽂件，该log ⽂件中存储的就是 Producer ⽣产的数据。Producer ⽣产的数据会不断追加到该 log ⽂件末端，且每条数据都有⾃⼰的 Offset。消费者组中的每个消费者，都会实时记录⾃⼰消费到了哪个 Offset，以便出错恢复时，从上次的位置继续消费。</p><p><a href="9a196aac8d47479f82b0046b6b51aa65.jpg" title="9a196aac8d47479f82b0046b6b51aa65" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//9a196aac8d47479f82b0046b6b51aa65.jpg" alt="9a196aac8d47479f82b0046b6b51aa65"></a></p><p>这些⽂件位于同⼀⽂件下，该⽂件夹的命名规则为：topic 名-分区号。例如，test这个 topic 有三个分区，则其对应的⽂件夹为 test-0，test-1，test-2。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$</span> <span class="built_in">ls</span> /tmp/kafka<span class="literal">-logs</span>/<span class="built_in">test-1</span></span><br><span class="line"><span class="number">00000000000000009014</span>.index</span><br><span class="line"><span class="number">00000000000000009014</span>.log</span><br><span class="line"><span class="number">00000000000000009014</span>.timeindex</span><br><span class="line">leader<span class="literal">-epoch-checkpoint</span></span><br></pre></td></tr></table></figure><p>index 和 log ⽂件以当前 Segment 的第⼀条消息的 Offset 命名。下图为 index ⽂件和 log ⽂件的结构示意图</p><p><a href="60904efb05104cdea48f0e38cb134cbd.jpg" title="60904efb05104cdea48f0e38cb134cbd" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//60904efb05104cdea48f0e38cb134cbd.jpg" alt="60904efb05104cdea48f0e38cb134cbd"></a></p><p>“.index” ⽂件存储⼤量的索引信息，“.log” ⽂件存储⼤量的数据，索引⽂件中的元数据指向对应数据⽂件中 Message 的物理偏移量。<br>使用shell命令查看索引</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka<span class="literal">-dump-log</span>.sh <span class="literal">--files</span> /tmp/kafka<span class="literal">-logs</span>/<span class="built_in">test-1</span>/<span class="number">00000000000000000000</span>.index</span><br></pre></td></tr></table></figure><h2 id="分区机制">分区机制</h2><p>分区原因：</p><p>⽅便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，⽽⼀个 Topic ⼜可以有多个 Partition 组成，因此可以以 Partition 为单位读写了。<br>可以提⾼并发，避免两个分区持久化的时候争夺资源。<br>备份的问题。防止一台机器宕机后数据丢失的问题。<br>分区原则：我们需要将 Producer 发送的数据封装成⼀个 ProducerRecord 对象。该对象需要指定⼀些参数：</p><p>topic：string 类型，NotNull。<br>partition：int 类型，可选。<br>timestamp：long 类型，可选。<br>key：string 类型，可选。<br>value：string 类型，可选。<br>headers：array 类型，Nullable。<br>指明 Partition 的情况下，直接将给定的 Value 作为 Partition 的值；没有指明 Partition 但有 Key 的情况下，将 Key 的 Hash 值与分区数取余得到 Partition 值；既没有 Partition 又没有 Key 的情况下，第⼀次调⽤时随机⽣成⼀个整数(后⾯每次调⽤都在这个整数上⾃增），将这个值与可⽤的分区数取余，得到 Partition 值，也就是常说的 Round-Robin轮询算法。</p><h2 id="生产者">生产者</h2><p>Producer⽣产者，是数据的⼊⼝。Producer在写⼊数据的时候永远的找leader，不会直接将数据写⼊follower。下图很好地阐释了生产者的工作流程。</p><p><a href="9715111fbe814854b01de917a3c4632d.jpg" title="9715111fbe814854b01de917a3c4632d" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//9715111fbe814854b01de917a3c4632d.jpg" alt="9715111fbe814854b01de917a3c4632d"></a></p><p>这里获取分区信息，是从zookeeper中获取的。<br>生产者不会每个消息都调用一次send()，这样效率太低，默认是数据攒到16K或是超时(如10ms）会send()一次。注意这里发消息是异步操作。</p><h2 id="ack机制">ack机制</h2><p>producer端设置request.required.acks=0；只要请求已发送出去，就算是发送完了，不关心有没有写成功。性能很好，如果是对一些日志进行分析，可以承受丢数据的情况，用这个参数，性能会很好。<br>request.required.acks=1；发送一条消息，当leader partition写入成功以后，才算写入成功。不过这种方式也有丢数据的可能。<br>request.required.acks=-1；需要ISR列表里面，所有副本都写完以后，这条消息才算写入成功。<br>设计一个不丢数据的方案：数据不丢失的方案：1)分区副本 &gt;=2 2)acks = -1 3)min.insync.replicas &gt;=2。<br>下面给出此时leader出现故障的情况，可以看出，此时数据可能重复。</p><p><a href="5ee45a5558bd4528a47a5a3b82749828.jpg" title="5ee45a5558bd4528a47a5a3b82749828" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//5ee45a5558bd4528a47a5a3b82749828.jpg" alt="5ee45a5558bd4528a47a5a3b82749828"></a></p><p>解释上面出现的几个名词。Leader维护了⼀个动态的 in-sync replica set(ISR）：和 Leader 保持同步的 Follower 集合。当 ISR 集合中的 Follower 完成数据的同步之后，Leader 就会给 Follower 发送 ACK。如果 Follower ⻓时间未向 Leader 同步数据，则该 Follower 将被踢出 ISR 集合，<a href="http://xn--replica-vk7kx82nb35atg4c5hzapha.lag.time.max.ms">该时间阈值由replica.lag.time.max.ms</a> 参数设定。Leader 发⽣故障后，就会从 ISR 中选举出新的 Leader。<br>kafka服务端中min.insync.replicas。 如果我们不设置的话，默认这个值是1。一个leader partition会维护一个ISR列表，这个值就是限制ISR列表里面 至少得有几个副本，比如这个值是2，那么当ISR列表里面只有一个副本的时候，往这个分区插入数据的时候会报错。</p><h2 id="消费者">消费者</h2><p>Consumer 采⽤ Pull(拉取）模式从 Broker 中读取数据。Pull 模式则可以根据 Consumer 的消费能⼒以适当的速率消费消息。Pull 模式不⾜之处是，如果Kafka 没有数据，消费者可能会陷⼊循环中，⼀直返回空数据。因为消费者从 Broker 主动拉取数据，需要维护⼀个⻓轮询，针对这⼀点， Kafka 的消费者在消费数据时会传⼊⼀个时⻓参数 timeout。如果当前没有数据可供消费，Consumer 会等待⼀段时间之后再返回，这段时⻓即为 timeout。</p><h2 id="分区分配策略">分区分配策略</h2><p>⼀个 Consumer Group 中有多个 Consumer，⼀个 Topic 有多个 Partition。不同组间的消费者是相互独立的，相同组内的消费者才会协作，这就必然会涉及到Partition 的分配问题，即确定哪个 Partition 由哪个 Consumer 来消费。<br>Kafka 有三种分配策略：</p><p>RoundRobin<br>Range，默认为Range<br>Sticky<br>当消费者组内消费者发⽣变化时，会触发分区分配策略(⽅法重新分配），在分配完成前，kafka会暂停对外服务。注意为了尽量确保消息的有序执行，一个分区只能对应一个消费者，这也说明消费者的数量不能超过分区的数量。</p><h4 id="range方式">range方式</h4><p>Range ⽅式是按照主题来分的，不会产⽣轮询⽅式的消费混乱问题，但是也有不足。</p><p><a href="2e8e7674b862451b95355ef670e259db.jpg" title="2e8e7674b862451b95355ef670e259db" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//2e8e7674b862451b95355ef670e259db.jpg" alt="2e8e7674b862451b95355ef670e259db"></a></p><p>注意图文不符，图片是一个例子，文字再给一个例子，以便理解。假设我们有10个分区，3个消费者，排完序的分区将会是0,1,2,3,4,5,6,7,8,9；消费者线程排完序将会是C1-0,C2-0,C3-0。然后将partitions的个数除于消费者线程的总数来决定每个消费者线程消费⼏个分区。如果除不尽，那么前⾯⼏个消费者线程将会多消费⼀个分区。<br>在我们的例⼦⾥⾯，我们有10个分区，3个消费者线程， 10/3 = 3，⽽且除不尽，那么消费者线程 C1-0将会多消费⼀个分区：C1-0 将消费 0, 1, 2, 3 分区；C2-0将消费 4,5,6分区；C3-0将消费 7,8,9分区。<br>假如我们有11个分区，那么最后分区分配的结果看起来是这样的：<br>C1-0将消费 0,1,2,3分区；C2-0将消费 4,5,6,7分区；C3-0 将消费 8, 9, 10 分区。<br>假如我们有2个主题(T1和T2)，分别有10个分区，那么最后分区分配的结果看起来是这样的：<br>C1-0 将消费 T1主题的 0, 1, 2, 3 分区以及 T2主题的 0, 1, 2, 3分区<br>C2-0将消费 T1主题的 4,5,6分区以及 T2主题的 4,5,6分区<br>C3-0将消费 T1主题的 7,8,9分区以及 T2主题的 7,8,9分区</p><p>这就可以看出，C1-0 消费者线程⽐其他消费者线程多消费了2个分区，这就是Range strategy的⼀个很明显的弊端。如下图所示，Consumer0、Consumer1 同时订阅了主题 A 和 B，可能造成消息分配不对等问题，当消费者组内订阅的主题越多，分区分配可能越不均衡。</p><p>RoundRobin<br>RoundRobin 轮询⽅式将分区所有作为⼀个整体进⾏ Hash 排序，消费者组内分配分区个数最⼤差别为 1，是按照组来分的，可以解决多个消费者消费数据不均衡的问题。<br>轮询分区策略是把所有partition和所有consumer线程都列出来，然后按照hashcode进⾏排序。最后通过轮询算法分配partition给消费线程。如果所有consumer实例的订阅是相同的，那么partition会均匀分布。<br>在上面的例⼦⾥⾯，假如按照 hashCode排序完的topic-partitions组依次为T1-5,T1-3,T1-0,T1-8,T1-2,T1-1,T1-4,T1-7,T1-6,T1-9，我们的消费者线程排序为C1-0,C1-1,C2-0,C2-1，最后分区分配的结果为：<br>C1-0将消费 T1-5,T1-2,T1-6分区；<br>C1-1将消费 T1-3,T1-1,T1-9分区；<br>C2-0将消费 T1-0,T1-4分区；<br>C2-1将消费 T1-8,T1-7分区。</p><p><a href="0e3ff9f5402f43c8a7424a1c4bcdfddd.jpg" title="0e3ff9f5402f43c8a7424a1c4bcdfddd" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//0e3ff9f5402f43c8a7424a1c4bcdfddd.jpg" alt="0e3ff9f5402f43c8a7424a1c4bcdfddd"></a></p><p>图文不符。<br>但是，当消费者组内订阅不同主题时，可能造成消费混乱，如下图所示，Consumer0 订阅主题A，Consumer1 订阅主题 B。</p><p><a href="3d63a1c330944ccbb834619c7ec32243.jpg" title="3d63a1c330944ccbb834619c7ec32243" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/17/%E6%B6%88%E6%81%AF/kafka//3d63a1c330944ccbb834619c7ec32243.jpg" alt="3d63a1c330944ccbb834619c7ec32243"></a></p><p>将 A、B 主题的分区排序后分配给消费者组，TopicB 分区中的数据可能分配到 Consumer0 中。<br>因此，使⽤轮询分区策略必须满⾜两个条件：</p><p>每个主题的消费者实例具有相同数量的流；<br>每个消费者订阅的主题必须是相同的。<br>注意，其实对于生产者而言，可以自定义push但哪个分区中，也可以使用如hash等方法。</p><p>Sticky<br>前两种rebalance方式需要重新映射，代价较大，特别是由于rebalance期间会暂停服务，这就要求该过程尽量短。Sticky在没有rebalance时采用轮询方式，发生rebalance时，尽量保持原映射关系，只是改变与宕机相关的映射，依然采用轮询的方式。</p><p>可靠性保证<br>在前面ack保障消息到了broker之后，消费者也需要有⼀定的保证，因为消费者也可能出现某些问题导致消息没有消费到。<br>这里介绍一下偏移量。每个consumer内存里数据结构保存对每个topic的每个分区的消费offset，定期会提交offset，0.9版本以后，提交offset发送给kafka内部额外生成的一个topic：__consumer_offsets，提交过去的时候， key是group.id+topic+分区号，value就是当前offset的值，每隔一段时间，kafka内部会对这个topic进行compact(合并)，也就是每个group.id+topic+分区号就保留最新数据。<br>这里引入enable.auto.commit，默认为true，也就是⾃动提交offset，⾃动提交是批量执⾏的，有⼀个时间窗⼝，这种⽅式会带来重复提交或者消息丢失的问题，所以对于⾼可靠性要求的程序，要使⽤⼿动提交。对于⾼可靠要求的应⽤来说，宁愿重复消费也不应该因为消费异常⽽导致消息丢失。当然，我们也可以使用策略来避免消息的重复消费与丢失，比如使用事务，将offset与消息执行放在同一数据库中。</p><p>最后再简单介绍一个应用。kafka可以用在分布式延时队列中。创建一个额外的主题和一个定时进程，检测这个主题中是否有消息过期，过期后放在常规的消息队列中，消费者从这个常规的队列中获取消息来消费。</p></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;kafka&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://so.csdn.net/so/search?q=Kafka&amp;amp;spm=1001.2101.3001.7020&quot;&gt;Kafka&lt;/a&gt; 本质上是⼀个</summary>
      
    
    
    
    <category term="消息中间件" scheme="https://0914ds.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
  </entry>
  
  <entry>
    <title>容器的演进发展</title>
    <link href="https://0914ds.github.io/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"/>
    <id>https://0914ds.github.io/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</id>
    <published>2023-06-04T10:17:28.000Z</published>
    <updated>2024-02-24T06:55:40.016Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><p>用户中台的性能问题<br>在一个大型科技公司用户中台中，组织机构扮演着至关重要的角色，涉及到多个部门、团队和员工的关系和层级。</p><p>然而，随着公司规模的不断扩大和组织结构的复杂性增加，组织机构树的数据量也日益庞大。</p><p>这给内部用户在内部系统平台查询组织机构树时带来了一系列挑战和问题。</p><p>其中最突出的问题之一是查询的效率问题。</p><p>传统的查询方式无法有效应对组织机构树庞大数据量的挑战，导致页面在查询时出现卡顿、响应时间过长甚至超时的情况。</p><p>有关问题详细的数据</p><p>单次点击 rt时间 &gt; 70s</p><p>100并发 压测，平均RT时间 &gt; 160</p><p>在某个大型科技公司用户中台中，组织机构接口的RT时间为70s。</p><p>通过postman工具调用接口获取组织树，可以看到这个时间：<br><a href="img.png" title="img.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img.png" alt="img.png"></a><br>我们可以看到，这一次组织树查询接口耗时大概在70s左右。 这个是太长了，性能太差了。</p><p>一般系统RT要求在500ms内，并且越短越好。</p><p>接下来，我们利用jmeter对该接口进行压测<br>在《 调优圣经：零基础精通Jmeter分布式压测，10Wqps+超高并发 》这篇文章中，对jmeter进行了详细介绍，</p><p>由于接口查询耗时太长，当前仅采用单机jmeter 进行压测，模拟100QPS的执行情况，</p><p><a href="img_1.png" title="img_1.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_1.png" alt="img_1.png"></a></p><p><a href="img_2.png" title="img_2.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_2.png" alt="img_2.png"></a></p><p><a href="img_3.png" title="img_3.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_3.png" alt="img_3.png"></a></p><p><a href="img_4.png" title="img_4.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_4.png" alt="img_4.png"></a></p><p>从报告中我们可以看到，100次查询请求，平均耗时接近160秒。</p><p>性能问题所带来的严重影响：</p><p>这严重影响了用户的工作效率和体验。 是严重的生产问题。</p><p>面对这一问题，我们需要寻找优化的解决方案，以提升组织机构树查询的性能和响应速度。</p><p>这涉及到在数据库层面、缓存层面以及网关层面进行针对性的优化措施。</p><p>通过优化数据库表结构、使用缓存技术、合理配置网关等手段，我们可以显著改善组织机构树查询的效率和用户体验。</p><p>接下来， 尼恩团队带大家开始，一步一步的进行优化。</p><h2 id="用户中台性能优化的常规思路">用户中台性能优化的常规思路</h2><p>首先，梳理一下用户中台性能优化的常规思路。</p><p>常见的优化思路如下：</p><ul><li>统一数据源：建立一个中心化的组织机构数据源，将所有部门和团队的组织机构数据集中存储，确保数据的一致性和准确性。</li><li>数据库优化：设计合适的数据库表结构和索引，以支持高效的组织机构查询操作。使用合适的数据库技术和优化方法，如垂直拆分或水平拆分等，来提高查询性能。</li><li>缓存机制：使用缓存来存储组织机构数据，如Redis等。通过合理的缓存策略，如设置适当的过期时间、使用LRU算法等，减少对数据库的频繁查询，提高查询效率。</li><li>分布式架构：采用分布式架构，将查询负载分散到多个节点上，通过水平扩展来提高查询性能和并发处理能力。</li><li>异步处理：对于复杂的组织机构查询，可以将其放入异步任务队列中处理，减少前端请求的等待时间，提高系统的并发处理能力。</li><li>数据同步机制：确保组织机构数据的同步和更新的及时性，使用合适的数据同步技术和机制，如定时任务、事件驱动等，保证数据的一致性。</li><li>前端优化：采用前端技术和界面设计优化，如数据分页加载、懒加载等方式，减少一次性加载大量组织机构数据所带来的性能压力。<br>本文将深入探讨针对大型科技公司中组织机构树数据量过大所引发的问题，并提供一系列优化方案。通过这些优化措施，我们将帮助您克服组织机构树查询中的困难，使您能够更快速、高效地获取所需的组织机构信息，提升工作效率和决策能力。</li></ul><p>接下来，本文将带着大家一起实践组织架构树的优化!</p><h3 id="第一轮优化：数据库层面优化，提升60倍">第一轮优化：数据库层面优化，提升60倍</h3><p>数据库优化是解决大型科技公司组织机构查询问题的重要一环。下面是一些详细的数据库优化策略和技术：</p><ul><li>合适的表结构设计：<br>根据组织机构的特点，设计合适的表结构，以支持高效的查询操作。可以采用适当的关系型数据库或者NoSQL数据库，根据具体需求选择合适的数据库引擎。<br>使用范式化或者反范式化的设计方式，根据查询需求和数据一致性的要求来决定表结构的规范化程度。<br>使用合适的数据类型来存储组织机构数据，以节省存储空间并提高查询效率。</li><li>索引优化：<br>通过创建合适的索引来加速组织机构查询。根据查询的字段和条件，为经常被用于查询的列创建索引，以提高查询的速度。<br>选择适当的索引类型，如B-tree索引、哈希索引或者全文索引，根据具体查询的需求和数据的特点做出选择。<br>定期进行索引维护和优化，包括索引重建、碎片整理等操作，以保持索引的性能。</li><li>查询优化：<br>编写高效的查询语句，使用合适的SQL语法和操作符，避免不必要的查询或子查询，提高查询的效率。<br>使用合适的查询缓存机制，如数据库自带的查询缓存或者第三方缓存工具，以减少对数据库的频繁查询。<br>避免过度使用JOIN操作，尽量减少关联查询的复杂性。考虑使用预加载或延迟加载的方式，根据实际需求来优化查询操作。<br>分析查询执行计划，通过索引优化、表结构调整或者SQL重写等手段，改善查询执行计划的性能。</li><li>数据分区和分片：<br>如果组织机构数据量非常大，可以考虑将数据分区或者分片存储。通过按照一定规则将数据拆分为多个分区或者分片，提高查询的并行度和扩展性。<br>使用分区表或者分片表的方式，将数据均匀地分布到多个物理存储设备或者数据库实例中，提高查询的性能和响应时间。</li><li>定期数据清理和维护：<br>定期清理不再使用的数据，如过期的组织机构信息或者历史数据。通过删除或者归档这些数据，可以减少数据库的存储压力和提高查询性能。<br>定期进行数据库的维护工作，包括备份、日志清理、统计信息更新等操作，以保持数据库的健康状态和性能。<br>一般组织机构对应的表结构如下所示：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `department` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `name` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">COLLATE</span> utf8mb4_unicode_ci <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `parent_id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">COLLATE</span> utf8mb4_unicode_ci <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `remark` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">COLLATE</span> utf8mb4_unicode_ci <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `created_at` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `deleted` tinyint(<span class="number">1</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  KEY `department_parent_id_IDX` (`parent_id`) <span class="keyword">USING</span> BTREE</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 <span class="keyword">COLLATE</span><span class="operator">=</span>utf8mb4_unicode_ci COMMENT<span class="operator">=</span><span class="string">&#x27;部门&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在这个表结构中，每个目录节点都有一个唯一的id标识和一个name字段表示部门的名称。</p><p>parent_id字段表示该节点的父节点的id。根节点可以通过parent_id为0来表示。</p><p>注意添加parent_id为索引，加快查询效率。</p><p>通过这种表结构，可以使用递归查询或者多级查询来构建整个树的结构。</p><p>例如，通过以下查询可以获取第一层目录树：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> department <span class="keyword">WHERE</span> parent_id <span class="operator">=</span> <span class="string">&#x27;0L&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后，通过递归或者多级查询，可以根据每个节点的id值，获取其子节点。</p><p>我们预先生产了一万多条的测试数据，组织结构层级最大4级，</p><p><a href="img_5.png" title="img_5.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_5.png" alt="img_5.png"></a><br>获取组织机构树的示例代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> DepartmentDTO <span class="title function_">findAll</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">DepartmentDTO</span> <span class="variable">departmentDTO</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DepartmentDTO</span>();</span><br><span class="line">    departmentDTO.setId(<span class="number">0L</span>);</span><br><span class="line">    queryChildren(departmentDTO);</span><br><span class="line">    <span class="keyword">return</span> departmentDTO;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 递归查询</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">queryChildren</span><span class="params">(DepartmentDTO parent)</span> &#123;</span><br><span class="line">    List&lt;DepartmentPO&gt; children = departmentDao.queryByParentId(parent.getId());</span><br><span class="line">    <span class="keyword">if</span> (CollectionUtils.isEmpty(children)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (DepartmentPO po : children) &#123;</span><br><span class="line">        <span class="type">DepartmentDTO</span> <span class="variable">departmentDTO</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DepartmentDTO</span>();</span><br><span class="line">        BeanUtil.copyProperties(po, departmentDTO);</span><br><span class="line">        parent.getChildren().add(departmentDTO);</span><br><span class="line">        queryChildren(departmentDTO);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>回到优化之前，接下来调用接口获取组织树：<br><a href="img_6.png" title="img_6.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_6.png" alt="img_6.png"></a><br>优化之后，进行单次接口的 调用接口，数据如下：<br><a href="img_7.png" title="img_7.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_7.png" alt="img_7.png"></a><br>可以发现，通过降低SQL调用次数，接口耗时从70多s降低到了800ms左右。</p><p>接下来，我们同样对接口进行下压测，</p><p>压测后，聚合报告如下所示：<br><a href="img_8.png" title="img_8.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_8.png" alt="img_8.png"></a><br>聚合报告显示，100次查询请求平均耗时仅2秒多，且吞吐量提升近60倍。</p><p>当然我们还需要进一步优化，以减少接口耗时和提升吞吐量。</p><h2 id="第二步：应用层优化，提升70倍">第二步：应用层优化，提升70倍</h2><p>在第一步优化过程中，我们采用级联查询，从根节点查询下级子节点列表，再从下级子节点查询下下级节点，每次查询都要提交SQL到MySQL，相当于一次接口调用，后端需要发起上万次SQL请求，效率非常低下。</p><p>因此我们可以在应用服务里，每次查询一次性从数据库中获取所有数据，在内存里排序、拼装成树形数据，</p><p>代码示例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">queryChildren2</span><span class="params">(DepartmentDTO root)</span> &#123;</span><br><span class="line">    <span class="comment">// 一次性取出所有数据</span></span><br><span class="line">    List&lt;DepartmentPO&gt; list = departmentDao.findAll(Sort.by(<span class="string">&quot;parentId&quot;</span>, <span class="string">&quot;id&quot;</span>).ascending());</span><br><span class="line">    Map&lt;Long, DepartmentDTO&gt; departmentMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    departmentMap.put(root.getId(), root);</span><br><span class="line">    <span class="comment">// 遍历数据，组成树形结构</span></span><br><span class="line">    <span class="keyword">for</span>(DepartmentPO po : list) &#123;</span><br><span class="line">        <span class="type">DepartmentDTO</span> <span class="variable">departmentDTO</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DepartmentDTO</span>();</span><br><span class="line">        BeanUtil.copyProperties(po, departmentDTO);</span><br><span class="line">        departmentMap.put(po.getId(), departmentDTO);</span><br><span class="line">        <span class="type">DepartmentDTO</span> <span class="variable">parent</span> <span class="operator">=</span> departmentMap.get(po.getParentId());</span><br><span class="line">        parent.getChildren().add(departmentDTO);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>调用接口, 结果如下：<br><a href="img_9.png" title="img_9.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_9.png" alt="img_9.png"></a><br>可以看到，应用层优化后，接口的耗时从700多ms降低到100ms左右，基本已满足生产环境要求的接口耗时，接下来，我们还需要对接口进行压测</p><h2 id="第三步：分布式缓存优化，但是高并发场景失败率过高">第三步：分布式缓存优化，但是高并发场景失败率过高</h2><p>传统的数据库查询往往需要耗费大量的时间和资源，特别是在数据量庞大的情况下。</p><p>通过引入分布式缓存，我们可以将组织机构数据缓存在内存中，以避免频繁访问数据库的开销。</p><p>分布式缓存采用分布式架构，将数据存储在多个缓存节点中，每个节点都具备独立的内存和处理能力。</p><p>当进行组织机构查询时，首先检查缓存中是否存在相应的数据。</p><p>如果缓存中存在数据，则直接返回结果，避免了对数据库的查询操作。这样可以大大减少查询的响应时间，提高整体系统的性能。</p><p>在引入分布式缓存时，需要设计合理的缓存策略和数据更新机制。</p><p>可以采用缓存失效策略，设置合适的缓存过期时间，确保缓存中的数据与数据库的数据保持一致。当组织机构数据发生变化时，及时更新缓存，保证查询结果的准确性。</p><p>此外，还可以考虑使用分布式缓存技术如Redis或Memcached，并进行合理的缓存数据划分和数据分片，以实现横向扩展和负载均衡。这样可以提高系统的可伸缩性和容错性，应对高并发访问和大规模组织机构数据的查询需求。</p><p>总之，引入分布式缓存是一种高效的优化策略，通过减少对数据库的访问次数和加速查询响应，可以极大地提升组织机构查询的效率和响应时间，从而提高整体系统的性能和用户体验。</p><p>首先，我们尝试在接口调用时，使用redis缓存组织结构树，之后每次接口请求时，都优先查询缓存，</p><p>代码示例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> DepartmentDTO <span class="title function_">findAll</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 查询缓存</span></span><br><span class="line">    <span class="type">DepartmentDTO</span> <span class="variable">departmentDTO</span> <span class="operator">=</span> (DepartmentDTO) redisTemplate.opsForValue().get(DEPARTMENT_CACHE_KEY);</span><br><span class="line">    <span class="comment">// 缓存不存在则查询数据库</span></span><br><span class="line">    <span class="keyword">if</span> (Objects.isNull(departmentDTO)) &#123;</span><br><span class="line">        departmentDTO = <span class="keyword">new</span> <span class="title class_">DepartmentDTO</span>();</span><br><span class="line">        departmentDTO.setId(<span class="number">0L</span>);</span><br><span class="line">        queryChildren2(departmentDTO);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 更新缓存</span></span><br><span class="line">    redisTemplate.opsForValue().set(DEPARTMENT_CACHE_KEY, departmentDTO, <span class="number">1</span>, TimeUnit.MINUTES);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> departmentDTO;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用分布式 jmeter集群的方式来进行压测<br>为了模拟高并发场景，使用分布式 jmeter集群的方式来进行压测。</p><p>由于单台jmeter压测受限于本地机器的CPU，内存，网络及其他原因，需要采用jmeter集群的方式来进行压测。</p><p>这里我们将参考《 调优圣经：零基础精通Jmeter分布式压测，10Wqps+超高并发 》这篇文章，利用Jmeter集群来进行压测，</p><p>Jemter集群采用docker-compose的方式搭建，</p><p>在本机新建jmeter文件夹，在文件夹下创建jmeter-master文件夹，<br><a href="img_10.png" title="img_10.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_10.png" alt="img_10.png"></a></p><p>docker-compose.yml内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3.9&quot;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">jmeter-master:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zhangyx1619/jmeter-master:orcaljdk17-jmeter5.5-graphs-plugins-release</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;./jmeter-master:/usr/local/jmeter/apache-jmeter-5.5/work_space/&quot;</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">swarmnet</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">jmeter-master</span></span><br><span class="line">    <span class="attr">deploy:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">com.service.name=jmeter-master</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">global</span></span><br><span class="line">      <span class="attr">update_config:</span></span><br><span class="line">        <span class="attr">parallelism:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">delay:</span> <span class="string">1s</span></span><br><span class="line">        <span class="attr">failure_action:</span> <span class="string">rollback</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">jmeter-slave01:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zhangyx1619/jmeter-slave:orcaljdk17-jmeter5.5-graphs-plugins-release</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">jmeter-slave01:/usr/local/jmeter/apache-jmeter-5.5/</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">swarmnet</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">jmeter-slave01</span></span><br><span class="line">    <span class="attr">deploy:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">global</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">com.service.name=jmeter-slave01</span></span><br><span class="line">      <span class="attr">update_config:</span></span><br><span class="line">        <span class="attr">parallelism:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">delay:</span> <span class="string">1s</span></span><br><span class="line">        <span class="attr">failure_action:</span> <span class="string">rollback</span></span><br><span class="line">  <span class="attr">jmeter-slave02:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zhangyx1619/jmeter-slave:orcaljdk17-jmeter5.5-graphs-plugins-release</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">jmeter-slave02:/usr/local/jmeter/apache-jmeter-5.5/</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">swarmnet</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">jmeter-slave02</span></span><br><span class="line">    <span class="attr">deploy:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">global</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">com.service.name=jmeter-slave02</span></span><br><span class="line">      <span class="attr">update_config:</span></span><br><span class="line">        <span class="attr">parallelism:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">delay:</span> <span class="string">1s</span></span><br><span class="line">        <span class="attr">failure_action:</span> <span class="string">rollback</span></span><br><span class="line">  <span class="attr">jmeter-slave03:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zhangyx1619/jmeter-slave:orcaljdk17-jmeter5.5-graphs-plugins-release</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">jmeter-slave03:/usr/local/jmeter/apache-jmeter-5.5/</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">swarmnet</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">jmeter-slave03</span></span><br><span class="line">    <span class="attr">deploy:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">global</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">com.service.name=jmeter-slave03</span></span><br><span class="line">      <span class="attr">update_config:</span></span><br><span class="line">        <span class="attr">parallelism:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">delay:</span> <span class="string">1s</span></span><br><span class="line">        <span class="attr">failure_action:</span> <span class="string">rollback</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">swarmnet:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">jmeter-slave01:</span></span><br><span class="line">  <span class="attr">jmeter-slave02:</span></span><br><span class="line">  <span class="attr">jmeter-slave03:</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在当前jemeter目录打开终端，运行docker命令, 启动容器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker compose up -d</span><br></pre></td></tr></table></figure><p>启动后，容器详情如下：<br><a href="img_11.png" title="img_11.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_11.png" alt="img_11.png"></a><br>其中包含一个主节点和4个子节点。</p><p>接下来，修改jmx脚本， 线程组的线程数我们调大到1000， 这样的话，4个子节点分别发起1000次请求，相当于是模拟4000 QPS 压测，<br><a href="img_12.png" title="img_12.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_12.png" alt="img_12.png"></a></p><p>点击左上角文件 -&gt; 保存 , 将当前jmeter脚本department.jmx 文件，保存到jmeter-master文件夹下，<br><a href="img_13.png" title="img_13.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_13.png" alt="img_13.png"></a><br>ok，到这里一切准备就绪后，就可以开始执行压测命令，</p><p>在终端运行如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it jemeter-jmeter-master-1 jmeter  -n -t /usr/local/jmeter/apache-jmeter-5.5/work_space/department.jmx -r -l /usr/local/jmeter/apache-jmeter-5.5/work_space/department.jtl -e -o /usr/local/jmeter/apache-jmeter-5.5/work_space/html/ </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这是一个使用Docker执行JMeter性能测试的命令，具体含义如下：</p><ul><li>docker exec: 运行一个命令在Docker容器中执行操作。</li><li>-it: 分配一个交互式终端，并将其连接到容器的输入和输出，以便与JMeter进行交互。</li><li>jemeter-jmeter-master-1: Docker容器的名称或ID，指定要执行命令的目标容器，这里是主节点容器名称。</li><li>jmeter: 要执行的命令，这里是执行JMeter性能测试。</li><li>-n: 在非GUI模式下运行JMeter。</li><li>-t /usr/local/jmeter/apache-jmeter-5.5/work_space/department.jmx: 指定要运行的JMX测试计划文件的路径和文件名。</li><li>-r: 运行以分布式方式执行测试。</li><li>-l /usr/local/jmeter/apache-jmeter-5.5/work_space/department.jtl: 指定测试结果的日志文件路径和文件名。</li><li>-e: 生成HTML格式的测试报告。</li><li>-o /usr/local/jmeter/apache-jmeter-5.5/work_space/html/: 指定生成的HTML测试报告的输出目录路径。<br>通过这个命令，您可以在指定的Docker容器中执行JMeter性能测试，并生成相应的测试结果日志和HTML报告。请注意，命令中的文件路径和名称需要根据实际情况进行修改。</li></ul><p>执行过程如下图所示：</p><p><a href="img_14.png" title="img_14.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_14.png" alt="img_14.png"></a><br>查看生成的报告<br><a href="img_16.png" title="img_16.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_16.png" alt="img_16.png"></a><br>我们可以看到，4台jmeter节点模拟1000个并发，一共是4000并发，Fail的占比90%多，</p><p>服务器会出现大量的异常，<br><a href="img_17.png" title="img_17.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_17.png" alt="img_17.png"></a><br>根因分析：</p><p>异常的原因是redis读取超时，因为一个键值对的数据量比较大，导致redis出现了BigKey问题，我们需要进一步优化</p><p>狼来了： BigKey问题来了</p><h2 id="第四步：BigKey问题优化，4000并发场景到100ms">第四步：BigKey问题优化，4000并发场景到100ms</h2><p>在Redis中，BigKey指的是占用大量内存空间的键值对。当一个键值对的数据量过大，超过Redis的配置限制或者内存容量时，就称之为BigKey。</p><p>BigKey会导致以下问题：</p><p>内存占用过高：BigKey占用大量内存空间，可能导致Redis服务器的内存资源紧张，影响其他操作和缓存数据的存储。<br>延迟和性能下降：由于读写大型BigKey的数据需要较长的时间，会导致读写操作的延迟增加，并且消耗更多的CPU资源和网络带宽，影响系统的整体性能。<br>Redis持久化和备份问题：BigKey在进行持久化（如RDB快照或AOF日志）或备份时，会增加持久化和备份的时间和资源消耗。<br>解决BigKey问题的一些优化方法包括：</p><ul><li>数据拆分：将大型BigKey拆分成多个较小的键值对，根据数据的逻辑关联性和查询模式进行合理的拆分和分组。这样可以降低单个键值对的大小，减少内存占用。</li><li>分片存储：将数据分散存储在多个键中，使用合适的哈希函数或者分片算法，将数据均匀地分散到不同的键中，避免单个键值对过大。这样可以平衡数据的存储和访问压力。</li><li>数据压缩：对于可以压缩的数据类型（如字符串或JSON格式的数据），可以使用压缩算法（如LZF、Snappy、Gzip等）进行压缩，减少BigKey的内存占用。</li><li>数据分页和增量加载：对于查询结果过大的BigKey，可以采用数据分页或者增量加载的方式，只加载部分数据或者按需加载，以降低单次查询的数据量和内存消耗。</li><li>避免无意义的数据存储：避免将无需持久化或频繁变更的数据存储为BigKey，可以使用临时缓存或者其他数据存储方案。<br>通过合理的数据拆分、分片存储和压缩等优化方法，可以有效地解决BigKey问题，提高Redis的性能和资源利用率。</li></ul><p>因为在根节点下的第一级优10个组织，这10个组织分别有不同的子孙节点，我们可以尝试将单个key先拆分成10个key，每个key分别对应这10个组织及子节点数据。</p><p>示例代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> DepartmentDTO <span class="title function_">findAll</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">DepartmentDTO</span> <span class="variable">root</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DepartmentDTO</span>();</span><br><span class="line">    root.setId(<span class="number">0L</span>);</span><br><span class="line">    <span class="comment">// 从10个key里获取缓存数据，放入到根节点的children集合里</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i&lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        <span class="type">DepartmentDTO</span> <span class="variable">child</span> <span class="operator">=</span> (DepartmentDTO)  redisTemplate.opsForValue().get(DEPARTMENT_CACHE_KEY + i);</span><br><span class="line">        <span class="comment">// 没有缓存数据</span></span><br><span class="line">        <span class="keyword">if</span> (Objects.isNull(child)) &#123;</span><br><span class="line">            root.setChildren(<span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        root.getChildren().add(child);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (root.getChildren().size() == <span class="number">0</span>) &#123;</span><br><span class="line">       <span class="comment">// 查询数据库</span></span><br><span class="line">       queryChildren2(root);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据按照1级部门存储到10个key</span></span><br><span class="line">    List&lt;DepartmentDTO&gt; children = root.getChildren();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span> ; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        redisTemplate.opsForValue().set(DEPARTMENT_CACHE_KEY + i, children.get(i), <span class="number">1</span>, TimeUnit.HOURS);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> root;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>接下来，继续进行分布式压测：<br><a href="img_18.png" title="img_18.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_18.png" alt="img_18.png"></a><br>我们再来看下生成的报告：<br><a href="img_19.png" title="img_19.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_19.png" alt="img_19.png"></a><br>这时我们可以看到通过率从8%提升到70%多，如果我们将key的数量提升到100, 通过率将进一步提升。</p><p>有兴趣的同学可以来尝试继续优化直到通过率为100%。</p><h2 id="第五步：本地缓存优化，优化到20ms">第五步：本地缓存优化，优化到20ms</h2><p>在分布式缓存的基础上，引入本地缓存是进一步提升组织机构查询效率和响应时间的一种优化方案。</p><p>本地缓存是指将数据缓存在应用程序的内存中，以避免频繁地访问分布式缓存或数据库，从而快速响应查询请求。</p><p>引入本地缓存的好处是可以减少对分布式缓存的访问次数，从而降低网络延迟和通信开销。</p><p>当应用程序发起组织机构查询时，首先检查本地缓存中是否存在相应的数据。如果数据在本地缓存中命中，则无需进一步访问分布式缓存或数据库，可以直接返回结果，极大地提升了查询的效率和响应时间。</p><p>本地缓存的使用需要考虑以下几个关键因素：</p><ul><li>缓存策略：选择合适的缓存策略，如LRU（最近最少使用）、LFU（最近最不常用）等，以平衡内存使用和数据命中率。</li><li>缓存更新机制：在组织机构数据发生变化时，及时更新本地缓存。可以通过订阅数据库或分布式缓存的数据变更事件，保持本地缓存与数据源的一致性。</li><li>缓存失效处理：设置合理的缓存失效时间，以确保缓存中的数据不过期。可以根据数据更新的频率和重要性进行调整。</li><li>内存管理：合理管理本地缓存使用的内存，避免因缓存过多导致内存溢出或应用程序性能下降的问题。<br>引入本地缓存的优化方案需要综合考虑应用程序的特点、数据的更新频率和一致性要求。合理使用本地缓存可以减少对分布式缓存和数据库的访问，提升组织机构查询的效率和响应时间，从而提高系统的整体性能和用户体验。</li></ul><p>在当前SpringBoot框架下，可以通过以下步骤集成Caffeine作为本地缓存：</p><ul><li>1.添加Caffeine依赖：在pom.xml文件中添加Caffeine的依赖项:</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.github.ben-manes.caffeine<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>caffeine<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>2.创建缓存配置类：创建一个Java类，用于配置Caffeine缓存</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.cache.CacheManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cache.annotation.EnableCaching;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cache.caffeine.CaffeineCacheManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> com.github.benmanes.caffeine.cache.Caffeine;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableCaching</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CacheConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Caffeine&lt;Object, Object&gt; <span class="title function_">caffeineConfig</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Caffeine.newBuilder()</span><br><span class="line">                .expireAfterWrite(<span class="number">10</span>, TimeUnit.MINUTES) <span class="comment">// 设置缓存失效时间为10分钟</span></span><br><span class="line">                .maximumSize(<span class="number">10_000</span>) <span class="comment">// 设置缓存的最大容量为10_000</span></span><br><span class="line">                .recordStats(); <span class="comment">// 启用统计信息，可通过Cache.stats()获取缓存命中率等统计数据</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> CacheManager <span class="title function_">cacheManager</span><span class="params">(Caffeine&lt;Object, Object&gt; caffeine)</span> &#123;</span><br><span class="line">        <span class="type">CaffeineCacheManager</span> <span class="variable">cacheManager</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CaffeineCacheManager</span>();</span><br><span class="line">        cacheManager.setCaffeine(caffeine);</span><br><span class="line">        <span class="keyword">return</span> cacheManager;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在上面的示例中，我们配置了一个名为&quot;cacheManager&quot;的缓存管理器，使用了Caffeine作为底层的缓存实现，并设置了缓存的失效时间和最大容量。</p><ul><li>3.使用缓存：在需要缓存的方法上添加@Cacheable注解，以告诉Spring应该缓存该方法的返回值。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Cacheable(&quot;department-cache&quot;)</span></span><br><span class="line"><span class="keyword">public</span> DepartmentDTO <span class="title function_">findAll</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 省略其它代码</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在上述示例中，findAll方法会首先检查名为&quot;department-cache&quot;的缓存中是否存在对应的数据。如果存在，直接从缓存中返回数据；如果缓存中不存在，则执行方法体的逻辑，并将返回值缓存起来供下次使用。</p><p>同样我们调用下接口，看下执行时间<br><a href="img_20.png" title="img_20.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_20.png" alt="img_20.png"></a><br>由于采用本地缓存，耗时几乎忽略不计。</p><p>接下来，继续执行下jmeter集群压测，压测报告如下所示：<br><a href="img_21.png" title="img_21.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//img_21.png" alt="img_21.png"></a></p><p>优化总结<br>如果本地缓存命中， 经过这一轮优化， 性能提升到 20ms，提升700倍</p><p>如果本地缓存位命中， 经过上一轮优化， 性能提升到 100ms ，提升3500倍</p><h2 id="第六步：网关层面的优化">第六步：网关层面的优化</h2><p>除了数据库、缓存、bigkey打散、本地缓存优化之外，还有很多其他的优化：</p><ul><li>网关层面的优化</li><li>系统层面的优化等等。<br>接下来说一下网关层面的优化。</li></ul><p>在网关层面进行优化可以提高组织机构树接口查询的性能和可扩展性。</p><p>以下是一些优化方案：<br>1、Nginx压缩：</p><p>在Nginx配置中启用压缩功能，将响应数据进行压缩，减少数据传输的大小，提高网络传输效率和响应速度。<br>配置gzip指令开启压缩，可以设置合适的压缩级别和压缩类型。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    gzip on;</span><br><span class="line">    gzip_types text/plain text/css application/json;</span><br><span class="line">    gzip_comp_level 5;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2、网关缓存：<br>在Nginx中，可以通过配置代理缓存来缓存接口的响应结果。以下是详细的步骤：</p><h2 id="一-启用代理缓存：">一.启用代理缓存：</h2><p>在Nginx的配置文件中，开启代理缓存功能并定义一个缓存区域。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>/path/to/cache：指定缓存存储路径。</li><li>levels=1:2：定义缓存路径层级。</li><li>keys_zone=my_cache:10m：为缓存区域指定一个名称（my_cache）和分配的内存大小（10MB）。</li><li>max_size=10g：设置缓存区域的最大容量为10GB。</li><li>inactive=60m：指定缓存项在60分钟内没有被访问时被认为是过期的。</li><li>use_temp_path=off：禁止使用临时路径。</li></ul><p>二.配置代理缓存：<br>在Nginx的配置文件中，为需要缓存的接口添加缓存配置。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  server &#123;</span><br><span class="line">    location /api/department &#123;</span><br><span class="line">        proxy_cache my_cache;</span><br><span class="line">        proxy_cache_valid 200 1d;</span><br><span class="line">        proxy_pass http://backend_server;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>proxy_cache my_cache：指定使用前面定义的缓存区域（my_cache）进行缓存。</li><li>proxy_cache_valid 200 1d：设置缓存有效期为1天，对于状态码为200的响应进行缓存。</li><li>proxy_pass http://backend_server：指定反向代理的目标后端服务器。<br>三，清除缓存：<br>如果需要手动清除缓存，可以使用Nginx的proxy_cache_purge模块，通过发送特定请求来清除缓存。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location /purge-cache &#123;</span><br><span class="line">    proxy_cache_purge my_cache &quot;$scheme$request_method$host$request_uri&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>proxy_cache_purge：启用proxy_cache_purge模块。</li><li>my_cache：指定要清除的缓存区域。</li><li>“$scheme$request_method$host$request_uri”：指定要清除的缓存键值。</li></ul><p>通过上述配置，Nginx会在接收到请求时先查看缓存，如果缓存中存在对应的响应，则直接返回缓存的结果，减少对后端服务的请求。如果缓存中不存在或已过期，则会转发请求到后端服务，并将响应结果缓存起来，以供后续相同请求使用。</p><p>请注意，缓存接口需要根据具体的业务需求和接口特性进行配置。需要根据接口的频率、数据更新频率和缓存策略进行合理的调整。</p><p>对于动态生成的树形数据页面，也可以采用页面缓存技术，将页面内容缓存到CDN或其他缓存中，并设置合适的缓存过期时间。</p><h2 id="从70s到20ms调优小结">从70s到20ms调优小结</h2><p>针对组织结构树的优化设计，我们可以在数据库层面、缓存层面和NGINX网关层面进行优化，以提高查询性能和系统的可伸缩性。</p><p>在数据库层面，我们可以采取以下优化设计：</p><p>使用适当的表结构和索引，优化组织结构树的存储和查询效率。<br>考虑采用合适的分库分表策略，将数据水平拆分，减少单表数据量。<br>针对组织结构树的查询，使用适当的查询语句和优化技巧，如递归查询、嵌套集模型等。<br>在缓存层面，我们可以采取以下优化设计：</p><p>使用Redis等缓存技术，将组织结构树的数据缓存在内存中，减少对数据库的访问次数。<br>针对频繁访问的组织结构树数据，设置合适的缓存过期时间和缓存策略。<br>使用合理的缓存命名规则和缓存键设计，确保缓存的准确性和一致性。<br>在NGINX网关层面，我们可以采取以下优化设计：</p><p>使用Nginx的压缩功能，减小响应数据的大小，提高网络传输效率。<br>使用CDN缓存静态资源，减轻网关和后端服务器的负载，加速资源传输。<br>配置代理缓存，将组织结构树接口的响应结果缓存起来，减少对后端服务的请求。<br>设置适当的负载均衡机制，分发请求到多个后端服务实例，提高系统的可扩展性和容错性。<br>综合上述优化设计，可以大大提升组织结构树接口的查询性能和系统的可伸缩性。通过数据库的优化，可以提高数据的存储和查询效率；通过缓存的优化，可以减少对数据库的访问次数；通过网关层面的优化，可以降低网络传输成本和后端服务的负载压力。这些综合的优化措施将显著改善系统的整体性能和用户体验。</p><p>=============================================================</p><h1>应用（Application）部署容器化演进之路</h1><h1>一、应用程序部署痛点</h1><h2 id="1-1-应用程序部署流程">1.1 应用程序部署流程</h2><p><strong>举例：部署一个JAVA编程语言开发的Web应用，以War包放入Tomcat方式部署。</strong></p><ul><li>部署过程如下：<ul><li>服务器配置运行环境:JAVA代码运行环境，例如JDK或JRE</li><li>服务器上安装Tomcat web中间件，用于运行War包</li><li>把JAVA Web对应的War包放置于Tomcat对应目录</li><li>在服务器上启动Tomcat应用</li><li>可选：涉及数据库（MySQL）或缓存系统(Redis)等都需要逐一部署。</li></ul></li></ul><h2 id="1-2-应用程序扩缩容">1.2 应用程序扩缩容</h2><ul><li>涉及多台服务器部署相同的上述环境</li><li>痛点：上述环境部署要重新实施一遍，较浪费人力与物力成本</li></ul><h2 id="1-3-应用程序多环境部署">1.3 应用程序多环境部署</h2><ul><li>环境：本地测试环境、预发布环境、生产环境</li><li>在本地测试环境运行没有问题，但在预发布环境中出现了问题，甚至上面2种环境都没有问题，到了生产环境就有问题了。</li><li>需求：一次成功，可到处运行。</li></ul><h1>二、 计算资源应用演进过程</h1><h2 id="2-1-使用物理服务器痛点">2.1 使用物理服务器痛点</h2><p><a href="%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF.assets/image-20220118161531257.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//image-20220118161531257.png" alt></a></p><ul><li><p>从物理服务器自身管理角度</p><ul><li>物理服务器环境部署人力成本大，特别是在自动化手段不足的情况下，依靠人肉运维的方式解决。</li><li>当物理服务器出现宕机后，服务器重启时间过长，短则1-2分钟，长则3-5分钟，有背于服务器在线时长达到99.999999999%标准的要求</li><li>物理服务器在应用程序运行期间硬件出现故障，解决较麻烦</li><li>物理服务器计算资源不能有效调度使用，无法发挥其充足资源的优势</li></ul></li><li><p>从物理服务器部署应用程序角度</p><ul><li>物理服务器环境部署浪费时间，没有自动化运维手段，时间是成倍增加的</li><li>在物理服务器上进行应用程序配置变更，需要重新实施前述步骤</li></ul></li></ul><h2 id="2-2-使用虚拟机优点与缺点">2.2 使用虚拟机优点与缺点</h2><p><a href="%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF.assets/image-20220118161210084.png" title="image-20220118161210084" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//image-20220118161210084.png" alt="image-20220118161210084"></a></p><h3 id="2-2-1-使用虚拟机优秀点">2.2.1 使用虚拟机优秀点</h3><ul><li><p>从虚拟机本身管理角度</p><ul><li>虚拟机较物理服务器轻量，可借助虚拟机模板实现虚拟机快捷生成及应用</li><li>虚拟机中部署应用与物理服务器一样可控性强，且当虚拟机出现故障时，可直接使用新的虚拟机代替</li><li>在物理服务器中使用虚拟机可高效使用物理服务器的资源</li><li>虚拟机与物理服务器一样可达到良好的应用程序运行环境的隔离</li></ul></li><li><p>从在虚拟机中部署应用程序角度</p><ul><li>在虚拟机中部署应用，容易扩容及缩容实现</li><li>与物理服务器相比较，当部署应用程序的虚拟机出现宕机时，可以快速启动，时间通常可达秒级，10秒或20秒即可启动，应用程序可以继续提供服务</li><li>应用程序迁移方便</li></ul></li></ul><h3 id="2-2-2-使用虚拟机缺点">2.2.2 使用虚拟机缺点</h3><ul><li>虚拟机管理软件本身占用物理服务器计算资源较多，例如:VMware Workstation Pro就会占用物理服务器大量资源，所以一般在企业应用中使用KVM虚拟机较多。</li><li>虚拟机底层硬件消耗物理服务器资源较大，例如：虚拟机操作系统硬盘，会直接占用大量物理服务器硬盘空间</li><li>相较于容器技术，虚拟机启动时间过长，容器启动可按毫秒级计算</li><li>虚拟机对物理服务器硬件资源调用添加了调链条，存在浪费时间的现象，所以虚拟机性能弱于物理服务器</li><li>由于应用程序是直接部署在虚拟机硬盘上，应用程序迁移时，需要连同虚拟机硬盘中的操作系统一同迁移，会导致迁移文件过大，浪费更多的存储空间及时间消耗过长</li></ul><h2 id="2-3-使用容器的优点与缺点">2.3 使用容器的优点与缺点</h2><p><a href="%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF.assets/image-20220118161301903.png" title="image-20220118161301903" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//image-20220118161301903.png" alt="image-20220118161301903"></a></p><h3 id="2-3-1-使用容器的优点">2.3.1 使用容器的优点</h3><ul><li>不需要为容器安装操作系统，可以节约大量时间</li><li>不需要通过手动的方式在容器中部署应用程序的运行环境，直接部署应用就可以了</li><li>不需要管理容器网络，以自动调用的方式访问容器中应用提供的服务</li><li>方便分享与构建应用容器，一次构建，到处运行</li><li>毫秒级启动</li><li>容器可直接使用物理服务器硬件资源，物理服务器硬件资源利用率高，性能较好。</li></ul><h3 id="2-3-2-使用容器的缺点">2.3.2 使用容器的缺点</h3><p>对于对使用物理服务器、虚拟机已成为习惯的小伙伴来说，容器化可控性不强，最直观的就是对容器管理访问，总想按物理服务器或虚拟机的方式去管理它，其实容器与物理服务器、虚拟机管理方式上有着本质的区别的，最好不要管理。</p><h1>三、 What is a Container?</h1><h2 id="3-1-容器定义">3.1 容器定义</h2><p><a href="%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF.assets/image-20220118161407959.png" title="image-20220118161407959" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E8%B0%83%E4%BC%98/%E6%8E%A5%E5%8F%A3%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98//image-20220118161407959.png" alt="image-20220118161407959"></a></p><ul><li><p>虚拟机</p><ul><li>采用虚拟化技术手段实现物理服务器计算资源打包的方式，为应用程序提供类物理服务器运行环境</li><li>能够实现应用程序与应用程序之间的隔离</li><li>使用自动化技术部署应用程序及应用程序迁移较方便</li><li>可横向扩展</li></ul></li><li><p>容器</p><ul><li>容器是轻量级物理服务器计算资源的打包方式，即轻量级虚拟机，为应用程序提供类虚拟机运行环境。</li><li>可在物理服务器中实现高密度部署</li></ul></li><li><p>容器与虚拟机对比</p></li></ul><table><thead><tr><th>对比属性</th><th>容器（Container）</th><th>虚拟机（VM）</th></tr></thead><tbody><tr><td>隔离性</td><td>基于进程隔离</td><td>提供资源的完全隔离</td></tr><tr><td>启动时间</td><td>毫秒级或秒级</td><td>秒级或分钟级</td></tr><tr><td>内核</td><td>共用宿主机内核</td><td>使用独立内核</td></tr><tr><td>占用资源</td><td>MB级</td><td>GB级</td></tr><tr><td>系统支持容量（同级别）</td><td>支持上千个容器</td><td>几十台虚拟机</td></tr></tbody></table><h2 id="3-2-容器功能">3.2 容器功能</h2><ul><li><p>安装容器管理工具，例如Docker,Containerd等，把应用以容器化的方式运行</p></li><li><p>应用在自己的容器中运行，实现应用程序间隔离</p></li><li><p>应用程序运行的容器可以生成应用程序模板文件，即容器镜像（Image），其不可变，即为云原生代表技术基础设施不可变,且可以在其它的物理服务器中运行。</p></li></ul><h2 id="3-3-容器解决了什么问题">3.3 容器解决了什么问题</h2><ul><li>快速交付和部署应用 (镜像与容器)</li><li>资源的高效利用和隔离 (在物理机上实现高密度部署)</li><li>便捷迁移和扩缩容(一次构建，多处运行)</li></ul><h1>四、使用容器步骤</h1><ul><li><p>安装容器管理工具</p><ul><li>Docker   (Docker公司)</li><li>Containerd  (2017年docker捐给CNCF云原生计算基金会)</li><li>Pouch  (阿里云)</li></ul></li><li><p>搜索/下载容器镜像(Image)</p></li><li><p>使用容器镜像生成容器(容器镜像中的应用程序启动)</p></li><li><p>终端用户(互联网用户或其它应用程序)访问</p></li><li><p>迁移部署(可直接把正在运行的容器打包成新的容器镜像，在其它主机上运行即可。)</p></li></ul></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;p&gt;用户中台的性能问题&lt;br&gt;
在一个大型科技公司用户中台中，组织机构扮演着至关重要的角色，涉及到多个部门、团队和员工的关系和层级。&lt;/p&gt;
&lt;p&gt;然而，随着公司规模的不断扩大和组织结构的复杂性增加，组织机构树的数据量</summary>
      
    
    
    
    <category term="系统调优" scheme="https://0914ds.github.io/categories/%E7%B3%BB%E7%BB%9F%E8%B0%83%E4%BC%98/"/>
    
    
  </entry>
  
  <entry>
    <title>容器的演进发展</title>
    <link href="https://0914ds.github.io/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/"/>
    <id>https://0914ds.github.io/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/</id>
    <published>2023-06-04T10:17:28.000Z</published>
    <updated>2023-06-22T07:11:29.022Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>应用（Application）部署容器化演进之路</h1><h1>一、应用程序部署痛点</h1><h2 id="1-1-应用程序部署流程">1.1 应用程序部署流程</h2><p><strong>举例：部署一个JAVA编程语言开发的Web应用，以War包放入Tomcat方式部署。</strong></p><ul><li>部署过程如下：<ul><li>服务器配置运行环境:JAVA代码运行环境，例如JDK或JRE</li><li>服务器上安装Tomcat web中间件，用于运行War包</li><li>把JAVA Web对应的War包放置于Tomcat对应目录</li><li>在服务器上启动Tomcat应用</li><li>可选：涉及数据库（MySQL）或缓存系统(Redis)等都需要逐一部署。</li></ul></li></ul><h2 id="1-2-应用程序扩缩容">1.2 应用程序扩缩容</h2><ul><li>涉及多台服务器部署相同的上述环境</li><li>痛点：上述环境部署要重新实施一遍，较浪费人力与物力成本</li></ul><h2 id="1-3-应用程序多环境部署">1.3 应用程序多环境部署</h2><ul><li>环境：本地测试环境、预发布环境、生产环境</li><li>在本地测试环境运行没有问题，但在预发布环境中出现了问题，甚至上面2种环境都没有问题，到了生产环境就有问题了。</li><li>需求：一次成功，可到处运行。</li></ul><h1>二、 计算资源应用演进过程</h1><h2 id="2-1-使用物理服务器痛点">2.1 使用物理服务器痛点</h2><p><a href="%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF.assets/image-20220118161531257.png" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF//image-20220118161531257.png" alt></a></p><ul><li><p>从物理服务器自身管理角度</p><ul><li>物理服务器环境部署人力成本大，特别是在自动化手段不足的情况下，依靠人肉运维的方式解决。</li><li>当物理服务器出现宕机后，服务器重启时间过长，短则1-2分钟，长则3-5分钟，有背于服务器在线时长达到99.999999999%标准的要求</li><li>物理服务器在应用程序运行期间硬件出现故障，解决较麻烦</li><li>物理服务器计算资源不能有效调度使用，无法发挥其充足资源的优势</li></ul></li><li><p>从物理服务器部署应用程序角度</p><ul><li>物理服务器环境部署浪费时间，没有自动化运维手段，时间是成倍增加的</li><li>在物理服务器上进行应用程序配置变更，需要重新实施前述步骤</li></ul></li></ul><h2 id="2-2-使用虚拟机优点与缺点">2.2 使用虚拟机优点与缺点</h2><p><a href="%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF.assets/image-20220118161210084.png" title="image-20220118161210084" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF//image-20220118161210084.png" alt="image-20220118161210084"></a></p><h3 id="2-2-1-使用虚拟机优秀点">2.2.1 使用虚拟机优秀点</h3><ul><li><p>从虚拟机本身管理角度</p><ul><li>虚拟机较物理服务器轻量，可借助虚拟机模板实现虚拟机快捷生成及应用</li><li>虚拟机中部署应用与物理服务器一样可控性强，且当虚拟机出现故障时，可直接使用新的虚拟机代替</li><li>在物理服务器中使用虚拟机可高效使用物理服务器的资源</li><li>虚拟机与物理服务器一样可达到良好的应用程序运行环境的隔离</li></ul></li><li><p>从在虚拟机中部署应用程序角度</p><ul><li>在虚拟机中部署应用，容易扩容及缩容实现</li><li>与物理服务器相比较，当部署应用程序的虚拟机出现宕机时，可以快速启动，时间通常可达秒级，10秒或20秒即可启动，应用程序可以继续提供服务</li><li>应用程序迁移方便</li></ul></li></ul><h3 id="2-2-2-使用虚拟机缺点">2.2.2 使用虚拟机缺点</h3><ul><li>虚拟机管理软件本身占用物理服务器计算资源较多，例如:VMware Workstation Pro就会占用物理服务器大量资源，所以一般在企业应用中使用KVM虚拟机较多。</li><li>虚拟机底层硬件消耗物理服务器资源较大，例如：虚拟机操作系统硬盘，会直接占用大量物理服务器硬盘空间</li><li>相较于容器技术，虚拟机启动时间过长，容器启动可按毫秒级计算</li><li>虚拟机对物理服务器硬件资源调用添加了调链条，存在浪费时间的现象，所以虚拟机性能弱于物理服务器</li><li>由于应用程序是直接部署在虚拟机硬盘上，应用程序迁移时，需要连同虚拟机硬盘中的操作系统一同迁移，会导致迁移文件过大，浪费更多的存储空间及时间消耗过长</li></ul><h2 id="2-3-使用容器的优点与缺点">2.3 使用容器的优点与缺点</h2><p><a href="%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF.assets/image-20220118161301903.png" title="image-20220118161301903" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF//image-20220118161301903.png" alt="image-20220118161301903"></a></p><h3 id="2-3-1-使用容器的优点">2.3.1 使用容器的优点</h3><ul><li>不需要为容器安装操作系统，可以节约大量时间</li><li>不需要通过手动的方式在容器中部署应用程序的运行环境，直接部署应用就可以了</li><li>不需要管理容器网络，以自动调用的方式访问容器中应用提供的服务</li><li>方便分享与构建应用容器，一次构建，到处运行</li><li>毫秒级启动</li><li>容器可直接使用物理服务器硬件资源，物理服务器硬件资源利用率高，性能较好。</li></ul><h3 id="2-3-2-使用容器的缺点">2.3.2 使用容器的缺点</h3><p>对于对使用物理服务器、虚拟机已成为习惯的小伙伴来说，容器化可控性不强，最直观的就是对容器管理访问，总想按物理服务器或虚拟机的方式去管理它，其实容器与物理服务器、虚拟机管理方式上有着本质的区别的，最好不要管理。</p><h1>三、 What is a Container?</h1><h2 id="3-1-容器定义">3.1 容器定义</h2><p><a href="%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF.assets/image-20220118161407959.png" title="image-20220118161407959" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%BA%94%E7%94%A8%EF%BC%88APP%EF%BC%89%E9%83%A8%E7%BD%B2%E5%AE%B9%E5%99%A8%E5%8C%96%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF//image-20220118161407959.png" alt="image-20220118161407959"></a></p><ul><li><p>虚拟机</p><ul><li>采用虚拟化技术手段实现物理服务器计算资源打包的方式，为应用程序提供类物理服务器运行环境</li><li>能够实现应用程序与应用程序之间的隔离</li><li>使用自动化技术部署应用程序及应用程序迁移较方便</li><li>可横向扩展</li></ul></li><li><p>容器</p><ul><li>容器是轻量级物理服务器计算资源的打包方式，即轻量级虚拟机，为应用程序提供类虚拟机运行环境。</li><li>可在物理服务器中实现高密度部署</li></ul></li><li><p>容器与虚拟机对比</p></li></ul><table><thead><tr><th>对比属性</th><th>容器（Container）</th><th>虚拟机（VM）</th></tr></thead><tbody><tr><td>隔离性</td><td>基于进程隔离</td><td>提供资源的完全隔离</td></tr><tr><td>启动时间</td><td>毫秒级或秒级</td><td>秒级或分钟级</td></tr><tr><td>内核</td><td>共用宿主机内核</td><td>使用独立内核</td></tr><tr><td>占用资源</td><td>MB级</td><td>GB级</td></tr><tr><td>系统支持容量（同级别）</td><td>支持上千个容器</td><td>几十台虚拟机</td></tr></tbody></table><h2 id="3-2-容器功能">3.2 容器功能</h2><ul><li><p>安装容器管理工具，例如Docker,Containerd等，把应用以容器化的方式运行</p></li><li><p>应用在自己的容器中运行，实现应用程序间隔离</p></li><li><p>应用程序运行的容器可以生成应用程序模板文件，即容器镜像（Image），其不可变，即为云原生代表技术基础设施不可变,且可以在其它的物理服务器中运行。</p></li></ul><h2 id="3-3-容器解决了什么问题">3.3 容器解决了什么问题</h2><ul><li>快速交付和部署应用 (镜像与容器)</li><li>资源的高效利用和隔离 (在物理机上实现高密度部署)</li><li>便捷迁移和扩缩容(一次构建，多处运行)</li></ul><h1>四、使用容器步骤</h1><ul><li><p>安装容器管理工具</p><ul><li>Docker   (Docker公司)</li><li>Containerd  (2017年docker捐给CNCF云原生计算基金会)</li><li>Pouch  (阿里云)</li></ul></li><li><p>搜索/下载容器镜像(Image)</p></li><li><p>使用容器镜像生成容器(容器镜像中的应用程序启动)</p></li><li><p>终端用户(互联网用户或其它应用程序)访问</p></li><li><p>迁移部署(可直接把正在运行的容器打包成新的容器镜像，在其它主机上运行即可。)</p></li></ul></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;应用（Application）部署容器化演进之路&lt;/h1&gt;
&lt;h1&gt;一、应用程序部署痛点&lt;/h1&gt;
&lt;h2 id=&quot;1-1-应用程序部署流程&quot;&gt;1.1 应用程序部署流程&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;举例：部署</summary>
      
    
    
    
    <category term="容器" scheme="https://0914ds.github.io/categories/%E5%AE%B9%E5%99%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>容器技术所涉及Linux内核关键技术</title>
    <link href="https://0914ds.github.io/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E6%89%80%E6%B6%89%E5%8F%8ALinux%E5%86%85%E6%A0%B8%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    <id>https://0914ds.github.io/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E6%89%80%E6%B6%89%E5%8F%8ALinux%E5%86%85%E6%A0%B8%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/</id>
    <published>2023-06-04T10:17:27.000Z</published>
    <updated>2023-06-22T07:11:46.619Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>容器技术所涉及Linux内核关键技术</h1><h1>一、容器技术前世今生</h1><h2 id="1-1-1979年-—-chroot">1.1 1979年 — chroot</h2><ul><li>容器技术的概念可以追溯到1979年的UNIX chroot。</li><li>它是一套“UNIX操作系统”系统，旨在将其root目录及其它子目录变更至文件系统内的新位置，且只接受特定进程的访问。</li><li>这项功能的设计目的在于为每个进程提供一套隔离化磁盘空间。</li><li>1982年其被添加至BSD当中。</li></ul><h2 id="1-2-2000年-—-FreeBSD-Jails">1.2 2000年 — FreeBSD Jails</h2><ul><li>FreeBSD Jails是由Derrick T. Woolworth于2000年在FreeBSD研发协会中构建而成的早期容器技术之一。</li><li>这是一套“操作系统”系统，与chroot的定位类似，不过其中包含有其它进程沙箱机制以对文件系统、用户及网络等资源进行隔离。</li><li>通过这种方式，它能够为每个Jail、定制化软件安装包乃至配置方案等提供一个对应的IP地址。</li></ul><h2 id="1-3-2001年-—-Linux-VServer">1.3 2001年 — Linux VServer</h2><ul><li>Linux VServer属于另一种jail机制，其能够被用于保护计算机系统之上各分区资源的安全(包括文件系统、CPU时间、网络地址以及内存等)。</li><li>每个分区被称为一套安全背景(security context)，而其中的虚拟化系统则被称为一套虚拟私有服务器。</li></ul><h2 id="1-4-2004年-—-Solaris容器">1.4 2004年 — Solaris容器</h2><ul><li>Solaris容器诞生之时面向x86与SPARC系统架构，其最初亮相于2004年2月的Solaris 10 Build 51 beta当中，随后于2005年正式登陆Solaris 10的完整版本。</li><li>Solaris容器相当于将系统资源控制与由分区提供的边界加以结合。各分区立足于单一操作系统实例之内以完全隔离的虚拟服务器形式运行。</li></ul><h2 id="1-5-2005年-—-OpenVZ">1.5 2005年 — OpenVZ</h2><ul><li>OpenVZ与Solaris容器非常相似，且使用安装有补丁的Linux内核以实现虚拟化、隔离能力、资源管理以及检查点交付。</li><li>每套OpenVZ容器拥有一套隔离化文件系统、用户与用户群组、一套进程树、网络、设备以及IPC对象。</li></ul><h2 id="1-6-2006年-—-Process容器">1.6 2006年 — Process容器</h2><ul><li>Process容器于2006年由谷歌公司推出，旨在对一整套进程集合中的资源使用量(包括CPU、内存、磁盘I/O以及网络等等)加以限制、分配与隔离。</li><li>此后其被更名为Control Groups(即控制组)，从而避免其中的“容器”字眼与Linux内核2.6.24中的另一术语出现冲突。这表明了谷歌公司率先重视容器技术的敏锐眼光以及为其做出的突出贡献。</li></ul><h2 id="1-7-2007年-—-Control-Groups">1.7 2007年 — Control Groups</h2><p>Control Groups也就是谷歌实现的cgroups，其于2007年被添加至Linux内核当中。</p><h2 id="1-8-2008年-—-LXC">1.8 2008年 — LXC</h2><ul><li>LXC指代的是Linux Containers</li><li>是第一套完整的Linux容器管理实现方案。</li><li>其功能通过cgroups以及Linux namespaces实现。</li><li>LXC通过liblxc库进行交付，并提供可与Python3、Python2、Lua、Go、Ruby以及Haskell等语言相对接的API。</li><li>相较于其它容器技术，LXC能够在无需任何额外补丁的前提下运行在原版Linux内核之上。</li></ul><h2 id="1-9-2011年-—-Warden">1.9 2011年 — Warden</h2><ul><li>Warden由CloudFoundry公司于2011年所建立，其利用LXC作为初始阶段，随后又将其替换为自家实现方案。</li><li>与LXC不同，Warden并不会与Linux紧密耦合。相反，其能够运行在任意能够提供多种隔离环境方式的操作系统之上。Warden以后台进程方式运行并提供API以实现容器管理。</li></ul><h2 id="1-10-2013年-—-LMCTFY">1.10 2013年 — LMCTFY</h2><ul><li>Lmctfy代表的是“Let Me Contain That For You(帮你实现容器化)”。它其实属于谷歌容器技术堆栈的开源版本，负责提供Linux应用程序容器。谷歌公司在该项目的起步阶段宣称其能够提供值得信赖的性能表现、高资源利用率、共享资源机制、充裕的发展空间以及趋近于零的额外资源消耗。</li><li>2013年10月lmctfy的首个版本正式推出，谷歌公司在2015年决定将lmctfy的核心概念与抽象机制转化为libcontainer。在失去了主干之后，如今lmctfy已经失去一切积极的发展势头。</li></ul><p>Libcontainer项目最初由Docker公司建立，如今已经被归入开放容器基金会的管辖范畴。</p><h2 id="1-11-2013年-Docker">1.11 2013年-Docker</h2><ul><li>在2013年Docker刚发布的时候，它是一款基于LXC的开源容器管理引擎。</li><li>把LXC复杂的容器创建与使用方式简化为Docker自己的一套命令体系。</li><li>随着Docker的不断发展，它开始有了更为远大的目标，那就是反向定义容器的实现标准，将底层实现都抽象化到Libcontainer的接口。这就意味着，底层容器的实现方式变成了一种可变的方案，无论是使用namespace、cgroups技术抑或是使用systemd等其他方案，只要实现了Libcontainer定义的一组接口，Docker都可以运行。这也为Docker实现全面的跨平台带来了可能。</li></ul><h1>二、NameSpace</h1><h2 id="2-1-NameSpace介绍">2.1 NameSpace介绍</h2><ul><li><p>很多编程语言都包含了命名空间的概念，我们可以认为命名空间是一种封装，封装本身实际上实现了代码的隔离</p></li><li><p>在操作系统中命名空间命名空间提供的是系统资源的隔离，其中系统资源包括了：进程、网络、文件系统…</p></li><li><p>实际上linux系统实现命名空间主要目的之一就是为了实现轻量级虚拟化服务，也就是我们说的容器，在同一个命名空间下的进程可以感知彼此的变化，而对其他命名空间的进程一无所知，这样就可以让容器中的进程产生一个错觉，仿佛它自己置身于一个独立的系统环境当中，以此达到独立和隔离的目的。</p></li></ul><h2 id="2-2-Linux系统中NameSpace分类">2.2 Linux系统中NameSpace分类</h2><table><thead><tr><th style="text-align:center">命名空间</th><th style="text-align:center">描述</th><th style="text-align:center">作用</th><th style="text-align:center">备注</th></tr></thead><tbody><tr><td style="text-align:center">进程命名空间</td><td style="text-align:center">隔离进程ID</td><td style="text-align:center">Linux通过命名空间管理进程号，同一个进程，在不同的命名空间进程号不同</td><td style="text-align:center">进程命名空间是一个父子结构，子空间对于父空间可见</td></tr><tr><td style="text-align:center">网络命名空间</td><td style="text-align:center">隔离网络设备、协议栈、端口等</td><td style="text-align:center">通过网络命名空间，实现网络隔离</td><td style="text-align:center">docker采用虚拟网络设备，将不同命名空间的网络设备连接到一起</td></tr><tr><td style="text-align:center">IPC命名空间</td><td style="text-align:center">隔离进程间通信</td><td style="text-align:center">进程间交互方法</td><td style="text-align:center">PID命名空间和IPC命名空间可以组合起来用，同一个IPC名字空间内的进程可以彼此看见，允许进行交互，不同空间进程无法交互</td></tr><tr><td style="text-align:center">挂载命名空间</td><td style="text-align:center">隔离挂载点</td><td style="text-align:center">隔离文件目录</td><td style="text-align:center">进程运行时可以将挂载点与系统分离，使用这个功能时，我们可以达到 chroot 的功能，而在安全性方面比 chroot 更高</td></tr><tr><td style="text-align:center">UTS命名空间</td><td style="text-align:center">隔离Hostname和NIS域名</td><td style="text-align:center">让容器拥有独立的主机名和域名，从而让容器看起来像个独立的主机</td><td style="text-align:center">目的是独立出主机名和网络信息服务（NIS）</td></tr><tr><td style="text-align:center">用户命名空间</td><td style="text-align:center">隔离用户和group ID</td><td style="text-align:center">每个容器内上的用户跟宿主主机上不在一个命名空间</td><td style="text-align:center">同进程 ID 一样，用户 ID 和组 ID 在命名空间内外是不一样的，并且在不同命名空间内可以存在相同的 ID</td></tr></tbody></table><h2 id="2-3-NameSpace应用案例">2.3 NameSpace应用案例</h2><blockquote><p>以net namespace为例</p></blockquote><ul><li>在 Linux 中，网络命名空间可以被认为是隔离的拥有单独网络栈（网卡、路由转发表、iptables）的环境。网络命名空间经常用来隔离网络设备和服务，只有拥有同样网络命名空间的设备，才能看到彼此。</li><li>从逻辑上说，网络命名空间是网络栈的副本，拥有自己的网络设备、路由选择表、邻接表、Netfilter表、网络套接字、网络procfs条目、网络sysfs条目和其他网络资源。</li><li>从系统的角度来看，当通过clone()系统调用创建新进程时，传递标志CLONE_NEWNET将在新进程中创建一个全新的网络命名空间。</li><li>从用户的角度来看，我们只需使用工具ip（package is iproute2）来创建一个新的持久网络命名空间。</li></ul><p><a href="%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E6%89%80%E6%B6%89%E5%8F%8ALinux%E5%86%85%E6%A0%B8%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF.assets/image-20220111132707215.png" title="image-20220111132707215" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E6%89%80%E6%B6%89%E5%8F%8ALinux%E5%86%85%E6%A0%B8%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF//image-20220111132707215.png" alt="image-20220111132707215"></a></p><h3 id="2-3-1-创建net命名空间">2.3.1 创建net命名空间</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">创建名称为msb的网络命名空间</span><br><span class="line"><span class="comment"># ip netns add msb</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">查看已创建的网络命名空间</span><br><span class="line"><span class="comment"># ip netns ls</span></span><br><span class="line">msb</span><br></pre></td></tr></table></figure><h3 id="2-3-2-删除net命名空间">2.3.2 删除net命名空间</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">删除已创建的网络命名空间</span><br><span class="line"><span class="comment"># ip netns delete msb</span></span><br></pre></td></tr></table></figure><h3 id="2-3-3-在net命名空间中执行命令">2.3.3 在net命名空间中执行命令</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在网络命名空间中执行bash命令，如果想退出，需要使用<span class="keyword">exit</span></span><br><span class="line"><span class="comment"># ip netns exec msb bash</span></span><br></pre></td></tr></table></figure><h3 id="2-3-4-在net命令空间中执行查看网络连接-网卡-命令">2.3.4 在net命令空间中执行查看网络连接(网卡)命令</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在网络命名空间中查看网络命名空间中的网卡信息</span><br><span class="line"><span class="comment"># ip link</span></span><br><span class="line"><span class="number">1</span>: lo: &lt;LOOPBACK&gt; mtu <span class="number">65536</span> qdisc noop state DOWN mode DEFAULT <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/loopback <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> brd <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在Linux主机系统中查看</span><br><span class="line"><span class="comment"># ip netns exec msb ip link list</span></span><br><span class="line"><span class="number">1</span>: lo: &lt;LOOPBACK&gt; mtu <span class="number">65536</span> qdisc noop state DOWN mode DEFAULT <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/loopback <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> brd <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br></pre></td></tr></table></figure><h3 id="2-3-5-退出当前的net命名空间">2.3.5 退出当前的net命名空间</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">退出已进入的网络命名空间</span><br><span class="line"><span class="comment"># exit</span></span><br><span class="line"><span class="keyword">exit</span></span><br></pre></td></tr></table></figure><h3 id="2-3-6-在net命名空间中执行多条命令">2.3.6 在net命名空间中执行多条命令</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在网络命名空间中查看路由表</span><br><span class="line"><span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">在网络命名空间中查看防火墙规则</span><br><span class="line"><span class="comment"># iptables -t nat -nL</span></span><br><span class="line">Chain PREROUTING (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain POSTROUTING (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination</span><br></pre></td></tr></table></figure><h3 id="2-3-7-创建虚拟网卡">2.3.7 创建虚拟网卡</h3><blockquote><p>同时创建一对虚拟网卡</p></blockquote><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">创建虚拟网卡对</span><br><span class="line"><span class="comment"># ip link add veth0 type veth peer name veth1</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在物理机上查看</span><br><span class="line"><span class="comment"># ip a s</span></span><br><span class="line">......</span><br><span class="line"><span class="number">10</span>: veth1@veth0: &lt;BROADCAST,MULTICAST,M<span class="literal">-DOWN</span>&gt; mtu <span class="number">1500</span> qdisc noop state DOWN <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/ether de:<span class="number">44</span>:f8:b7:<span class="number">12</span>:<span class="number">65</span> brd ff:ff:ff:ff:ff:ff</span><br><span class="line"><span class="number">11</span>: veth0@veth1: &lt;BROADCAST,MULTICAST,M<span class="literal">-DOWN</span>&gt; mtu <span class="number">1500</span> qdisc noop state DOWN <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/ether <span class="number">46</span>:<span class="number">5</span>e:<span class="number">89</span>:<span class="number">8</span>c:cb:b3 brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure><h3 id="2-3-8-迁移虚拟网卡到命名空间中">2.3.8 迁移虚拟网卡到命名空间中</h3><blockquote><p>这两个网卡还都属于“default”或“global”命名空间，和物理网卡一样。把其中一个网卡转移到命名空间msb中。</p></blockquote><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">把创建的veth1网卡添加到msb网络命名空间中</span><br><span class="line"><span class="comment"># ip link set veth1 netns msb</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">在Linux系统命令行查看网络命名空间中的网络</span><br><span class="line"><span class="comment"># ip netns exec msb ip link</span></span><br><span class="line"><span class="number">1</span>: lo: &lt;LOOPBACK&gt; mtu <span class="number">65536</span> qdisc noop state DOWN mode DEFAULT <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/loopback <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> brd <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="number">10</span>: veth1@if11: &lt;BROADCAST,MULTICAST&gt; mtu <span class="number">1500</span> qdisc noop state DOWN mode DEFAULT <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/ether de:<span class="number">44</span>:f8:b7:<span class="number">12</span>:<span class="number">65</span> brd ff:ff:ff:ff:ff:ff link<span class="literal">-netnsid</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="2-3-9-命名空间中迁出虚拟网卡">2.3.9 命名空间中迁出虚拟网卡</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在Linux系统命令行把虚拟网卡veth1从网络命名空间删除</span><br><span class="line"><span class="comment"># ip netns exec msb ip link delete veth1</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在Linux系统命令行查看结果</span><br><span class="line"><span class="comment"># ip netns exec msb ip link</span></span><br><span class="line"><span class="number">1</span>: lo: &lt;LOOPBACK&gt; mtu <span class="number">65536</span> qdisc noop state DOWN mode DEFAULT <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/loopback <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> brd <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br></pre></td></tr></table></figure><h3 id="2-3-10-配置虚拟网卡IP地址">2.3.10 配置虚拟网卡IP地址</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">再次创建虚拟网卡，添加到msb网络命名空间，并设置IP地址</span><br><span class="line"><span class="comment"># ip link add veth0 type veth peer name veth1</span></span><br><span class="line"><span class="comment"># ip link set veth1 netns msb</span></span><br><span class="line"><span class="comment"># ip netns exec msb ip addr add 192.168.50.2/24 dev veth1</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在Linux系统命令行查看网络状态</span><br><span class="line"><span class="comment"># ip netns exec msb ip addr</span></span><br><span class="line"><span class="number">1</span>: lo: &lt;LOOPBACK&gt; mtu <span class="number">65536</span> qdisc noop state DOWN <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/loopback <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> brd <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="number">12</span>: veth1@if13: &lt;BROADCAST,MULTICAST&gt; mtu <span class="number">1500</span> qdisc noop state DOWN <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/ether fe:<span class="number">20</span>:<span class="built_in">ac</span>:a8:<span class="number">13</span>:<span class="number">4</span>c brd ff:ff:ff:ff:ff:ff link<span class="literal">-netnsid</span> <span class="number">0</span></span><br><span class="line">    inet <span class="number">192.168</span>.<span class="number">50.2</span>/<span class="number">24</span> scope global veth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">启动虚拟网卡,veth1与lo全部要启动</span><br><span class="line"><span class="comment"># ip netns exec msb ip link set veth1 up</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ip netns exec msb ip link set lo up</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">为物理机veth0添加IP地址</span><br><span class="line"></span><br><span class="line"><span class="comment"># ip a s</span></span><br><span class="line">......</span><br><span class="line"><span class="number">15</span>: veth0@if14: &lt;BROADCAST,MULTICAST&gt; mtu <span class="number">1500</span> qdisc noop state DOWN <span class="built_in">group</span> defau</span><br><span class="line">lt qlen <span class="number">1000</span></span><br><span class="line">    link/ether <span class="number">2</span>e:b4:<span class="number">40</span>:c8:<span class="number">73</span>:dc brd ff:ff:ff:ff:ff:ff link<span class="literal">-netnsid</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ip addr add 192.168.50.3/24 dev veth0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ip a s veth0</span></span><br><span class="line"><span class="number">15</span>: veth0@if14: &lt;BROADCAST,MULTICAST&gt; mtu <span class="number">1500</span> qdisc noop state DOWN <span class="built_in">group</span> default qlen <span class="number">1000</span></span><br><span class="line">    link/ether <span class="number">2</span>e:b4:<span class="number">40</span>:c8:<span class="number">73</span>:dc brd ff:ff:ff:ff:ff:ff link<span class="literal">-netnsid</span> <span class="number">0</span></span><br><span class="line">    inet <span class="number">192.168</span>.<span class="number">50.3</span>/<span class="number">24</span> scope global veth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ip link set veth0 up</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">在宿主机上ping msb中的veth1</span><br><span class="line"><span class="comment"># ping 192.168.50.2</span></span><br><span class="line">PING <span class="number">192.168</span>.<span class="number">50.2</span> (<span class="number">192.168</span>.<span class="number">50.2</span>) <span class="number">56</span>(<span class="number">84</span>) bytes of <span class="keyword">data</span>.</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">192.168</span>.<span class="number">50.2</span>: icmp_seq=<span class="number">1</span> ttl=<span class="number">64</span> time=<span class="number">0.102</span> ms</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">192.168</span>.<span class="number">50.2</span>: icmp_seq=<span class="number">2</span> ttl=<span class="number">64</span> time=<span class="number">0.068</span> ms</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">192.168</span>.<span class="number">50.2</span>: icmp_seq=<span class="number">3</span> ttl=<span class="number">64</span> time=<span class="number">0.068</span> ms</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">在msb中的veth1 ping 宿主机上veth0</span><br><span class="line"><span class="comment"># ip netns exec msb ping 192.168.50.3</span></span><br><span class="line">PING <span class="number">192.168</span>.<span class="number">50.3</span> (<span class="number">192.168</span>.<span class="number">50.3</span>) <span class="number">56</span>(<span class="number">84</span>) bytes of <span class="keyword">data</span>.</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">192.168</span>.<span class="number">50.3</span>: icmp_seq=<span class="number">1</span> ttl=<span class="number">64</span> time=<span class="number">0.053</span> ms</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">192.168</span>.<span class="number">50.3</span>: icmp_seq=<span class="number">2</span> ttl=<span class="number">64</span> time=<span class="number">0.031</span> ms</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">192.168</span>.<span class="number">50.3</span>: icmp_seq=<span class="number">3</span> ttl=<span class="number">64</span> time=<span class="number">0.029</span> ms</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果需要访问本机的其它网段，可手动添加如下默认路由条目。</span><br><span class="line"><span class="comment"># ip netns exec msb ip route add default via 192.168.50.3</span></span><br></pre></td></tr></table></figure><blockquote><p>关于如何ping通外网主机，可设置路由转发完成。</p></blockquote><h1>三、CGroups</h1><h2 id="3-1-CGroups介绍">3.1 CGroups介绍</h2><ul><li><p>Control groups(cgroups) 控制组</p></li><li><p>linux内核提供的可以限制、记录、隔离进程组所使用的物理资源的机制。为容器而生，没有cgroups就没有今天的容器技术。</p></li></ul><p><a href="%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E6%89%80%E6%B6%89%E5%8F%8ALinux%E5%86%85%E6%A0%B8%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF.assets/image-20220112182824405.png" title="image-20220112182824405" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E8%BF%90%E7%BB%B4/%E5%AE%B9%E5%99%A8/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E6%89%80%E6%B6%89%E5%8F%8ALinux%E5%86%85%E6%A0%B8%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF//image-20220112182824405.png" alt="image-20220112182824405"></a></p><h2 id="3-2-CGroups功能">3.2 CGroups功能</h2><ul><li>资源限制（Resource Limitation）：cgroups 可以对进程组使用的资源总额进行限制。如设定应用运行时使用内存的上限，一旦超过这个配额就发出 OOM（Out of Memory）。</li><li>优先级分配（Prioritization）：通过分配的 CPU 时间片数量及硬盘 IO 带宽大小，实际上就相当于控制了进程运行的优先级。</li><li>资源统计（Accounting）： cgroups 可以统计系统的资源使用量，如 CPU 使用时长、内存用量等等，这个功能非常适用于计费。</li><li>进程控制（Control）：cgroups 可以对进程组执行挂起、恢复等操作。</li></ul><h2 id="3-3-CGroups应用案例">3.3 CGroups应用案例</h2><h3 id="3-3-1-安装及开启服务">3.3.1 安装及开启服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# yum -y install libcgroup</span><br><span class="line">[root@localhost ~]# systemctl start cgconfig.service     </span><br><span class="line">[root@localhost ~]# systemctl enable cgconfig.service</span><br></pre></td></tr></table></figure><h3 id="3-3-2-限制进程使用CPU">3.3.2 限制进程使用CPU</h3><h4 id="3-3-2-1-查看cpu-shares">3.3.2.1 查看cpu shares</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">查看资源限制子系统</span><br><span class="line">[<span class="type">root</span>@<span class="type">localhost</span> ~]<span class="comment"># lssubsys</span></span><br><span class="line">cpuset</span><br><span class="line">cpu,cpuacct</span><br><span class="line">memory</span><br><span class="line">devices</span><br><span class="line">freezer</span><br><span class="line">net_cls,net_prio</span><br><span class="line">blkio</span><br><span class="line">perf_event</span><br><span class="line">hugetlb</span><br><span class="line">pids</span><br><span class="line"></span><br><span class="line">查看子系统配置文件所在位置</span><br><span class="line">[<span class="type">root</span>@<span class="type">localhost</span> ~]<span class="comment"># ls /sys/fs/cgroup/</span></span><br><span class="line">blkio  cpuacct      cpuset   freezer  memory   net_cls,net_prio  perf_event  systemd</span><br><span class="line">cpu    cpu,cpuacct  devices  hugetlb  net_cls  net_prio          pids</span><br><span class="line">[<span class="type">root</span>@<span class="type">localhost</span> ~]<span class="comment"># ls /sys/fs/cgroup/cpu</span></span><br><span class="line">cgroup.clone_children  cpuacct.stat          cpu.cfs_quota_us   cpu.stat</span><br><span class="line">cgroup.event_control   cpuacct.usage         cpu.rt_period_us   notify_on_release</span><br><span class="line">cgroup.procs           cpuacct.usage_percpu  cpu.rt_runtime_us  release_agent</span><br><span class="line">cgroup.sane_behavior   cpu.cfs_period_us     cpu.shares         tasks</span><br><span class="line"></span><br><span class="line">查看CPU时间分片，用于保证分组所得到的CPU分片总量。</span><br><span class="line">[<span class="type">root</span>@<span class="type">localhost</span> ~]<span class="comment"># cat /sys/fs/cgroup/cpu/cpu.shares</span></span><br><span class="line"><span class="number">1024</span></span><br></pre></td></tr></table></figure><h4 id="3-3-2-2-使用CPU子系统创建2个group分组">3.3.2.2 使用CPU子系统创建2个group分组</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim /etc/cgconfig.conf</span><br><span class="line">group lesscpu &#123;</span><br><span class="line">    cpu&#123;</span><br><span class="line">        cpu.shares=200;</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br><span class="line">group morecpu &#123;</span><br><span class="line">    cpu&#123;</span><br><span class="line">        cpu.shares=800;</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# systemctl restart cgconfig</span><br></pre></td></tr></table></figure><p>准备一个脚本</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">a=<span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> true</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"></span><br><span class="line">        a=<span class="variable">$</span>[<span class="variable">$a</span>+<span class="number">1</span>]</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>将将要运行的应用程序分配到指定分组(<strong>请使用单CPU机器,三个终端验证</strong>)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">终端1# cgexec -g cpu:lesscpu sh /tmp/1.sh</span><br><span class="line"></span><br><span class="line">终端2# cgexec -g cpu:morecpu sh /tmp/1.sh</span><br><span class="line"></span><br><span class="line">终端3# top</span><br></pre></td></tr></table></figure><p><strong>PS: 如果主机有多CPU，为了验证效果，可以进行如下操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">lscpu</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">echo</span> 0 &gt; /sys/devices/system/cpu/cpu0/online</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">echo</span> 1 &gt; /sys/devices/system/cpu/cpu1/online</span></span><br></pre></td></tr></table></figure></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;容器技术所涉及Linux内核关键技术&lt;/h1&gt;
&lt;h1&gt;一、容器技术前世今生&lt;/h1&gt;
&lt;h2 id=&quot;1-1-1979年-—-chroot&quot;&gt;1.1 1979年 — chroot&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;容</summary>
      
    
    
    
    <category term="容器" scheme="https://0914ds.github.io/categories/%E5%AE%B9%E5%99%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>MYSQL performance schema详解</title>
    <link href="https://0914ds.github.io/2023/06/04/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MYSQL%20performance%20schema%E8%AF%A6%E8%A7%A3/"/>
    <id>https://0914ds.github.io/2023/06/04/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MYSQL%20performance%20schema%E8%AF%A6%E8%A7%A3/</id>
    <published>2023-06-04T05:13:16.000Z</published>
    <updated>2023-06-22T07:12:12.061Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>MYSQL performance schema详解</h1><h3 id="0、performance-schema的介绍">0、performance_schema的介绍</h3><p>​        <strong>MySQL的performance schema 用于监控MySQL server在一个较低级别的运行过程中的资源消耗、资源等待等情况</strong>。</p><p>​        特点如下：</p><p>​        1、提供了一种在数据库运行时实时检查server的内部执行情况的方法。performance_schema 数据库中的表使用performance_schema存储引擎。该数据库主要关注数据库运行过程中的性能相关的数据，与information_schema不同，information_schema主要关注server运行过程中的元数据信息</p><p>​        2、performance_schema通过监视server的事件来实现监视server内部运行情况， “事件”就是server内部活动中所做的任何事情以及对应的时间消耗，利用这些信息来判断server中的相关资源消耗在了哪里？一般来说，事件可以是函数调用、操作系统的等待、SQL语句执行的阶段（如sql语句执行过程中的parsing 或 sorting阶段）或者整个SQL语句与SQL语句集合。事件的采集可以方便的提供server中的相关存储引擎对磁盘文件、表I/O、表锁等资源的同步调用信息。<br>​        3、performance_schema中的事件与写入二进制日志中的事件（描述数据修改的events）、事件计划调度程序（这是一种存储程序）的事件不同。performance_schema中的事件记录的是server执行某些活动对某些资源的消耗、耗时、这些活动执行的次数等情况。<br>​        4、performance_schema中的事件只记录在本地server的performance_schema中，其下的这些表中数据发生变化时不会被写入binlog中，也不会通过复制机制被复制到其他server中。<br>​        5、 当前活跃事件、历史事件和事件摘要相关的表中记录的信息。能提供某个事件的执行次数、使用时长。进而可用于分析某个特定线程、特定对象（如mutex或file）相关联的活动。<br>​        6、PERFORMANCE_SCHEMA存储引擎使用server源代码中的“检测点”来实现事件数据的收集。对于performance_schema实现机制本身的代码没有相关的单独线程来检测，这与其他功能（如复制或事件计划程序）不同<br>​        7、收集的事件数据存储在performance_schema数据库的表中。这些表可以使用SELECT语句查询，也可以使用SQL语句更新performance_schema数据库中的表记录（如动态修改performance_schema的setup_*开头的几个配置表，但要注意：配置表的更改会立即生效，这会影响数据收集）<br>​        8、performance_schema的表中的数据不会持久化存储在磁盘中，而是保存在内存中，一旦服务器重启，这些数据会丢失（包括配置表在内的整个performance_schema下的所有数据）<br>​        9、MySQL支持的所有平台中事件监控功能都可用，但不同平台中用于统计事件时间开销的计时器类型可能会有所差异。</p><h3 id="1、performance-schema入门">1、performance schema入门</h3><p>​        在mysql的5.7版本中，性能模式是默认开启的，如果想要显式的关闭的话需要修改配置文件，不能直接进行修改，会报错Variable ‘performance_schema’ is a read only variable。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--查看performance_schema的属性</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> VARIABLES <span class="keyword">LIKE</span> <span class="string">&#x27;performance_schema&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name      <span class="operator">|</span> <span class="keyword">Value</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> performance_schema <span class="operator">|</span> <span class="keyword">ON</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+-------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br><span class="line"></span><br><span class="line"><span class="comment">--在配置文件中修改performance_schema的属性值，on表示开启，off表示关闭</span></span><br><span class="line">[mysqld]</span><br><span class="line">performance_schema<span class="operator">=</span><span class="keyword">ON</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--切换数据库</span></span><br><span class="line">use performance_schema;</span><br><span class="line"></span><br><span class="line"><span class="comment">--查看当前数据库下的所有表,会看到有很多表存储着相关的信息</span></span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"></span><br><span class="line"><span class="comment">--可以通过show create table tablename来查看创建表的时候的表结构</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> setup_consumers;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+---------------------------------</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">Table</span>           <span class="operator">|</span> <span class="keyword">Create</span> <span class="keyword">Table</span>                    </span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+---------------------------------</span></span><br><span class="line"><span class="operator">|</span> setup_consumers <span class="operator">|</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `setup_consumers` (</span><br><span class="line">  `NAME` <span class="type">varchar</span>(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,                      </span><br><span class="line">  `ENABLED` enum(<span class="string">&#x27;YES&#x27;</span>,<span class="string">&#x27;NO&#x27;</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>               </span><br><span class="line">) ENGINE<span class="operator">=</span>PERFORMANCE_SCHEMA <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8 <span class="operator">|</span>  </span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+---------------------------------</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)                             </span><br></pre></td></tr></table></figure><p>​        想要搞明白后续的内容，同学们需要理解两个基本概念：</p><p>​        instruments: 生产者，用于采集mysql中各种各样的操作产生的事件信息，对应配置表中的配置项我们可以称为监控采集配置项。</p><p>​        consumers:消费者，对应的消费者表用于存储来自instruments采集的数据，对应配置表中的配置项我们可以称为消费存储配置项。</p><h3 id="2、performance-schema表的分类">2、performance_schema表的分类</h3><p>​        performance_schema库下的表可以按照监视不同的纬度就行分组。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--语句事件记录表，这些表记录了语句事件信息，当前语句事件表events_statements_current、历史语句事件表events_statements_history和长语句历史事件表events_statements_history_long、以及聚合后的摘要表summary，其中，summary表还可以根据帐号(account)，主机(host)，程序(program)，线程(thread)，用户(user)和全局(global)再进行细分)</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">like</span> <span class="string">&#x27;%statement%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--等待事件记录表，与语句事件类型的相关记录表类似：</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">like</span> <span class="string">&#x27;%wait%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--阶段事件记录表，记录语句执行的阶段事件的表</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">like</span> <span class="string">&#x27;%stage%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--事务事件记录表，记录事务相关的事件的表</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">like</span> <span class="string">&#x27;%transaction%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--监控文件系统层调用的表</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">like</span> <span class="string">&#x27;%file%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--监视内存使用的表</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">like</span> <span class="string">&#x27;%memory%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--动态对performance_schema进行配置的配置表</span></span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">like</span> <span class="string">&#x27;%setup%&#x27;</span>;</span><br></pre></td></tr></table></figure><h3 id="3、performance-schema的简单配置与使用">3、performance_schema的简单配置与使用</h3><p>​        数据库刚刚初始化并启动时，并非所有instruments(事件采集项，在采集项的配置表中每一项都有一个开关字段，或为YES，或为NO)和consumers(与采集项类似，也有一个对应的事件类型保存表配置项，为YES就表示对应的表保存性能数据，为NO就表示对应的表不保存性能数据)都启用了，所以默认不会收集所有的事件，可能你需要检测的事件并没有打开，需要进行设置，可以使用如下两个语句打开对应的instruments和consumers（行计数可能会因MySQL版本而异)。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--打开等待事件的采集器配置项开关，需要修改setup_instruments配置表中对应的采集器配置项</span></span><br><span class="line"><span class="keyword">UPDATE</span> setup_instruments <span class="keyword">SET</span> ENABLED <span class="operator">=</span> <span class="string">&#x27;YES&#x27;</span>, TIMED <span class="operator">=</span> <span class="string">&#x27;YES&#x27;</span><span class="keyword">where</span> name <span class="keyword">like</span> <span class="string">&#x27;wait%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--打开等待事件的保存表配置开关，修改setup_consumers配置表中对应的配置项</span></span><br><span class="line"><span class="keyword">UPDATE</span> setup_consumers <span class="keyword">SET</span> ENABLED <span class="operator">=</span> <span class="string">&#x27;YES&#x27;</span><span class="keyword">where</span> name <span class="keyword">like</span> <span class="string">&#x27;%wait%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--当配置完成之后可以查看当前server正在做什么，可以通过查询events_waits_current表来得知，该表中每个线程只包含一行数据，用于显示每个线程的最新监视事件</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> events_waits_current\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1.</span> <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">            THREAD_ID: <span class="number">11</span></span><br><span class="line">             EVENT_ID: <span class="number">570</span></span><br><span class="line">         END_EVENT_ID: <span class="number">570</span></span><br><span class="line">           EVENT_NAME: wait<span class="operator">/</span>synch<span class="operator">/</span>mutex<span class="operator">/</span>innodb<span class="operator">/</span>buf_dblwr_mutex</span><br><span class="line">               SOURCE: </span><br><span class="line">          TIMER_START: <span class="number">4508505105239280</span></span><br><span class="line">            TIMER_END: <span class="number">4508505105270160</span></span><br><span class="line">           TIMER_WAIT: <span class="number">30880</span></span><br><span class="line">                SPINS: <span class="keyword">NULL</span></span><br><span class="line">        OBJECT_SCHEMA: <span class="keyword">NULL</span></span><br><span class="line">          OBJECT_NAME: <span class="keyword">NULL</span></span><br><span class="line">           INDEX_NAME: <span class="keyword">NULL</span></span><br><span class="line">          OBJECT_TYPE: <span class="keyword">NULL</span></span><br><span class="line">OBJECT_INSTANCE_BEGIN: <span class="number">67918392</span></span><br><span class="line">     NESTING_EVENT_ID: <span class="keyword">NULL</span></span><br><span class="line">   NESTING_EVENT_TYPE: <span class="keyword">NULL</span></span><br><span class="line">            OPERATION: lock</span><br><span class="line">      NUMBER_OF_BYTES: <span class="keyword">NULL</span></span><br><span class="line">                FLAGS: <span class="keyword">NULL</span></span><br><span class="line"><span class="comment">/*该信息表示线程id为11的线程正在等待buf_dblwr_mutex锁，等待事件为30880</span></span><br><span class="line"><span class="comment">属性说明：</span></span><br><span class="line"><span class="comment">    id:事件来自哪个线程，事件编号是多少</span></span><br><span class="line"><span class="comment">    event_name:表示检测到的具体的内容</span></span><br><span class="line"><span class="comment">    source:表示这个检测代码在哪个源文件中以及行号</span></span><br><span class="line"><span class="comment">    timer_start:表示该事件的开始时间</span></span><br><span class="line"><span class="comment">    timer_end:表示该事件的结束时间</span></span><br><span class="line"><span class="comment">    timer_wait:表示该事件总的花费时间</span></span><br><span class="line"><span class="comment">注意：_current表中每个线程只保留一条记录，一旦线程完成工作，该表中不会再记录该线程的事件信息</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">_history表中记录每个线程应该执行完成的事件信息，但每个线程的事件信息只会记录10条，再多就会被覆盖，*_history_long表中记录所有线程的事件信息，但总记录数量是10000，超过就会被覆盖掉</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">select</span> thread_id,event_id,event_name,timer_wait <span class="keyword">from</span> events_waits_history <span class="keyword">order</span> <span class="keyword">by</span> thread_id limit <span class="number">21</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">summary表提供所有事件的汇总信息，该组中的表以不同的方式汇总事件数据（如：按用户，按主机，按线程等等）。例如：要查看哪些instruments占用最多的时间，可以通过对events_waits_summary_global_by_event_name表的COUNT_STAR或SUM_TIMER_WAIT列进行查询（这两列是对事件的记录数执行COUNT（*）、事件记录的TIMER_WAIT列执行SUM（TIMER_WAIT）统计而来）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">SELECT</span> EVENT_NAME,COUNT_STAR <span class="keyword">FROM</span> events_waits_summary_global_by_event_name  <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT_STAR <span class="keyword">DESC</span> LIMIT <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">instance表记录了哪些类型的对象会被检测。这些对象在被server使用时，在该表中将会产生一条事件记录，例如，file_instances表列出了文件I/O操作及其关联文件名</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> file_instances limit <span class="number">20</span>; </span><br></pre></td></tr></table></figure><h3 id="4、常用配置项的参数说明">4、常用配置项的参数说明</h3><p>1、启动选项</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">performance_schema_consumer_events_statements_current<span class="operator">=</span><span class="literal">TRUE</span></span><br><span class="line">是否在mysql server启动时就开启events_statements_current表的记录功能(该表记录当前的语句事件信息)，启动之后也可以在setup_consumers表中使用<span class="keyword">UPDATE</span>语句进行动态更新setup_consumers配置表中的events_statements_current配置项，默认值为<span class="literal">TRUE</span></span><br><span class="line"></span><br><span class="line">performance_schema_consumer_events_statements_history<span class="operator">=</span><span class="literal">TRUE</span></span><br><span class="line">与performance_schema_consumer_events_statements_current选项类似，但该选项是用于配置是否记录语句事件短历史信息，默认为<span class="literal">TRUE</span></span><br><span class="line"></span><br><span class="line">performance_schema_consumer_events_stages_history_long<span class="operator">=</span><span class="literal">FALSE</span></span><br><span class="line">与performance_schema_consumer_events_statements_current选项类似，但该选项是用于配置是否记录语句事件长历史信息，默认为<span class="literal">FALSE</span></span><br><span class="line"></span><br><span class="line">除了statement(语句)事件之外，还支持：wait(等待)事件、state(阶段)事件、transaction(事务)事件，他们与statement事件一样都有三个启动项分别进行配置，但这些等待事件默认未启用，如果需要在MySQL Server启动时一同启动，则通常需要写进my.cnf配置文件中</span><br><span class="line">performance_schema_consumer_global_instrumentation<span class="operator">=</span><span class="literal">TRUE</span></span><br><span class="line">是否在MySQL Server启动时就开启全局表（如：mutex_instances、rwlock_instances、cond_instances、file_instances、users、hostsaccounts、socket_summary_by_event_name、file_summary_by_instance等大部分的全局对象计数统计和事件汇总统计信息表 ）的记录功能，启动之后也可以在setup_consumers表中使用<span class="keyword">UPDATE</span>语句进行动态更新全局配置项</span><br><span class="line">默认值为<span class="literal">TRUE</span></span><br><span class="line"></span><br><span class="line">performance_schema_consumer_statements_digest<span class="operator">=</span><span class="literal">TRUE</span></span><br><span class="line">是否在MySQL Server启动时就开启events_statements_summary_by_digest 表的记录功能，启动之后也可以在setup_consumers表中使用<span class="keyword">UPDATE</span>语句进行动态更新digest配置项</span><br><span class="line">默认值为<span class="literal">TRUE</span></span><br><span class="line"></span><br><span class="line">performance_schema_consumer_thread_instrumentation<span class="operator">=</span><span class="literal">TRUE</span></span><br><span class="line">是否在MySQL Server启动时就开启</span><br><span class="line"></span><br><span class="line">events_xxx_summary_by_yyy_by_event_name表的记录功能，启动之后也可以在setup_consumers表中使用<span class="keyword">UPDATE</span>语句进行动态更新线程配置项</span><br><span class="line">默认值为<span class="literal">TRUE</span></span><br><span class="line"></span><br><span class="line">performance_schema_instrument[<span class="operator">=</span>name]</span><br><span class="line">是否在MySQL Server启动时就启用某些采集器，由于instruments配置项多达数千个，所以该配置项支持key<span class="operator">-</span><span class="keyword">value</span>模式，还支持<span class="operator">%</span>号进行通配等，如下:</span><br><span class="line"></span><br><span class="line"># [<span class="operator">=</span>name]可以指定为具体的Instruments名称（但是这样如果有多个需要指定的时候，就需要使用该选项多次），也可以使用通配符，可以指定instruments相同的前缀<span class="operator">+</span>通配符，也可以使用<span class="operator">%</span>代表所有的instruments</span><br><span class="line"></span><br><span class="line">## 指定开启单个instruments</span><br><span class="line"></span><br><span class="line"><span class="comment">--performance-schema-instrument= &#x27;instrument_name=value&#x27;</span></span><br><span class="line"></span><br><span class="line">## 使用通配符指定开启多个instruments</span><br><span class="line"></span><br><span class="line"><span class="comment">--performance-schema-instrument= &#x27;wait/synch/cond/%=COUNTED&#x27;</span></span><br><span class="line"></span><br><span class="line">## 开关所有的instruments</span><br><span class="line"></span><br><span class="line"><span class="comment">--performance-schema-instrument= &#x27;%=ON&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--performance-schema-instrument= &#x27;%=OFF&#x27;</span></span><br><span class="line"></span><br><span class="line">注意，这些启动选项要生效的前提是，需要设置performance_schema<span class="operator">=</span><span class="keyword">ON</span>。另外，这些启动选项虽然无法使用<span class="keyword">show</span> variables语句查看，但我们可以通过setup_instruments和setup_consumers表查询这些选项指定的值。</span><br></pre></td></tr></table></figure><p>2、系统变量</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;%performance_schema%&#x27;</span>;</span><br><span class="line"><span class="comment">--重要的属性解释</span></span><br><span class="line">performance_schema<span class="operator">=</span><span class="keyword">ON</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">控制performance_schema功能的开关，要使用MySQL的performance_schema，需要在mysqld启动时启用，以启用事件收集功能</span></span><br><span class="line"><span class="comment">该参数在5.7.x之前支持performance_schema的版本中默认关闭，5.7.x版本开始默认开启</span></span><br><span class="line"><span class="comment">注意：如果mysqld在初始化performance_schema时发现无法分配任何相关的内部缓冲区，则performance_schema将自动禁用，并将performance_schema设置为OFF</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line">performance_schema_digests_size<span class="operator">=</span><span class="number">10000</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">控制events_statements_summary_by_digest表中的最大行数。如果产生的语句摘要信息超过此最大值，便无法继续存入该表，此时performance_schema会增加状态变量</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">performance_schema_events_statements_history_long_size<span class="operator">=</span><span class="number">10000</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">控制events_statements_history_long表中的最大行数，该参数控制所有会话在events_statements_history_long表中能够存放的总事件记录数，超过这个限制之后，最早的记录将被覆盖</span></span><br><span class="line"><span class="comment">全局变量，只读变量，整型值，5.6.3版本引入 * 5.6.x版本中，5.6.5及其之前的版本默认为10000，5.6.6及其之后的版本默认值为-1，通常情况下，自动计算的值都是10000 * 5.7.x版本中，默认值为-1，通常情况下，自动计算的值都是10000</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">performance_schema_events_statements_history_size<span class="operator">=</span><span class="number">10</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">控制events_statements_history表中单个线程（会话）的最大行数，该参数控制单个会话在events_statements_history表中能够存放的事件记录数，超过这个限制之后，单个会话最早的记录将被覆盖</span></span><br><span class="line"><span class="comment">全局变量，只读变量，整型值，5.6.3版本引入 * 5.6.x版本中，5.6.5及其之前的版本默认为10，5.6.6及其之后的版本默认值为-1，通常情况下，自动计算的值都是10 * 5.7.x版本中，默认值为-1，通常情况下，自动计算的值都是10</span></span><br><span class="line"><span class="comment">除了statement(语句)事件之外，wait(等待)事件、state(阶段)事件、transaction(事务)事件，他们与statement事件一样都有三个参数分别进行存储限制配置，有兴趣的同学自行研究，这里不再赘述</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">performance_schema_max_digest_length<span class="operator">=</span><span class="number">1024</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">用于控制标准化形式的SQL语句文本在存入performance_schema时的限制长度，该变量与max_digest_length变量相关(max_digest_length变量含义请自行查阅相关资料)</span></span><br><span class="line"><span class="comment">全局变量，只读变量，默认值1024字节，整型值，取值范围0~1048576</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">performance_schema_max_sql_text_length<span class="operator">=</span><span class="number">1024</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">控制存入events_statements_current，events_statements_history和events_statements_history_long语句事件表中的SQL_TEXT列的最大SQL长度字节数。 超出系统变量performance_schema_max_sql_text_length的部分将被丢弃，不会记录，一般情况下不需要调整该参数，除非被截断的部分与其他SQL比起来有很大差异</span></span><br><span class="line"><span class="comment">全局变量，只读变量，整型值，默认值为1024字节，取值范围为0~1048576，5.7.6版本引入</span></span><br><span class="line"><span class="comment">降低系统变量performance_schema_max_sql_text_length值可以减少内存使用，但如果汇总的SQL中，被截断部分有较大差异，会导致没有办法再对这些有较大差异的SQL进行区分。 增加该系统变量值会增加内存使用，但对于汇总SQL来讲可以更精准地区分不同的部分。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h3 id="5、重要配置表的相关说明">5、重要配置表的相关说明</h3><p>​        配置表之间存在相互关联关系，按照配置影响的先后顺序，可添加为</p><p><a href="image-20191203125003597.png" title="image-20191203125003597" class="gallery-item" style="box-shadow: none;"> <img src="/2023/06/04/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MYSQL%20performance%20schema%E8%AF%A6%E8%A7%A3//image-20191203125003597.png" alt="image-20191203125003597"></a></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">performance_timers表中记录了server中有哪些可用的事件计时器</span></span><br><span class="line"><span class="comment">字段解释：</span></span><br><span class="line"><span class="comment">    timer_name:表示可用计时器名称，CYCLE是基于CPU周期计数器的定时器</span></span><br><span class="line"><span class="comment">    timer_frequency:表示每秒钟对应的计时器单位的数量,CYCLE计时器的换算值与CPU的频率相关、</span></span><br><span class="line"><span class="comment">    timer_resolution:计时器精度值，表示在每个计时器被调用时额外增加的值</span></span><br><span class="line"><span class="comment">    timer_overhead:表示在使用定时器获取事件时开销的最小周期值</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> performance_timers;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">setup_timers表中记录当前使用的事件计时器信息</span></span><br><span class="line"><span class="comment">字段解释：</span></span><br><span class="line"><span class="comment">    name:计时器类型，对应某个事件类别</span></span><br><span class="line"><span class="comment">    timer_name:计时器类型名称</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> setup_timers;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">setup_consumers表中列出了consumers可配置列表项</span></span><br><span class="line"><span class="comment">字段解释：</span></span><br><span class="line"><span class="comment">    NAME：consumers配置名称</span></span><br><span class="line"><span class="comment">    ENABLED：consumers是否启用，有效值为YES或NO，此列可以使用UPDATE语句修改。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> setup_consumers;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">setup_instruments 表列出了instruments 列表配置项，即代表了哪些事件支持被收集：</span></span><br><span class="line"><span class="comment">字段解释：</span></span><br><span class="line"><span class="comment">    NAME：instruments名称，instruments名称可能具有多个部分并形成层次结构</span></span><br><span class="line"><span class="comment">    ENABLED：instrumetns是否启用，有效值为YES或NO，此列可以使用UPDATE语句修改。如果设置为NO，则这个instruments不会被执行，不会产生任何的事件信息</span></span><br><span class="line"><span class="comment">    TIMED：instruments是否收集时间信息，有效值为YES或NO，此列可以使用UPDATE语句修改，如果设置为NO，则这个instruments不会收集时间信息</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> setup_instruments;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">setup_actors表的初始内容是匹配任何用户和主机，因此对于所有前台线程，默认情况下启用监视和历史事件收集功能</span></span><br><span class="line"><span class="comment">字段解释：</span></span><br><span class="line"><span class="comment">    HOST：与grant语句类似的主机名，一个具体的字符串名字，或使用“％”表示“任何主机”</span></span><br><span class="line"><span class="comment">    USER：一个具体的字符串名称，或使用“％”表示“任何用户”</span></span><br><span class="line"><span class="comment">    ROLE：当前未使用，MySQL 8.0中才启用角色功能</span></span><br><span class="line"><span class="comment">    ENABLED：是否启用与HOST，USER，ROLE匹配的前台线程的监控功能，有效值为：YES或NO</span></span><br><span class="line"><span class="comment">    HISTORY：是否启用与HOST， USER，ROLE匹配的前台线程的历史事件记录功能，有效值为：YES或NO</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> setup_actors;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">setup_objects表控制performance_schema是否监视特定对象。默认情况下，此表的最大行数为100行。</span></span><br><span class="line"><span class="comment">字段解释：</span></span><br><span class="line"><span class="comment">    OBJECT_TYPE：instruments类型，有效值为：“EVENT”（事件调度器事件）、“FUNCTION”（存储函数）、“PROCEDURE”（存储过程）、“TABLE”（基表）、“TRIGGER”（触发器），TABLE对象类型的配置会影响表I/O事件（wait/io/table/sql/handler instrument）和表锁事件（wait/lock/table/sql/handler instrument）的收集</span></span><br><span class="line"><span class="comment">    OBJECT_SCHEMA：某个监视类型对象涵盖的数据库名称，一个字符串名称，或“％”(表示“任何数据库”)</span></span><br><span class="line"><span class="comment">    OBJECT_NAME：某个监视类型对象涵盖的表名，一个字符串名称，或“％”(表示“任何数据库内的对象”)</span></span><br><span class="line"><span class="comment">    ENABLED：是否开启对某个类型对象的监视功能，有效值为：YES或NO。此列可以修改</span></span><br><span class="line"><span class="comment">    TIMED：是否开启对某个类型对象的时间收集功能，有效值为：YES或NO，此列可以修改</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> setup_objects;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">threads表对于每个server线程生成一行包含线程相关的信息，</span></span><br><span class="line"><span class="comment">字段解释：</span></span><br><span class="line"><span class="comment">    THREAD_ID：线程的唯一标识符（ID）</span></span><br><span class="line"><span class="comment">    NAME：与server中的线程检测代码相关联的名称(注意，这里不是instruments名称)</span></span><br><span class="line"><span class="comment">    TYPE：线程类型，有效值为：FOREGROUND、BACKGROUND。分别表示前台线程和后台线程</span></span><br><span class="line"><span class="comment">    PROCESSLIST_ID：对应INFORMATION_SCHEMA.PROCESSLIST表中的ID列。</span></span><br><span class="line"><span class="comment">    PROCESSLIST_USER：与前台线程相关联的用户名，对于后台线程为NULL。</span></span><br><span class="line"><span class="comment">    PROCESSLIST_HOST：与前台线程关联的客户端的主机名，对于后台线程为NULL。</span></span><br><span class="line"><span class="comment">    PROCESSLIST_DB：线程的默认数据库，如果没有，则为NULL。</span></span><br><span class="line"><span class="comment">    PROCESSLIST_COMMAND：对于前台线程，该值代表着当前客户端正在执行的command类型，如果是sleep则表示当前会话处于空闲状态</span></span><br><span class="line"><span class="comment">    PROCESSLIST_TIME：当前线程已处于当前线程状态的持续时间（秒）</span></span><br><span class="line"><span class="comment">    PROCESSLIST_STATE：表示线程正在做什么事情。</span></span><br><span class="line"><span class="comment">    PROCESSLIST_INFO：线程正在执行的语句，如果没有执行任何语句，则为NULL。</span></span><br><span class="line"><span class="comment">    PARENT_THREAD_ID：如果这个线程是一个子线程（由另一个线程生成），那么该字段显示其父线程ID</span></span><br><span class="line"><span class="comment">    ROLE：暂未使用</span></span><br><span class="line"><span class="comment">    INSTRUMENTED：线程执行的事件是否被检测。有效值：YES、NO </span></span><br><span class="line"><span class="comment">    HISTORY：是否记录线程的历史事件。有效值：YES、NO * </span></span><br><span class="line"><span class="comment">    THREAD_OS_ID：由操作系统层定义的线程或任务标识符（ID）：</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> threads</span><br></pre></td></tr></table></figure><p>注意：在performance_schema库中还包含了很多其他的库和表，能对数据库的性能做完整的监控，大家需要参考官网详细了解。</p><h3 id="6、performance-schema实践操作">6、performance_schema实践操作</h3><p>​        基本了解了表的相关信息之后，可以通过这些表进行实际的查询操作来进行实际的分析。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--1、哪类的SQL执行最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> DIGEST_TEXT,COUNT_STAR,FIRST_SEEN,LAST_SEEN <span class="keyword">FROM</span> events_statements_summary_by_digest <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT_STAR <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--2、哪类SQL的平均响应时间最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> DIGEST_TEXT,AVG_TIMER_WAIT <span class="keyword">FROM</span> events_statements_summary_by_digest <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT_STAR <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--3、哪类SQL排序记录数最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> DIGEST_TEXT,SUM_SORT_ROWS <span class="keyword">FROM</span> events_statements_summary_by_digest <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT_STAR <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--4、哪类SQL扫描记录数最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> DIGEST_TEXT,SUM_ROWS_EXAMINED <span class="keyword">FROM</span> events_statements_summary_by_digest <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT_STAR <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--5、哪类SQL使用临时表最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> DIGEST_TEXT,SUM_CREATED_TMP_TABLES,SUM_CREATED_TMP_DISK_TABLES <span class="keyword">FROM</span> events_statements_summary_by_digest <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT_STAR <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--6、哪类SQL返回结果集最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> DIGEST_TEXT,SUM_ROWS_SENT <span class="keyword">FROM</span> events_statements_summary_by_digest <span class="keyword">ORDER</span> <span class="keyword">BY</span> COUNT_STAR <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--7、哪个表物理IO最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> file_name,event_name,SUM_NUMBER_OF_BYTES_READ,SUM_NUMBER_OF_BYTES_WRITE <span class="keyword">FROM</span> file_summary_by_instance <span class="keyword">ORDER</span> <span class="keyword">BY</span> SUM_NUMBER_OF_BYTES_READ <span class="operator">+</span> SUM_NUMBER_OF_BYTES_WRITE <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--8、哪个表逻辑IO最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> object_name,COUNT_READ,COUNT_WRITE,COUNT_FETCH,SUM_TIMER_WAIT <span class="keyword">FROM</span> table_io_waits_summary_by_table <span class="keyword">ORDER</span> <span class="keyword">BY</span> sum_timer_wait <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--9、哪个索引访问最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> OBJECT_NAME,INDEX_NAME,COUNT_FETCH,COUNT_INSERT,COUNT_UPDATE,COUNT_DELETE <span class="keyword">FROM</span> table_io_waits_summary_by_index_usage <span class="keyword">ORDER</span> <span class="keyword">BY</span> SUM_TIMER_WAIT <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--10、哪个索引从来没有用过？</span></span><br><span class="line"><span class="keyword">SELECT</span> OBJECT_SCHEMA,OBJECT_NAME,INDEX_NAME <span class="keyword">FROM</span> table_io_waits_summary_by_index_usage <span class="keyword">WHERE</span> INDEX_NAME <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">AND</span> COUNT_STAR <span class="operator">=</span> <span class="number">0</span> <span class="keyword">AND</span> OBJECT_SCHEMA <span class="operator">&lt;&gt;</span> <span class="string">&#x27;mysql&#x27;</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> OBJECT_SCHEMA,OBJECT_NAME;</span><br><span class="line"><span class="comment">--11、哪个等待事件消耗时间最多？</span></span><br><span class="line"><span class="keyword">SELECT</span> EVENT_NAME,COUNT_STAR,SUM_TIMER_WAIT,AVG_TIMER_WAIT <span class="keyword">FROM</span> events_waits_summary_global_by_event_name <span class="keyword">WHERE</span> event_name <span class="operator">!=</span> <span class="string">&#x27;idle&#x27;</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> SUM_TIMER_WAIT <span class="keyword">DESC</span></span><br><span class="line"><span class="comment">--12-1、剖析某条SQL的执行情况，包括statement信息，stege信息，wait信息</span></span><br><span class="line"><span class="keyword">SELECT</span> EVENT_ID,sql_text <span class="keyword">FROM</span> events_statements_history <span class="keyword">WHERE</span> sql_text <span class="keyword">LIKE</span> <span class="string">&#x27;%count(*)%&#x27;</span>;</span><br><span class="line"><span class="comment">--12-2、查看每个阶段的时间消耗</span></span><br><span class="line"><span class="keyword">SELECT</span> event_id,EVENT_NAME,SOURCE,TIMER_END <span class="operator">-</span> TIMER_START <span class="keyword">FROM</span> events_stages_history_long <span class="keyword">WHERE</span> NESTING_EVENT_ID <span class="operator">=</span> <span class="number">1553</span>;</span><br><span class="line"><span class="comment">--12-3、查看每个阶段的锁等待情况</span></span><br><span class="line"><span class="keyword">SELECT</span> event_id,event_name,source,timer_wait,object_name,index_name,operation,nesting_event_id <span class="keyword">FROM</span> events_waits_history_longWHERE nesting_event_id <span class="operator">=</span> <span class="number">1553</span>;</span><br></pre></td></tr></table></figure></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;MYSQL performance schema详解&lt;/h1&gt;
&lt;h3 id=&quot;0、performance-schema的介绍&quot;&gt;0、performance_schema的介绍&lt;/h3&gt;
&lt;p&gt;​        </summary>
      
    
    
    
    <category term="数据库" scheme="https://0914ds.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>图数据库nebulaGraph选型</title>
    <link href="https://0914ds.github.io/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93nebulaGraph%E9%80%89%E5%9E%8B/"/>
    <id>https://0914ds.github.io/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93nebulaGraph%E9%80%89%E5%9E%8B/</id>
    <published>2023-05-09T18:45:12.000Z</published>
    <updated>2023-06-22T07:27:52.708Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>nebulaGraph 选型</h1><h2 id="一-why-nebulaGraph-？">一.why nebulaGraph ？</h2><p>在图数据库的选型上我们主要考虑了以下 5 点：(A) 项目开源，暂不考虑需付费的图数据库；(B) 分布式架构设计，具备良好的可扩展性；© 毫秒级的多跳查询延迟；(D) 支持千亿量级点边存储；(E) 具备批量从数仓导入数据的能力。</p><p>分析 DB-Engines[2] 上排名前 30 的图数据库，剔除不开源的项目，我们将剩余的图数据库分为三类：</p><ul><li><strong>第一类：Neo4j[3]、ArangoDB[4]、Virtuoso[5]、TigerGraph[6]、RedisGraph[7]。</strong> 此类图数据库只有单机版本开源可用，性能优秀，但不能应对分布式场景中数据的规模增长，即不满足选型要求（B）、（D）。</li><li><strong>第二类：JanusGraph[8]、HugeGraph[9]。</strong> 此类图数据库在现有存储系统之上新增了通用的图语义解释层，图语义层提供了图遍历的能力，但是受到存储层或者架构限制，不支持完整的计算下推，多跳遍历的性能较差，很难满足 OLTP 场景下对低延时的要求，即不满足选型要求（C）。</li><li><strong>第三类：DGraph[10]、NebulaGraph[11]。</strong> 此类图数据库根据图数据的特点对数据存储模型、点边分布、执行引擎进行了全新设计，对图的多跳遍历进行了深度优化，基本满足我们的选型要求。</li></ul><p>DGraph 是由前 Google 员工 Manish Rai Jain 离职创业后，在 2016 年推出的图数据库产品，底层数据模型是 RDF[12]，基于 Go 语言编写，存储引擎基于 BadgerDB[13] 改造，使用 RAFT 保证数据读写的强一致性。</p><p>NebulaGraph 是由前 Facebook 员工叶小萌离职创业后，在 2019年 推出的图数据库产品，底层数据模型是属性图，基于 C++ 语言编写，存储引擎基于 RocksDB[14] 改造，使用 RAFT 保证数据读写的强一致性。</p><p>这两个项目的创始人都在互联网公司图数据库领域深耕多年，对图数据库的落地痛点有深刻认识，整体的架构设计也有较多相似之处。在图数据库最终的选型上，我们基于 LDBC-SNB 数据集[15]对 NebulaGraph、DGraph、HugeGraph 进行了深度性能测评，测试详情见文章：<a href="https://mp.weixin.qq.com/s?__biz=Mzg4OTg0MzY0Mw==&amp;mid=2247492115&amp;idx=1&amp;sn=1fd71049c940f9ee0013782cf6733a14&amp;source=41#wechat_redirect">主流开源分布式图数据库 Benchmark</a>，从测试结果看 NebulaGraph 在数据导入、实时写入及多跳查询方面性能均优于竞品。此外，NebulaGraph 社区活跃，问题响应速度快，所以团队最终选择基于 NebulaGraph 来搭建图数据库平台</p><h2 id="二-nebulagraph架构">二.nebulagraph架构</h2><p><a href="nebulaGraph%E6%9E%B6%E6%9E%84.png" title="nebulaGraph架构" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93nebulaGraph%E9%80%89%E5%9E%8B//nebulaGraph%E6%9E%B6%E6%9E%84.png" alt="nebulaGraph架构"></a></p><p>一个完整的 NebulaGraph 集群包含三类服务，即 Query Service、Storage Service 和 Meta Service。每类服务都有其各自的可执行二进制文件，既可以部署在同一节点上，也可以部署在不同的节点上。下面是NebulaGraph 架构设计（见图 3）的几个核心点[16][17]。</p><ul><li><strong>Meta Service：</strong> 架构图中右侧为 Meta Service 集群，它采用 Leader/Follower 架构。Leader 由集群中所有的 Meta Service 节点选出，然后对外提供服务；Followers 处于待命状态，并从 Leader 复制更新的数据。一旦 Leader 节点 Down 掉，会再选举其中一个 Follower 成为新的 Leader。Meta Service 不仅负责存储和提供图数据的 Meta 信息，如 Schema、数据分片信息等；同时还提供 Job Manager 机制管理长耗时任务，负责指挥数据迁移、Leader 变更、数据 compaction、索引重建等运维操作。</li><li><strong>存储计算分离：</strong> 在架构图中 Meta Service 的左侧，为 NebulaGraph 的主要服务，NebulaGraph 采用存储与计算分离的架构，虚线以上为计算，以下为存储。存储计算分离有诸多优势，最直接的优势就是，计算层和存储层可以根据各自的情况弹性扩容、缩容。存储计算分离还带来了另一个优势：使水平扩展成为可能。此外，存储计算分离使得 Storage Service 可以为多种类型的计算层或者计算引擎提供服务。当前 Query Service 是一个高优先级的 OLTP 计算层，而各种 OLAP 迭代计算框架会是另外一个计算层。</li><li><strong>无状态计算层：</strong> 每个计算节点都运行着一个无状态的查询计算引擎，而节点彼此间无任何通信关系。计算节点仅从 Meta Service 读取 Meta 信息以及和 Storage Service 进行交互。这样设计使得计算层集群更容易使用 K8s 管理或部署在云上。每个查询计算引擎都能接收客户端的请求，解析查询语句，生成抽象语法树（AST）并将 AST 传递给执行计划器和优化器，最后再交由执行器执行。</li><li><strong>Shared-nothing 分布式存储层：</strong> Storage Service 采用 Shared-nothing 的分布式架构设计，共有三层，最底层是 Store Engine，它是一个单机版 Local Store Engine，提供了对本地数据的get/put/scan/delete 操作，该层定义了数据操作接口，用户可以根据自己的需求定制开发相关 Local Store Plugin。目前，NebulaGraph 提供了基于 RocksDB 实现的 Store Engine。在 Local Store Engine 之上是 Consensus 层，实现了 Multi Group Raft，每一个 Partition 都对应了一组 Raft Group。在 Consensus 层上面是 Storage interfaces，这一层定义了一系列和图相关的 API。 这些 API 请求会在这一层被翻译成一组针对相应 Partition 的 KV 操作。正是这一层的存在，使得存储服务变成了真正的图存储。否则，Storage Service 只是一个 KV 存储罢了。而 NebulaGraph 没把 KV 作为一个服务单独提出，最主要的原因便是图查询过程中会涉及到大量计算，这些计算往往需要使用图的 Schema，而 KV 层没有数据 Schema 概念，这样设计比较容易实现计算下推，是 NebulaGraph 查询性能优越的主要原因。</li></ul><p>NebulaGraph 基于 C++ 实现，架构设计支持存储千亿顶点、万亿边，并提供毫秒级别的查询延时。我们在 3 台 48U192G 物理机搭建的集群上灌入 10 亿美食图谱数据对 NebulaGraph 的功能进行了验证。</p><ul><li>一跳查询 TP99 延时在 5ms 内，两跳查询 TP99 延时在 20ms 内，一般的多跳查询 TP99 延时在百毫秒内。</li><li>集群在线写入速率约为20万 Records/s。</li><li>支持通过 Spark 任务离线生成 RocksDB 底层 SST File，直接将数据文件载入到集群中，即类似 HBase BulkLoad 能力。</li><li>提供了类 SQL 查询语言，对于新增的业务需求，只需构造 NebulaGraph SQL 语句，易于理解且能满足各类复杂查询要求。</li><li>提供联合索引、GEO 索引，可通过实体属性或者关系属性查询实体、关系，或者查询在某个经纬度附近 N 米内的实体。</li><li>一个 NebulaGraph 集群中可以创建多个 Space （概念类似 MySQL 的DataBase），并且不同 Space 中的数据在物理上是隔离的。</li></ul></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;nebulaGraph 选型&lt;/h1&gt;
&lt;h2 id=&quot;一-why-nebulaGraph-？&quot;&gt;一.why nebulaGraph ？&lt;/h2&gt;
&lt;p&gt;在图数据库的选型上我们主要考虑了以下 5 点：(A) 项目</summary>
      
    
    
    
    <category term="数据库" scheme="https://0914ds.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>k8s安装部署nebulaGraph</title>
    <link href="https://0914ds.github.io/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph/"/>
    <id>https://0914ds.github.io/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph/</id>
    <published>2023-05-09T18:45:12.000Z</published>
    <updated>2023-06-22T08:28:37.236Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>k8s集群安装&amp;nebulaGraph部署</h1><h2 id="一，集群环境准备">一，集群环境准备</h2><ul><li><p>集群规划</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把xxx替换为对应的主机名</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">222.141</span> node1</span><br><span class="line"><span class="number">192.168</span>.<span class="number">222.142</span> node2</span><br><span class="line"><span class="number">192.168</span>.<span class="number">222.143</span> node3</span><br></pre></td></tr></table></figure></li><li><p>配置静态ip</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vi /etc/sysconfig/network-scripts/ifcfg-enss3</span></span><br><span class="line"><span class="comment">#添加如下内容：所有集群都是</span></span><br><span class="line">IPADDR=<span class="string">&quot;192.168.222.XXX&quot;</span></span><br><span class="line">PREFIX=<span class="string">&quot;24&quot;</span></span><br><span class="line">GATEWAY=<span class="string">&quot;192.168.222.x&quot;</span></span><br><span class="line">DNS1=<span class="string">&quot;119.29.29.29&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>配置主机名</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl <span class="built_in">set-hostname</span> xxx</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">192.168</span>.<span class="number">222.141</span> node1</span><br><span class="line"><span class="number">192.168</span>.<span class="number">222.142</span> node2</span><br><span class="line"><span class="number">192.168</span>.<span class="number">222.143</span> node3</span><br></pre></td></tr></table></figure></li><li><p>配置ip_forward及过滤机制</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/sysctl.conf</span></span><br><span class="line">net.ipv4.ip_forward = <span class="number">1</span></span><br><span class="line">net.bridge.bridge<span class="literal">-nf-call-ip6tables</span> = <span class="number">1</span></span><br><span class="line">net.bridge.bridge<span class="literal">-nf-call-iptables</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><pre><code class="language-powershell">modprobe br_netfilter<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* ```powershell</span><br><span class="line">  sysctl -p /etc/sysctl.conf</span><br></pre></td></tr></table></figure></code></pre></li><li><p>防火墙</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl stop firewalld</span></span><br><span class="line"><span class="comment"># systemctl disable firewalld</span></span><br></pre></td></tr></table></figure></li><li><p>selinux</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">永久关闭，一定要重启操作系统后生效。</span><br><span class="line">sed <span class="literal">-ri</span> <span class="string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/&#x27;</span> /etc/selinux/config</span><br></pre></td></tr></table></figure></li><li><p>主机swap分区设置</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="literal">-ri</span> <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span><br></pre></td></tr></table></figure></li><li><p>时间同步</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment"># yum -y install ntpdate</span></span><br><span class="line">  <span class="comment"># crontab -e</span></span><br><span class="line"><span class="number">0</span> */<span class="number">1</span> * * *  ntpdate time1.aliyun.com</span><br></pre></td></tr></table></figure></li></ul><h2 id="二、Docker部署">二、Docker部署</h2><blockquote><p>所有主机均要配置</p></blockquote><h3 id="2-1-配置Docker-YUM源">2.1 配置Docker YUM源</h3><p><a href="image-20220130193936921.png" title="image-20220130193936921" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220130193936921.png" alt="image-20220130193936921"></a></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span></span><br></pre></td></tr></table></figure><h3 id="2-2-安装Docker-CE">2.2 安装Docker CE</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  yum install docker-ce-18.09.8-3.el7.x86_64 -y</span></span><br></pre></td></tr></table></figure><h3 id="2-3-启动Docker服务">2.3 启动Docker服务</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl enable docker</span></span><br><span class="line"><span class="comment"># systemctl start docker</span></span><br></pre></td></tr></table></figure><h3 id="2-4-配置Docker容器镜像加速器">2.4 配置Docker容器镜像加速器</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/docker/daemon.json</span></span><br><span class="line"><span class="comment"># cat /etc/docker/daemon.json</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;https://s27w6kze.mirror.aliyuncs.com&quot;</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="三、docker-compose安装">三、docker compose安装</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># curl -L &quot;https://github.com/docker/compose/releases/download/1.28.5/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># chmod +x /usr/local/bin/docker-compose</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker-compose --version</span></span><br></pre></td></tr></table></figure><h2 id="四、添加rancher用户">四、添加rancher用户</h2><blockquote><p>使用CentOS时，不能使用 root 账号，因此要添加专用的账号进行 docker相关 操作。</p></blockquote><blockquote><p>所有集群主机均需要操作</p></blockquote><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># useradd rancher</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># usermod -aG docker rancher</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># echo 123 | passwd --stdin rancher</span></span><br></pre></td></tr></table></figure><h2 id="五、生成ssh证书用于部署集群">五、生成ssh证书用于部署集群</h2><blockquote><p>rke二进制文件安装主机上创建密钥，即为control主机，用于部署集群。</p></blockquote><h3 id="5-1-生成ssh证书">5.1 生成ssh证书</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh-keygen</span></span><br></pre></td></tr></table></figure><h3 id="5-2-复制证书到集群中所有主机">5.2 复制证书到集群中所有主机</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改文件夹所属用户及所属组</span></span><br><span class="line">chown <span class="literal">-R</span> rancher:rancher /home/rancher</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh-copy-id rancher@master01</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh-copy-id rancher@master02</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh-copy-id rancher@worker01</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh-copy-id rancher@worker02</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh-copy-id rancher@etcd01</span></span><br></pre></td></tr></table></figure><h3 id="5-3-验证ssh证书是否可用">5.3 验证ssh证书是否可用</h3><blockquote><p>本次在master01上部署rke二进制文件。</p></blockquote><blockquote><p>在rke二进制文件安装主机机测试连接其它集群主机，验证是否可使用docker ps命令即可。</p></blockquote><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh rancher@主机名</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">远程主机<span class="comment"># docker ps</span></span><br></pre></td></tr></table></figure><h2 id="六、rke工具下载">六、rke工具下载</h2><blockquote><p>本次在master01上部署rke二进制文件。</p></blockquote><p><a href="image-20220222170808926.png" title="image-20220222170808926" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222170808926.png" alt="image-20220222170808926"></a></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wget https://github.com/rancher/rke/releases/download/v1.3.7/rke_linux-amd64</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mv rke_linux-amd64 /usr/local/bin/rke</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># chmod +x /usr/local/bin/rke</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rke --version</span></span><br><span class="line">rke version v1.<span class="number">3.7</span></span><br></pre></td></tr></table></figure><h2 id="七、初始化rke配置文件">七、初始化rke配置文件</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir -p /app/rancher</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /app/rancher</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rke config --name cluster.yml</span></span><br><span class="line">[+] Cluster Level SSH Private Key Path [~/<span class="type">.ssh</span>/<span class="type">id_rsa</span>]: 集群私钥路径</span><br><span class="line">[+] Number of Hosts [<span class="number">1</span>]: <span class="number">3</span> 集群中有<span class="number">3</span>个节点</span><br><span class="line">[+] SSH Address of host (<span class="number">1</span>) [<span class="type">none</span>]: <span class="number">192.168</span>.<span class="number">10.10</span> 第一个节点IP地址</span><br><span class="line">[+] SSH Port of host (<span class="number">1</span>) [<span class="number">22</span>]: <span class="number">22</span> 第一个节点SSH访问端口</span><br><span class="line">[+] SSH Private Key Path of host (<span class="number">192.168</span>.<span class="number">10.10</span>) [<span class="type">none</span>]: ~/.ssh/id_rsa 第一个节点私钥路径</span><br><span class="line">[+] SSH User of host (<span class="number">192.168</span>.<span class="number">10.10</span>) [<span class="type">ubuntu</span>]: rancher 远程用户名</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.10</span>) a Control Plane host (y/n)? [<span class="type">y</span>]: y 是否为k8s集群控制节点</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.10</span>) a Worker host (y/n)? [<span class="type">n</span>]: n 不是worker节点</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.10</span>) an etcd host (y/n)? [<span class="type">n</span>]: n 不是etcd节点</span><br><span class="line">[+] Override Hostname of host (<span class="number">192.168</span>.<span class="number">10.10</span>) [<span class="type">none</span>]: 不覆盖现有主机名</span><br><span class="line">[+] Internal IP of host (<span class="number">192.168</span>.<span class="number">10.10</span>) [<span class="type">none</span>]: 主机局域网IP地址</span><br><span class="line">[+] Docker socket path on host (<span class="number">192.168</span>.<span class="number">10.10</span>) [/<span class="type">var</span>/<span class="type">run</span>/<span class="type">docker.sock</span>]: 主机上docker.sock路径</span><br><span class="line">[+] SSH Address of host (<span class="number">2</span>) [<span class="type">none</span>]: <span class="number">192.168</span>.<span class="number">10.12</span> 第二个节点</span><br><span class="line">[+] SSH Port of host (<span class="number">2</span>) [<span class="number">22</span>]: <span class="number">22</span> 远程端口</span><br><span class="line">[+] SSH Private Key Path of host (<span class="number">192.168</span>.<span class="number">10.12</span>) [<span class="type">none</span>]: ~/.ssh/id_rsa 私钥路径</span><br><span class="line">[+] SSH User of host (<span class="number">192.168</span>.<span class="number">10.12</span>) [<span class="type">ubuntu</span>]: rancher 远程访问用户</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.12</span>) a Control Plane host (y/n)? [<span class="type">y</span>]: n 不是控制节点</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.12</span>) a Worker host (y/n)? [<span class="type">n</span>]: y 是worker节点</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.12</span>) an etcd host (y/n)? [<span class="type">n</span>]: n 不是etcd节点</span><br><span class="line">[+] Override Hostname of host (<span class="number">192.168</span>.<span class="number">10.12</span>) [<span class="type">none</span>]: 不覆盖现有主机名</span><br><span class="line">[+] Internal IP of host (<span class="number">192.168</span>.<span class="number">10.12</span>) [<span class="type">none</span>]: 主机局域网IP地址</span><br><span class="line">[+] Docker socket path on host (<span class="number">192.168</span>.<span class="number">10.12</span>) [/<span class="type">var</span>/<span class="type">run</span>/<span class="type">docker.sock</span>]: 主机上docker.sock路径</span><br><span class="line">[+] SSH Address of host (<span class="number">3</span>) [<span class="type">none</span>]: <span class="number">192.168</span>.<span class="number">10.14</span> 第三个节点</span><br><span class="line">[+] SSH Port of host (<span class="number">3</span>) [<span class="number">22</span>]: <span class="number">22</span> 远程端口</span><br><span class="line">[+] SSH Private Key Path of host (<span class="number">192.168</span>.<span class="number">10.14</span>) [<span class="type">none</span>]: ~/.ssh/id_rsa 私钥路径</span><br><span class="line">[+] SSH User of host (<span class="number">192.168</span>.<span class="number">10.14</span>) [<span class="type">ubuntu</span>]: rancher 远程访问用户</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.14</span>) a Control Plane host (y/n)? [<span class="type">y</span>]: n 不是控制节点</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.14</span>) a Worker host (y/n)? [<span class="type">n</span>]: n 不是worker节点</span><br><span class="line">[+] Is host (<span class="number">192.168</span>.<span class="number">10.14</span>) an etcd host (y/n)? [<span class="type">n</span>]: y 是etcd节点</span><br><span class="line">[+] Override Hostname of host (<span class="number">192.168</span>.<span class="number">10.14</span>) [<span class="type">none</span>]: 不覆盖现有主机名</span><br><span class="line">[+] Internal IP of host (<span class="number">192.168</span>.<span class="number">10.14</span>) [<span class="type">none</span>]: 主机局域网IP地址</span><br><span class="line">[+] Docker socket path on host (<span class="number">192.168</span>.<span class="number">10.14</span>) [/<span class="type">var</span>/<span class="type">run</span>/<span class="type">docker.sock</span>]: 主机上docker.sock路径</span><br><span class="line">[+] Network Plugin <span class="built_in">Type</span> (flannel, calico, weave, canal, aci) [<span class="type">canal</span>]: 使用的网络插件</span><br><span class="line">[+] Authentication Strategy [<span class="type">x509</span>]: 认证策略</span><br><span class="line">[+] Authorization Mode (rbac, none) [<span class="type">rbac</span>]: 认证模式</span><br><span class="line">[+] Kubernetes Docker image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>]: 集群容器镜像</span><br><span class="line">[+] Cluster domain [<span class="type">cluster.local</span>]: 集群域名</span><br><span class="line">[+] Service Cluster IP Range [<span class="number">10.43</span><span class="type">.0.0</span>/<span class="number">16</span>]: 集群中Servic IP地址范围</span><br><span class="line">[+] Enable PodSecurityPolicy [<span class="type">n</span>]: 是否开启Pod安装策略</span><br><span class="line">[+] Cluster Network CIDR [<span class="number">10.42</span><span class="type">.0.0</span>/<span class="number">16</span>]: 集群Pod网络</span><br><span class="line">[+] Cluster DNS Service IP [<span class="number">10.43</span><span class="type">.0.10</span>]: 集群DNS Service IP地址</span><br><span class="line">[+] Add addon manifest URLs or YAML files [<span class="type">no</span>]: 是否增加插件manifest URL或配置文件</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master01</span> <span class="type">rancher</span>]<span class="comment"># ls</span></span><br><span class="line">cluster.yml</span><br></pre></td></tr></table></figure><blockquote><p>在cluster.yaml文件中</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kube<span class="literal">-controller</span>:</span><br><span class="line">image: <span class="string">&quot;&quot;</span></span><br><span class="line">extra_args:</span><br><span class="line"><span class="comment"># 如果后面需要部署kubeflow或istio则一定要配置以下参数</span></span><br><span class="line">cluster<span class="literal">-signing-cert-file</span>: <span class="string">&quot;/etc/kubernetes/ssl/kube-ca.pem&quot;</span></span><br><span class="line">cluster<span class="literal">-signing-key-file</span>: <span class="string">&quot;/etc/kubernetes/ssl/kube-ca-key.pem&quot;</span></span><br></pre></td></tr></table></figure></blockquote><h2 id="八、集群部署">八、集群部署</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pwd</span></span><br><span class="line">/app/rancher</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rke up</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br></pre></td><td class="code"><pre><span class="line">输出：</span><br><span class="line">INFO[<span class="number">0000</span>] Running RKE version: v1.<span class="number">3.7</span></span><br><span class="line">INFO[<span class="number">0000</span>] Initiating Kubernetes cluster</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">dialer</span>] Setup tunnel <span class="keyword">for</span> host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">dialer</span>] Setup tunnel <span class="keyword">for</span> host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">dialer</span>] Setup tunnel <span class="keyword">for</span> host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0000</span>] Checking <span class="keyword">if</span> container [<span class="type">cluster</span>-<span class="type">state</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0000</span>] Checking <span class="keyword">if</span> container [<span class="type">cluster</span>-<span class="type">state</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0000</span>] Checking <span class="keyword">if</span> container [<span class="type">cluster</span>-<span class="type">state</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">certificates</span>] Generating CA kubernetes certificates</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">certificates</span>] Generating Kubernetes API server aggregation layer requestheader client CA certificates</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">certificates</span>] GenerateServingCertificate is disabled, checking <span class="keyword">if</span> there are unused kubelet certificates</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">certificates</span>] Generating Kubernetes API server certificates</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">certificates</span>] Generating Service account token key</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">certificates</span>] Generating Kube Controller certificates</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">certificates</span>] Generating Kube Scheduler certificates</span><br><span class="line">INFO[<span class="number">0000</span>] [<span class="type">certificates</span>] Generating Kube Proxy certificates</span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">certificates</span>] Generating Node certificate</span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">certificates</span>] Generating admin certificates and kubeconfig</span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">certificates</span>] Generating Kubernetes API server proxy client certificates</span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">certificates</span>] Generating kube<span class="literal">-etcd-192-168-10-14</span> certificate and key</span><br><span class="line">INFO[<span class="number">0001</span>] Successfully Deployed state file at [<span class="type">.</span>/<span class="type">cluster.rkestate</span>]</span><br><span class="line">INFO[<span class="number">0001</span>] Building Kubernetes cluster</span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">dialer</span>] Setup tunnel <span class="keyword">for</span> host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">dialer</span>] Setup tunnel <span class="keyword">for</span> host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">dialer</span>] Setup tunnel <span class="keyword">for</span> host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">network</span>] Deploying port listener containers</span><br><span class="line">INFO[<span class="number">0001</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0001</span>] Starting container [<span class="type">rke</span>-<span class="type">etcd</span>-<span class="type">port</span>-<span class="type">listener</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0001</span>] [<span class="type">network</span>] Successfully started [<span class="type">rke</span>-<span class="type">etcd</span>-<span class="type">port</span>-<span class="type">listener</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0001</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0001</span>] Starting container [<span class="type">rke</span>-<span class="type">cp</span>-<span class="type">port</span>-<span class="type">listener</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0002</span>] [<span class="type">network</span>] Successfully started [<span class="type">rke</span>-<span class="type">cp</span>-<span class="type">port</span>-<span class="type">listener</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0002</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0002</span>] Starting container [<span class="type">rke</span>-<span class="type">worker</span>-<span class="type">port</span>-<span class="type">listener</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0002</span>] [<span class="type">network</span>] Successfully started [<span class="type">rke</span>-<span class="type">worker</span>-<span class="type">port</span>-<span class="type">listener</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0002</span>] [<span class="type">network</span>] Port listener containers deployed successfully</span><br><span class="line">INFO[<span class="number">0002</span>] [<span class="type">network</span>] Running control plane -&gt; etcd port checks</span><br><span class="line">INFO[<span class="number">0002</span>] [<span class="type">network</span>] Checking <span class="keyword">if</span> host [<span class="number">192.168</span><span class="type">.10.10</span>] can connect to host(s) [<span class="number">192.168</span><span class="type">.10.14</span>] on port(s) [<span class="number">2379</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0002</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0002</span>] Starting container [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0002</span>] [<span class="type">network</span>] Successfully started [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0002</span>] Removing container [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0002</span>] [<span class="type">network</span>] Running control plane -&gt; worker port checks</span><br><span class="line">INFO[<span class="number">0002</span>] [<span class="type">network</span>] Checking <span class="keyword">if</span> host [<span class="number">192.168</span><span class="type">.10.10</span>] can connect to host(s) [<span class="number">192.168</span><span class="type">.10.12</span>] on port(s) [<span class="number">10250</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0002</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] Starting container [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">network</span>] Successfully started [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] Removing container [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">network</span>] Running workers -&gt; control plane port checks</span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">network</span>] Checking <span class="keyword">if</span> host [<span class="number">192.168</span><span class="type">.10.12</span>] can connect to host(s) [<span class="number">192.168</span><span class="type">.10.10</span>] on port(s) [<span class="number">6443</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] Starting container [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">network</span>] Successfully started [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] Removing container [<span class="type">rke</span>-<span class="type">port</span>-<span class="type">checker</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">network</span>] Checking KubeAPI port Control Plane hosts</span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">network</span>] Removing port listener containers</span><br><span class="line">INFO[<span class="number">0003</span>] Removing container [<span class="type">rke</span>-<span class="type">etcd</span>-<span class="type">port</span>-<span class="type">listener</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">etcd</span>-<span class="type">port</span>-<span class="type">listener</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] Removing container [<span class="type">rke</span>-<span class="type">cp</span>-<span class="type">port</span>-<span class="type">listener</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">cp</span>-<span class="type">port</span>-<span class="type">listener</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] Removing container [<span class="type">rke</span>-<span class="type">worker</span>-<span class="type">port</span>-<span class="type">listener</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">worker</span>-<span class="type">port</span>-<span class="type">listener</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">network</span>] Port listener containers removed successfully</span><br><span class="line">INFO[<span class="number">0003</span>] [<span class="type">certificates</span>] Deploying kubernetes certificates to Cluster nodes</span><br><span class="line">INFO[<span class="number">0003</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0003</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0003</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0004</span>] Starting container [<span class="type">cert</span>-<span class="type">deployer</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0004</span>] Starting container [<span class="type">cert</span>-<span class="type">deployer</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0004</span>] Starting container [<span class="type">cert</span>-<span class="type">deployer</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0004</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0004</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0004</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0009</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0009</span>] Removing container [<span class="type">cert</span>-<span class="type">deployer</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0009</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0009</span>] Removing container [<span class="type">cert</span>-<span class="type">deployer</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0009</span>] Checking <span class="keyword">if</span> container [<span class="type">cert</span>-<span class="type">deployer</span>] is running on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0009</span>] Removing container [<span class="type">cert</span>-<span class="type">deployer</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0009</span>] [<span class="type">reconcile</span>] Rebuilding and updating local kube config</span><br><span class="line">INFO[<span class="number">0009</span>] Successfully Deployed local admin kubeconfig at [<span class="type">.</span>/<span class="type">kube_config_cluster.yml</span>]</span><br><span class="line">WARN[<span class="number">0009</span>] [<span class="type">reconcile</span>] host [<span class="number">192.168</span><span class="type">.10.10</span>] is a control plane node without reachable Kubernetes API endpoint <span class="keyword">in</span> the cluster</span><br><span class="line">WARN[<span class="number">0009</span>] [<span class="type">reconcile</span>] no control plane node with reachable Kubernetes API endpoint <span class="keyword">in</span> the cluster found</span><br><span class="line">INFO[<span class="number">0009</span>] [<span class="type">certificates</span>] Successfully deployed kubernetes certificates to Cluster nodes</span><br><span class="line">INFO[<span class="number">0009</span>] [<span class="type">file</span>-<span class="type">deploy</span>] Deploying file [/<span class="type">etc</span>/<span class="type">kubernetes</span>/<span class="type">audit</span>-<span class="type">policy.yaml</span>] to node [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0009</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0009</span>] Starting container [<span class="type">file</span>-<span class="type">deployer</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0009</span>] Successfully started [<span class="type">file</span>-<span class="type">deployer</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0009</span>] Waiting <span class="keyword">for</span> [<span class="type">file</span>-<span class="type">deployer</span>] container to <span class="keyword">exit</span> on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0009</span>] Waiting <span class="keyword">for</span> [<span class="type">file</span>-<span class="type">deployer</span>] container to <span class="keyword">exit</span> on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0009</span>] Container [<span class="type">file</span>-<span class="type">deployer</span>] is still running on host [<span class="number">192.168</span><span class="type">.10.10</span>]: stderr: [], stdout: []</span><br><span class="line">INFO[<span class="number">0010</span>] Waiting <span class="keyword">for</span> [<span class="type">file</span>-<span class="type">deployer</span>] container to <span class="keyword">exit</span> on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0010</span>] Removing container [<span class="type">file</span>-<span class="type">deployer</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0010</span>] [<span class="type">remove</span>/<span class="type">file</span>-<span class="type">deployer</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0010</span>] [/<span class="type">etc</span>/<span class="type">kubernetes</span>/<span class="type">audit</span>-<span class="type">policy.yaml</span>] Successfully deployed audit policy file to Cluster control nodes</span><br><span class="line">INFO[<span class="number">0010</span>] [<span class="type">reconcile</span>] Reconciling cluster state</span><br><span class="line">INFO[<span class="number">0010</span>] [<span class="type">reconcile</span>] This is newly generated cluster</span><br><span class="line">INFO[<span class="number">0010</span>] Pre<span class="literal">-pulling</span> kubernetes images</span><br><span class="line">INFO[<span class="number">0010</span>] Pulling image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0010</span>] Pulling image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0010</span>] Pulling image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0087</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0090</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0092</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0092</span>] Kubernetes images pulled successfully</span><br><span class="line">INFO[<span class="number">0092</span>] [<span class="type">etcd</span>] Building up etcd plane..</span><br><span class="line">INFO[<span class="number">0092</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0092</span>] Starting container [<span class="type">etcd</span>-<span class="type">fix</span>-<span class="type">perm</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0092</span>] Successfully started [<span class="type">etcd</span>-<span class="type">fix</span>-<span class="type">perm</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0092</span>] Waiting <span class="keyword">for</span> [<span class="type">etcd</span>-<span class="type">fix</span>-<span class="type">perm</span>] container to <span class="keyword">exit</span> on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0092</span>] Waiting <span class="keyword">for</span> [<span class="type">etcd</span>-<span class="type">fix</span>-<span class="type">perm</span>] container to <span class="keyword">exit</span> on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0092</span>] Container [<span class="type">etcd</span>-<span class="type">fix</span>-<span class="type">perm</span>] is still running on host [<span class="number">192.168</span><span class="type">.10.14</span>]: stderr: [], stdout: []</span><br><span class="line">INFO[<span class="number">0093</span>] Waiting <span class="keyword">for</span> [<span class="type">etcd</span>-<span class="type">fix</span>-<span class="type">perm</span>] container to <span class="keyword">exit</span> on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0093</span>] Removing container [<span class="type">etcd</span>-<span class="type">fix</span>-<span class="type">perm</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0093</span>] [<span class="type">remove</span>/<span class="type">etcd</span>-<span class="type">fix</span>-<span class="type">perm</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0093</span>] Image [<span class="type">rancher</span>/<span class="type">mirrored</span>-<span class="type">coreos</span>-<span class="type">etcd</span>:<span class="type">v3.5.0</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0093</span>] Starting container [<span class="type">etcd</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0093</span>] [<span class="type">etcd</span>] Successfully started [<span class="type">etcd</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0093</span>] [<span class="type">etcd</span>] Running rolling snapshot container [<span class="type">etcd</span>-<span class="type">snapshot</span>-<span class="type">once</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0093</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0094</span>] Starting container [<span class="type">etcd</span>-<span class="type">rolling</span>-<span class="type">snapshots</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0094</span>] [<span class="type">etcd</span>] Successfully started [<span class="type">etcd</span>-<span class="type">rolling</span>-<span class="type">snapshots</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0099</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0099</span>] Starting container [<span class="type">rke</span>-<span class="type">bundle</span>-<span class="type">cert</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0099</span>] [<span class="type">certificates</span>] Successfully started [<span class="type">rke</span>-<span class="type">bundle</span>-<span class="type">cert</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0099</span>] Waiting <span class="keyword">for</span> [<span class="type">rke</span>-<span class="type">bundle</span>-<span class="type">cert</span>] container to <span class="keyword">exit</span> on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0099</span>] Container [<span class="type">rke</span>-<span class="type">bundle</span>-<span class="type">cert</span>] is still running on host [<span class="number">192.168</span><span class="type">.10.14</span>]: stderr: [], stdout: []</span><br><span class="line">INFO[<span class="number">0100</span>] Waiting <span class="keyword">for</span> [<span class="type">rke</span>-<span class="type">bundle</span>-<span class="type">cert</span>] container to <span class="keyword">exit</span> on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0100</span>] [<span class="type">certificates</span>] successfully saved certificate bundle [/<span class="type">opt</span>/<span class="type">rke</span>/<span class="type">etcd</span>-<span class="type">snapshots</span>//<span class="type">pki.bundle.tar.gz</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0100</span>] Removing container [<span class="type">rke</span>-<span class="type">bundle</span>-<span class="type">cert</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0100</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0100</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0100</span>] [<span class="type">etcd</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0100</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0100</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0100</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0101</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0101</span>] [<span class="type">etcd</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0101</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0101</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0101</span>] [<span class="type">etcd</span>] Successfully started etcd plane.. Checking etcd cluster health</span><br><span class="line">INFO[<span class="number">0101</span>] [<span class="type">etcd</span>] etcd host [<span class="number">192.168</span><span class="type">.10.14</span>] reported healthy=true</span><br><span class="line">INFO[<span class="number">0101</span>] [<span class="type">controlplane</span>] Building up Controller Plane..</span><br><span class="line">INFO[<span class="number">0101</span>] Checking <span class="keyword">if</span> container [<span class="type">service</span>-<span class="type">sidekick</span>] is running on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0101</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0101</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0101</span>] Starting container [<span class="type">kube</span>-<span class="type">apiserver</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0101</span>] [<span class="type">controlplane</span>] Successfully started [<span class="type">kube</span>-<span class="type">apiserver</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0101</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kube</span>-<span class="type">apiserver</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0106</span>] [<span class="type">healthcheck</span>] service [<span class="type">kube</span>-<span class="type">apiserver</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>] is healthy</span><br><span class="line">INFO[<span class="number">0106</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0107</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0107</span>] [<span class="type">controlplane</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0107</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0107</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0107</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0107</span>] Starting container [<span class="type">kube</span>-<span class="type">controller</span>-<span class="type">manager</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0107</span>] [<span class="type">controlplane</span>] Successfully started [<span class="type">kube</span>-<span class="type">controller</span>-<span class="type">manager</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0107</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kube</span>-<span class="type">controller</span>-<span class="type">manager</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0112</span>] [<span class="type">healthcheck</span>] service [<span class="type">kube</span>-<span class="type">controller</span>-<span class="type">manager</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>] is healthy</span><br><span class="line">INFO[<span class="number">0112</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0113</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0113</span>] [<span class="type">controlplane</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0113</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0113</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0113</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0113</span>] Starting container [<span class="type">kube</span>-<span class="type">scheduler</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0113</span>] [<span class="type">controlplane</span>] Successfully started [<span class="type">kube</span>-<span class="type">scheduler</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0113</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kube</span>-<span class="type">scheduler</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0118</span>] [<span class="type">healthcheck</span>] service [<span class="type">kube</span>-<span class="type">scheduler</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>] is healthy</span><br><span class="line">INFO[<span class="number">0118</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">controlplane</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">controlplane</span>] Successfully started Controller Plane..</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">authz</span>] Creating rke<span class="literal">-job-deployer</span> ServiceAccount</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">authz</span>] rke<span class="literal">-job-deployer</span> ServiceAccount created successfully</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">authz</span>] Creating system:node ClusterRoleBinding</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">authz</span>] system:node ClusterRoleBinding created successfully</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">authz</span>] Creating kube<span class="literal">-apiserver</span> proxy ClusterRole and ClusterRoleBinding</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">authz</span>] kube<span class="literal">-apiserver</span> proxy ClusterRole and ClusterRoleBinding created successfully</span><br><span class="line">INFO[<span class="number">0119</span>] Successfully Deployed state file at [<span class="type">.</span>/<span class="type">cluster.rkestate</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">state</span>] Saving full cluster state to Kubernetes</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">state</span>] Successfully Saved full cluster state to Kubernetes ConfigMap: full<span class="literal">-cluster-state</span></span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">worker</span>] Building up Worker Plane..</span><br><span class="line">INFO[<span class="number">0119</span>] Checking <span class="keyword">if</span> container [<span class="type">service</span>-<span class="type">sidekick</span>] is running on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0119</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">sidekick</span>] Sidekick container already created on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Starting container [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">worker</span>] Successfully started [<span class="type">kubelet</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Starting container [<span class="type">nginx</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">worker</span>] Successfully started [<span class="type">nginx</span>-<span class="type">proxy</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Starting container [<span class="type">nginx</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0119</span>] [<span class="type">worker</span>] Successfully started [<span class="type">nginx</span>-<span class="type">proxy</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0119</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0120</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0120</span>] [<span class="type">worker</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0120</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] Checking <span class="keyword">if</span> container [<span class="type">service</span>-<span class="type">sidekick</span>] is running on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0120</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] [<span class="type">worker</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0120</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] Checking <span class="keyword">if</span> container [<span class="type">service</span>-<span class="type">sidekick</span>] is running on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0120</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] Starting container [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0120</span>] [<span class="type">worker</span>] Successfully started [<span class="type">kubelet</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] Starting container [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0120</span>] [<span class="type">worker</span>] Successfully started [<span class="type">kubelet</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0120</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0124</span>] [<span class="type">healthcheck</span>] service [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>] is healthy</span><br><span class="line">INFO[<span class="number">0124</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0124</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0125</span>] [<span class="type">worker</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0125</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0125</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0125</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0125</span>] Starting container [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0125</span>] [<span class="type">worker</span>] Successfully started [<span class="type">kube</span>-<span class="type">proxy</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0125</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0125</span>] [<span class="type">healthcheck</span>] service [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>] is healthy</span><br><span class="line">INFO[<span class="number">0125</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0125</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0125</span>] [<span class="type">healthcheck</span>] service [<span class="type">kubelet</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>] is healthy</span><br><span class="line">INFO[<span class="number">0125</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0125</span>] [<span class="type">worker</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0125</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0125</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0126</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0126</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0126</span>] Starting container [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0126</span>] [<span class="type">worker</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0126</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0126</span>] [<span class="type">worker</span>] Successfully started [<span class="type">kube</span>-<span class="type">proxy</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0126</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0126</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0126</span>] Image [<span class="type">rancher</span>/<span class="type">hyperkube</span>:<span class="type">v1.21.9</span>-<span class="type">rancher1</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0126</span>] Starting container [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0126</span>] [<span class="type">worker</span>] Successfully started [<span class="type">kube</span>-<span class="type">proxy</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0126</span>] [<span class="type">healthcheck</span>] <span class="built_in">Start</span> Healthcheck on service [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0130</span>] [<span class="type">healthcheck</span>] service [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>] is healthy</span><br><span class="line">INFO[<span class="number">0130</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0130</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0130</span>] [<span class="type">worker</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0130</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0130</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] [<span class="type">healthcheck</span>] service [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>] is healthy</span><br><span class="line">INFO[<span class="number">0131</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0131</span>] [<span class="type">healthcheck</span>] service [<span class="type">kube</span>-<span class="type">proxy</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>] is healthy</span><br><span class="line">INFO[<span class="number">0131</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] [<span class="type">worker</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0131</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0131</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] [<span class="type">worker</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0131</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">linker</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] [<span class="type">worker</span>] Successfully started Worker Plane..</span><br><span class="line">INFO[<span class="number">0131</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0131</span>] Image [<span class="type">rancher</span>/<span class="type">rke</span>-<span class="type">tools</span>:<span class="type">v0.1.78</span>] exists on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0132</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0132</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0132</span>] Starting container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">cleanup</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0132</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] on host [<span class="number">192.168</span><span class="type">.10.14</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">cleanup</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0132</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] on host [<span class="number">192.168</span><span class="type">.10.12</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">cleanup</span>] Successfully started [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0132</span>] Removing container [<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] on host [<span class="number">192.168</span><span class="type">.10.10</span>], <span class="keyword">try</span> <span class="comment">#1</span></span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.14</span>]</span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.12</span>]</span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">remove</span>/<span class="type">rke</span>-<span class="type">log</span>-<span class="type">cleaner</span>] Successfully removed container on host [<span class="number">192.168</span><span class="type">.10.10</span>]</span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">sync</span>] Syncing nodes Labels and Taints</span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">sync</span>] Successfully synced nodes Labels and Taints</span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">network</span>] Setting up network plugin: canal</span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">addons</span>] Saving ConfigMap <span class="keyword">for</span> addon rke<span class="literal">-network-plugin</span> to Kubernetes</span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">addons</span>] Successfully saved ConfigMap <span class="keyword">for</span> addon rke<span class="literal">-network-plugin</span> to Kubernetes</span><br><span class="line">INFO[<span class="number">0132</span>] [<span class="type">addons</span>] Executing deploy job rke<span class="literal">-network-plugin</span></span><br><span class="line">INFO[<span class="number">0137</span>] [<span class="type">addons</span>] Setting up coredns</span><br><span class="line">INFO[<span class="number">0137</span>] [<span class="type">addons</span>] Saving ConfigMap <span class="keyword">for</span> addon rke<span class="literal">-coredns-addon</span> to Kubernetes</span><br><span class="line">INFO[<span class="number">0137</span>] [<span class="type">addons</span>] Successfully saved ConfigMap <span class="keyword">for</span> addon rke<span class="literal">-coredns-addon</span> to Kubernetes</span><br><span class="line">INFO[<span class="number">0137</span>] [<span class="type">addons</span>] Executing deploy job rke<span class="literal">-coredns-addon</span></span><br><span class="line">INFO[<span class="number">0142</span>] [<span class="type">addons</span>] CoreDNS deployed successfully</span><br><span class="line">INFO[<span class="number">0142</span>] [<span class="type">dns</span>] DNS provider coredns deployed successfully</span><br><span class="line">INFO[<span class="number">0142</span>] [<span class="type">addons</span>] Setting up Metrics Server</span><br><span class="line">INFO[<span class="number">0142</span>] [<span class="type">addons</span>] Saving ConfigMap <span class="keyword">for</span> addon rke<span class="literal">-metrics-addon</span> to Kubernetes</span><br><span class="line">INFO[<span class="number">0142</span>] [<span class="type">addons</span>] Successfully saved ConfigMap <span class="keyword">for</span> addon rke<span class="literal">-metrics-addon</span> to Kubernetes</span><br><span class="line">INFO[<span class="number">0142</span>] [<span class="type">addons</span>] Executing deploy job rke<span class="literal">-metrics-addon</span></span><br><span class="line">INFO[<span class="number">0147</span>] [<span class="type">addons</span>] Metrics Server deployed successfully</span><br><span class="line">INFO[<span class="number">0147</span>] [<span class="type">ingress</span>] Setting up nginx ingress controller</span><br><span class="line">INFO[<span class="number">0147</span>] [<span class="type">ingress</span>] removing admission batch jobs <span class="keyword">if</span> they exist</span><br><span class="line">INFO[<span class="number">0147</span>] [<span class="type">addons</span>] Saving ConfigMap <span class="keyword">for</span> addon rke<span class="literal">-ingress-controller</span> to Kubernetes</span><br><span class="line">INFO[<span class="number">0147</span>] [<span class="type">addons</span>] Successfully saved ConfigMap <span class="keyword">for</span> addon rke<span class="literal">-ingress-controller</span> to Kubernetes</span><br><span class="line">INFO[<span class="number">0147</span>] [<span class="type">addons</span>] Executing deploy job rke<span class="literal">-ingress-controller</span></span><br><span class="line">INFO[<span class="number">0152</span>] [<span class="type">ingress</span>] removing default backend service and deployment <span class="keyword">if</span> they exist</span><br><span class="line">INFO[<span class="number">0152</span>] [<span class="type">ingress</span>] ingress controller nginx deployed successfully</span><br><span class="line">INFO[<span class="number">0152</span>] [<span class="type">addons</span>] Setting up user addons</span><br><span class="line">INFO[<span class="number">0152</span>] [<span class="type">addons</span>] no user addons defined</span><br><span class="line">INFO[<span class="number">0152</span>] Finished building Kubernetes cluster successfully</span><br></pre></td></tr></table></figure><blockquote><p>如果部署失败，报错：</p><p>WARN[0114] [etcd] host [xxxxxxx] failed to check etcd health: failed to get /health for host [xxxxxxx]: Get “<a href="https://xxxxxxxx:2379/health">https://xxxxxxxx:2379/health</a>”: remote error: tls: bad certificate<br>FATA[0114] [etcd] Failed to bring up Etcd Plane: etcd cluster is unhealthy: hosts [xxxxxxxx] failed to report healthy. Check etcd container logs on each host for more information</p><p>所有节点执行（无法删除就重启机器）：rm -rf /etc/kubernetes/ /var/lib/kubelet/ /var/lib/etcd/</p></blockquote><h2 id="九、安装kubectl客户端">九、安装kubectl客户端</h2><blockquote><p>在master01主机上操作。</p></blockquote><h3 id="9-1-kubectl客户端安装">9.1 kubectl客户端安装</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wget https://storage.googleapis.com/kubernetes-release/release/v1.21.9/bin/linux/amd64/kubectl</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># chmod +x kubectl </span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mv kubectl /usr/local/bin/kubectl</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl version --client</span></span><br><span class="line">Client Version: version.Info&#123;Major:<span class="string">&quot;1&quot;</span>, Minor:<span class="string">&quot;21&quot;</span>, GitVersion:<span class="string">&quot;v1.21.9&quot;</span>, GitCommit:<span class="string">&quot;f59f5c2fda36e4036b49ec027e556a15456108f0&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, BuildDate:<span class="string">&quot;2022-01-19T17:33:06Z&quot;</span>, GoVersion:<span class="string">&quot;go1.16.12&quot;</span>, Compiler:<span class="string">&quot;gc&quot;</span>, Platform:<span class="string">&quot;linux/amd64&quot;</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="9-2-kubectl客户端配置集群管理文件及应用验证">9.2 kubectl客户端配置集群管理文件及应用验证</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># ls /app/rancher/</span></span><br><span class="line">cluster.rkestate  cluster.yml  kube_config_cluster.yml</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># mkdir ./.kube</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># cp /app/rancher/kube_config_cluster.yml /root/.kube/config</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME            STATUS   ROLES          AGE     VERSION</span><br><span class="line"><span class="number">192.168</span>.<span class="number">10.10</span>   Ready    controlplane   <span class="number">9</span>m13s   v1.<span class="number">21.9</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">10.12</span>   Ready    worker         <span class="number">9</span>m12s   v1.<span class="number">21.9</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">10.14</span>   Ready    etcd           <span class="number">9</span>m12s   v1.<span class="number">21.9</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># kubectl get pods -n kube-system</span></span><br><span class="line">NAME                                         READY   STATUS      RESTARTS   AGE</span><br><span class="line">calico<span class="literal">-kube-controllers-5685fbd9f7-gcwj7</span>     <span class="number">1</span>/<span class="number">1</span>     Running     <span class="number">0</span>          <span class="number">9</span>m36s</span><br><span class="line">canal<span class="literal">-fz2bg</span>                                  <span class="number">2</span>/<span class="number">2</span>     Running     <span class="number">0</span>          <span class="number">9</span>m36s</span><br><span class="line">canal<span class="literal">-qzw4n</span>                                  <span class="number">2</span>/<span class="number">2</span>     Running     <span class="number">0</span>          <span class="number">9</span>m36s</span><br><span class="line">canal<span class="literal">-sstjn</span>                                  <span class="number">2</span>/<span class="number">2</span>     Running     <span class="number">0</span>          <span class="number">9</span>m36s</span><br><span class="line">coredns<span class="literal">-8578b6dbdd-ftnf6</span>                     <span class="number">1</span>/<span class="number">1</span>     Running     <span class="number">0</span>          <span class="number">9</span>m30s</span><br><span class="line">coredns<span class="literal">-autoscaler-f7b68ccb7-fzdgc</span>           <span class="number">1</span>/<span class="number">1</span>     Running     <span class="number">0</span>          <span class="number">9</span>m30s</span><br><span class="line">metrics<span class="literal">-server-6bc7854fb5-kwppz</span>              <span class="number">1</span>/<span class="number">1</span>     Running     <span class="number">0</span>          <span class="number">9</span>m25s</span><br><span class="line">rke<span class="literal">-coredns-addon-deploy-job--1-x56w2</span>        <span class="number">0</span>/<span class="number">1</span>     Completed   <span class="number">0</span>          <span class="number">9</span>m31s</span><br><span class="line">rke<span class="literal">-ingress-controller-deploy-job--1-wzp2b</span>   <span class="number">0</span>/<span class="number">1</span>     Completed   <span class="number">0</span>          <span class="number">9</span>m21s</span><br><span class="line">rke<span class="literal">-metrics-addon-deploy-job--1-ltlgn</span>        <span class="number">0</span>/<span class="number">1</span>     Completed   <span class="number">0</span>          <span class="number">9</span>m26s</span><br><span class="line">rke<span class="literal">-network-plugin-deploy-job--1-nsbfn</span>       <span class="number">0</span>/<span class="number">1</span>     Completed   <span class="number">0</span>          <span class="number">9</span>m41s</span><br></pre></td></tr></table></figure><h2 id="十、集群web管理-rancher">十、集群web管理 rancher</h2><blockquote><p>在master01运行</p></blockquote><p>rancher控制面板主要方便用于控制k8s集群，查看集群状态，编辑集群等。</p><h3 id="10-1，使用docker-run启动一个rancher">10.1，使用docker run启动一个rancher</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意映射端口改了</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># docker run -d --restart=unless-stopped --privileged --name rancher -p 1080:80 -p 1443:443 rancher/rancher:v2.5.9</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID   IMAGE                                COMMAND                  CREATED          STATUS          PORTS                                                                      NAMES</span><br><span class="line"><span class="number">0</span>fd46ee77655   rancher/rancher:v2.<span class="number">5.9</span>               <span class="string">&quot;entrypoint.sh&quot;</span>          <span class="number">5</span> seconds ago    Up <span class="number">3</span> seconds    <span class="number">0.0</span>.<span class="number">0.0</span>:<span class="number">80</span>-&gt;<span class="number">80</span>/tcp, :::<span class="number">80</span>-&gt;<span class="number">80</span>/tcp, <span class="number">0.0</span>.<span class="number">0.0</span>:<span class="number">443</span>-&gt;<span class="number">443</span>/tcp, :::<span class="number">443</span>-&gt;<span class="number">443</span>/tcp   rancher</span><br></pre></td></tr></table></figure><h3 id="10-2-访问rancher【这里映射端口1080，1443】">10.2 访问rancher【这里映射端口1080，1443】</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># ss -anput | grep &quot;:1080&quot;</span></span><br><span class="line">tcp    LISTEN     <span class="number">0</span>      <span class="number">128</span>       *:<span class="number">1080</span>                    *:*                   users:((<span class="string">&quot;docker-proxy&quot;</span>,pid=<span class="number">29564</span>,fd=<span class="number">4</span>))</span><br><span class="line">tcp    LISTEN     <span class="number">0</span>      <span class="number">128</span>    [::]:<span class="number">1080</span>                 [::]:*                   users:((<span class="string">&quot;docker-proxy&quot;</span>,pid=<span class="number">29570</span>,fd=<span class="number">4</span>))</span><br></pre></td></tr></table></figure><p><a href="image-20220222120525765.png" title="image-20220222120525765" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222120525765.png" alt="image-20220222120525765"></a></p><p><a href="image-20220222120615706.png" title="image-20220222120615706" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222120615706.png" alt="image-20220222120615706"></a></p><p><a href="image-20220222120657384.png" title="image-20220222120657384" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222120657384.png" alt="image-20220222120657384"></a></p><p><a href="image-20220222121036160.png" title="image-20220222121036160" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222121036160.png" alt="image-20220222121036160"></a></p><p><a href="image-20220222121132181.png" title="image-20220222121132181" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222121132181.png" alt="image-20220222121132181"></a></p><h3 id="10-3-在rancher-web界面添加kubernetes集群">10.3 在rancher web界面添加kubernetes集群</h3><p><a href="image-20220222121419801.png" title="image-20220222121419801" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222121419801.png" alt="image-20220222121419801"></a></p><p><a href="image-20220222121500369.png" title="image-20220222121500369" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222121500369.png" alt="image-20220222121500369"></a></p><p><a href="image-20220222121639207.png" title="image-20220222121639207" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222121639207.png" alt="image-20220222121639207"></a></p><p><a href="image-20220222121800708.png" title="image-20220222121800708" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222121800708.png" alt="image-20220222121800708"></a></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">使用第一条报错：</span><br><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># kubectl apply -f https://192.168.10.10/v3/import/vljtg5srnznpzts662q6ncs4jm6f8kd847xqs97d6fbs5rhn7kfzvk_c-ktwhn.yaml</span></span><br><span class="line">Unable to connect to the server: x509: certificate is valid <span class="keyword">for</span> <span class="number">127.0</span>.<span class="number">0.1</span>, <span class="number">172.17</span>.<span class="number">0.2</span>, not <span class="number">192.168</span>.<span class="number">10.10</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">使用第二条：</span><br><span class="line"></span><br><span class="line">第一次报错：</span><br><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># curl --insecure -sfL https://192.168.10.10/v3/import/vljtg5srnznpzts662q6ncs4jm6f8kd847xqs97d6fbs5rhn7kfzvk_c-ktwhn.yaml | kubectl apply -f -</span></span><br><span class="line">error: no objects passed to apply</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">第二次成功：</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master01</span> ~]<span class="comment"># curl --insecure -sfL https://192.168.10.10/v3/import/vljtg5srnznpzts662q6ncs4jm6f8kd847xqs97d6fbs5rhn7kfzvk_c-ktwhn.yaml | kubectl apply -f -</span></span><br><span class="line">Warning: resource clusterroles/proxy<span class="literal">-clusterrole-kubeapiserver</span> is missing the kubectl.kubernetes.io/last<span class="literal">-applied-configuration</span> annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create <span class="literal">--save-config</span> or kubectl apply. The missing annotation will be patched automatically.</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/proxy<span class="literal">-clusterrole-kubeapiserver</span> configured</span><br><span class="line">Warning: resource clusterrolebindings/proxy<span class="literal">-role-binding-kubernetes-master</span> is missing the kubectl.kubernetes.io/last<span class="literal">-applied-configuration</span> annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create <span class="literal">--save-config</span> or kubectl apply. The missing annotation will be patched automatically.</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/proxy<span class="literal">-role-binding-kubernetes-master</span> configured</span><br><span class="line">namespace/cattle<span class="literal">-system</span> created</span><br><span class="line">serviceaccount/cattle created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/cattle<span class="literal">-admin-binding</span> created</span><br><span class="line">secret/cattle<span class="literal">-credentials-0619853</span> created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/cattle<span class="literal">-admin</span> created</span><br><span class="line">Warning: spec.template.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms[<span class="number">0</span>].matchExpressions[<span class="number">0</span>].key: beta.kubernetes.io/os is deprecated since v1.<span class="number">14</span>; use <span class="string">&quot;kubernetes.io/os&quot;</span> instead</span><br><span class="line">deployment.apps/cattle<span class="literal">-cluster-agent</span> created</span><br></pre></td></tr></table></figure><p><a href="image-20220222124826542.png" title="image-20220222124826542" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222124826542.png" alt="image-20220222124826542"></a></p><p><a href="image-20220222124844668.png" title="image-20220222124844668" class="gallery-item" style="box-shadow: none;"> <img src="/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/graphdatabase/k8s%E9%83%A8%E7%BD%B2nebulaGraph//image-20220222124844668.png" alt="image-20220222124844668"></a></p><ul><li><p>查看pod运行在那个节点</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看podid</span></span><br><span class="line">kubectl get pods <span class="literal">-o</span> wide</span><br><span class="line"><span class="comment">#进入pod</span></span><br><span class="line">kubectl exec <span class="literal">-it</span> containerid  <span class="literal">--</span> /bin/sh</span><br></pre></td></tr></table></figure></li></ul><h2 id="十一，搭建nfs服务器">十一，搭建nfs服务器</h2><ul><li><pre><code class="language-powershell">[root@nfsserver ~]# mkdir -p /data/nfs[root@nfsserver ~]# vim /etc/exports/data/nfs       *(rw,no_root_squash,sync)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* 所有节点中安装nfs客户端</span><br><span class="line"></span><br><span class="line">  ```powershell</span><br><span class="line">  yum install nfs-utils -y</span><br></pre></td></tr></table></figure></code></pre></li><li><p>验证是否可用再工作节点中</p></li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showmount <span class="literal">-e</span> <span class="number">192.168</span>.<span class="number">222.143</span> <span class="comment">#nfs服务器的地址</span></span><br></pre></td></tr></table></figure><h2 id="十二-使用NFS文件系统创建存储动态供给-storageclass安装">十二 使用NFS文件系统创建存储动态供给(storageclass安装)</h2><p>PV对存储系统的支持可通过其插件来实现，目前，Kubernetes支持如下类型的插件。</p><p>PV对存储系统的支持可通过其插件来实现，目前，Kubernetes支持如下类型的插件。</p><p>官方地址：<a href="https://kubernetes.io/docs/concepts/storage/storage-classes/">https://kubernetes.io/docs/concepts/storage/storage-classes/</a></p><p>官方插件是不支持NFS动态供给的，但是我们可以用第三方的插件来实现</p><p>第三方插件地址: <a href="https://github.com/kubernetes-retired/external-storage">https://github.com/kubernetes-retired/external-storage</a></p><h3 id="12-1，下载并创建storageclass">12.1，下载并创建storageclass</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># wget https://raw.githubusercontent.com/kubernetes-sigs/nfs-subdir-external-provisioner/master/deploy/class.yaml</span></span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># mv class.yaml storageclass-nfs.yml</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># cat storageclass-nfs.yml</span></span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass<span class="comment"># 类型</span></span><br><span class="line">metadata:</span><br><span class="line">  name: nfs<span class="literal">-client</span><span class="comment"># 名称,要使用就需要调用此名称</span></span><br><span class="line">provisioner: k8s<span class="literal">-sigs</span>.io/nfs<span class="literal">-subdir-external-provisioner</span> <span class="comment"># 动态供给插件</span></span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: <span class="string">&quot;false&quot;</span><span class="comment"># 删除数据时是否存档，false表示不存档，true表示存档</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># kubectl apply -f storageclass-nfs.yml</span></span><br><span class="line">storageclass.storage.k8s.io/managed<span class="literal">-nfs-storage</span> created</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># kubectl get storageclass</span></span><br><span class="line">NAME         PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE</span><br><span class="line">nfs<span class="literal">-client</span>   k8s<span class="literal">-sigs</span>.io/nfs<span class="literal">-subdir-external-provisioner</span>   Delete          Immediate           false                  <span class="number">10</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># RECLAIMPOLICY pv回收策略，pod或pvc被删除后，pv是否删除还是保留。</span></span><br><span class="line"><span class="comment"># VOLUMEBINDINGMODE Immediate 模式下PVC与PV立即绑定，主要是不等待相关Pod调度完成，不关心其运行节点，直接完成绑定。相反的 WaitForFirstConsumer模式下需要等待Pod调度完成后进行PV绑定。</span></span><br><span class="line"><span class="comment"># ALLOWVOLUMEEXPANSION pvc扩容</span></span><br></pre></td></tr></table></figure><h3 id="12-2，下载并创建rbac">12.2，下载并创建rbac</h3><p>因为storage自动创建pv需要经过kube-apiserver，所以需要授权。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># wget https://raw.githubusercontent.com/kubernetes-sigs/nfs-subdir-external-provisioner/master/deploy/rbac.yaml</span></span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># mv rbac.yaml storageclass-nfs-rbac.yaml</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># cat storageclass-nfs-rbac.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs<span class="literal">-client-provisioner</span></span><br><span class="line">  <span class="comment"># replace with namespace where provisioner is deployed</span></span><br><span class="line">  namespace: default</span><br><span class="line"><span class="literal">---</span></span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs<span class="literal">-client-provisioner-runner</span></span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;persistentvolumes&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]</span><br><span class="line">  - apiGroups: [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;persistentvolumeclaims&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]</span><br><span class="line">  - apiGroups: [<span class="string">&quot;storage.k8s.io&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;storageclasses&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  - apiGroups: [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;events&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]</span><br><span class="line"><span class="literal">---</span></span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: run<span class="literal">-nfs-client-provisioner</span></span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs<span class="literal">-client-provisioner</span></span><br><span class="line">    <span class="comment"># replace with namespace where provisioner is deployed</span></span><br><span class="line">    namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nfs<span class="literal">-client-provisioner-runner</span></span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line"><span class="literal">---</span></span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader<span class="literal">-locking-nfs-client-provisioner</span></span><br><span class="line">  <span class="comment"># replace with namespace where provisioner is deployed</span></span><br><span class="line">  namespace: default</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;endpoints&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]</span><br><span class="line"><span class="literal">---</span></span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader<span class="literal">-locking-nfs-client-provisioner</span></span><br><span class="line">  <span class="comment"># replace with namespace where provisioner is deployed</span></span><br><span class="line">  namespace: default</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs<span class="literal">-client-provisioner</span></span><br><span class="line">    <span class="comment"># replace with namespace where provisioner is deployed</span></span><br><span class="line">    namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: leader<span class="literal">-locking-nfs-client-provisioner</span></span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># kubectl apply -f rbac.yaml</span></span><br><span class="line">serviceaccount/nfs<span class="literal">-client-provisioner</span> created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/nfs<span class="literal">-client-provisioner-runner</span> created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/run<span class="literal">-nfs-client-provisioner</span> created</span><br><span class="line">role.rbac.authorization.k8s.io/leader<span class="literal">-locking-nfs-client-provisioner</span> created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/leader<span class="literal">-locking-nfs-client-provisioner</span> created</span><br></pre></td></tr></table></figure><h3 id="12-3，创建动态供给的deployment">12.3，创建动态供给的deployment</h3><p>需要一个deployment来专门实现pv与pvc的自动创建</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># vim deploy-nfs-client-provisioner.yml</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs<span class="literal">-client-provisioner</span></span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">1</span></span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: Recreate</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nfs<span class="literal">-client-provisioner</span></span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs<span class="literal">-client-provisioner</span></span><br><span class="line">    spec:</span><br><span class="line">      serviceAccount: nfs<span class="literal">-client-provisioner</span></span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs<span class="literal">-client-provisioner</span></span><br><span class="line">          image: registry.cn<span class="literal">-beijing</span>.aliyuncs.com/pylixm/nfs<span class="literal">-subdir-external-provisioner</span>:v4.<span class="number">0.0</span></span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs<span class="literal">-client-root</span></span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: k8s<span class="literal">-sigs</span>.io/nfs<span class="literal">-subdir-external-provisioner</span></span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: <span class="number">192.168</span>.<span class="number">10.129</span></span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /<span class="keyword">data</span>/nfs</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs<span class="literal">-client-root</span></span><br><span class="line">          nfs:</span><br><span class="line">            server: <span class="number">192.168</span>.<span class="number">10.129</span></span><br><span class="line">            path: /<span class="keyword">data</span>/nfs</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># kubectl apply -f deploy-nfs-client-provisioner.yml</span></span><br><span class="line">deployment.apps/nfs<span class="literal">-client-provisioner</span> created</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master1</span> ~]<span class="comment"># kubectl get pods |grep nfs-client-provisioner</span></span><br><span class="line">nfs<span class="literal">-client-provisioner-5b5ddcd6c8-b6zbq</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">34</span>s</span><br></pre></td></tr></table></figure><h2 id="十三，nebulaGraph-operator-安装部署">十三，nebulaGraph operator 安装部署</h2><ul><li><p>参考官网  安装 NebulaGraph Operator 前，用户需要安装以下软件并确保安装版本的正确性（NebulaGraph Operator 不负责处理安装这些软件过程中出现的问题）。</p><table><thead><tr><th style="text-align:left">软件</th><th style="text-align:left">版本要求</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://kubernetes.io/">Kubernetes</a></td><td style="text-align:left">&gt;= 1.16</td></tr><tr><td style="text-align:left"><a href="https://helm.sh/">Helm</a></td><td style="text-align:left">&gt;= 3.2.0</td></tr><tr><td style="text-align:left"><a href="https://github.com/coredns/coredns">CoreDNS</a></td><td style="text-align:left">&gt;= 1.6.0</td></tr></tbody></table></li><li><p>Helm安装</p> <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">a</span> ~]<span class="comment"># curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash</span></span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line"><span class="number">100</span> <span class="number">11345</span>  <span class="number">100</span> <span class="number">11345</span>    <span class="number">0</span>     <span class="number">0</span>  <span class="number">18830</span>      <span class="number">0</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span> <span class="number">18845</span></span><br><span class="line">[<span class="type">WARNING</span>] Could not find git. It is required <span class="keyword">for</span> plugin installation.</span><br><span class="line">Downloading https://get.helm.sh/helm<span class="literal">-v3</span>.<span class="number">12.1</span><span class="literal">-linux-amd64</span>.tar.gz</span><br><span class="line">Verifying checksum... Done.</span><br><span class="line">Preparing to install helm into /usr/local/bin</span><br><span class="line">helm installed into /usr/local/bin/helm</span><br></pre></td></tr></table></figure></li><li><p>coreDNS安装可以网上查阅资料(上面rke安装过程中已经安装了coredns)</p></li><li><p>安装 NebulaGraph Operator</p></li></ul><ol><li><p>添加 NebulaGraph Operator Helm 仓库。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm repo add nebula-operator https://vesoft-inc.github.io/nebula-operator/charts</span><br></pre></td></tr></table></figure></li><li><p>拉取最新的 Operator Helm 仓库。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm repo update</span><br></pre></td></tr></table></figure><p>参考 <a href="https://helm.sh/docs/helm/helm_repo/">Helm 仓库</a>获取更多<code>helm repo</code>相关信息。</p></li><li><p>创建命名空间用于安装 NebulaGraph Operator。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace &lt;namespace_name&gt;</span><br></pre></td></tr></table></figure><p>例如，创建operator命名空间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace operator</span><br></pre></td></tr></table></figure><ul><li>nebula-operator chart 中的所有资源都会安装在该命名空间下。</li><li>用户也可创建其他命名空间。</li></ul></li><li><p>安装 NebulaGraph Operator。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install nebula-operator nebula-operator/nebula-operator --namespace=&lt;namespace_name&gt; --version=$&#123;chart_version&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 目前1.5.0无法安装 可以不指定版本 默认安装最新版本,由于gcr.io无法下载镜像使用kubesphere/kube-rbac-proxy:v0.8.0代替</span><br><span class="line"></span><br><span class="line">helm install nebula-operator nebula-operator/nebula-operator --namespace=nebula-operator-system --set image.kubeRBACProxy.image=kubesphere/kube-rbac-proxy:v0.8.0</span><br></pre></td></tr></table></figure></li></ol><ul><li><h3 id="卸载-NebulaGraph-Operator">卸载 NebulaGraph Operator</h3><ol><li><p>卸载 NebulaGraph Operator chart。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm uninstall nebula-operator --namespace=operator</span><br></pre></td></tr></table></figure></li><li><p>删除 CRD。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete crd nebulaclusters.apps.nebula-graph.io</span><br></pre></td></tr></table></figure></li></ol></li></ul><h2 id="十四，部署nebulaGraph（kubectl）">十四，部署nebulaGraph（kubectl）</h2><ul><li>创建集群配置文件。</li></ul><p>​       创建名为<code>apps_v1alpha1_nebulacluster.yaml</code>的文件。官网提供了模板可以直接下载</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps.nebula<span class="literal">-graph</span>.io/v1alpha1</span><br><span class="line">kind: NebulaCluster</span><br><span class="line">metadata:</span><br><span class="line">  name: nebula</span><br><span class="line">spec:</span><br><span class="line">  graphd:</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: <span class="string">&quot;500m&quot;</span></span><br><span class="line">        memory: <span class="string">&quot;500Mi&quot;</span></span><br><span class="line">      limits:</span><br><span class="line">        cpu: <span class="string">&quot;1&quot;</span></span><br><span class="line">        memory: <span class="string">&quot;1Gi&quot;</span></span><br><span class="line">    replicas: <span class="number">1</span></span><br><span class="line">    image: vesoft/nebula<span class="literal">-graphd</span></span><br><span class="line">    version: v3.<span class="number">5.0</span></span><br><span class="line">    service:</span><br><span class="line">      <span class="built_in">type</span>: NodePort</span><br><span class="line">      externalTrafficPolicy: Local</span><br><span class="line">    logVolumeClaim:</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: <span class="number">1</span><span class="built_in">Gi</span></span><br><span class="line">      storageClassName: managed<span class="literal">-nfs-storage</span></span><br><span class="line">  metad:</span><br><span class="line"><span class="comment">#    license:</span></span><br><span class="line"><span class="comment">#      secretName: &quot;nebula-license&quot;</span></span><br><span class="line"><span class="comment">#      licenseKey: &quot;nebula.license&quot;</span></span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: <span class="string">&quot;500m&quot;</span></span><br><span class="line">        memory: <span class="string">&quot;500Mi&quot;</span></span><br><span class="line">      limits:</span><br><span class="line">        cpu: <span class="string">&quot;1&quot;</span></span><br><span class="line">        memory: <span class="string">&quot;1Gi&quot;</span></span><br><span class="line">    replicas: <span class="number">1</span></span><br><span class="line">    image: vesoft/nebula<span class="literal">-metad</span></span><br><span class="line">    version: v3.<span class="number">5.0</span></span><br><span class="line">    dataVolumeClaim:</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: <span class="number">5</span><span class="built_in">Gi</span></span><br><span class="line">      storageClassName:  managed<span class="literal">-nfs-storage</span></span><br><span class="line">    logVolumeClaim:</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: <span class="number">1</span><span class="built_in">Gi</span></span><br><span class="line">      storageClassName:  managed<span class="literal">-nfs-storage</span></span><br><span class="line">  storaged:</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: <span class="string">&quot;500m&quot;</span></span><br><span class="line">        memory: <span class="string">&quot;500Mi&quot;</span></span><br><span class="line">      limits:</span><br><span class="line">        cpu: <span class="string">&quot;1&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>注意：所有的storageClassName需要和上面安装storageclass时名称相同。 即 storageclass-nfs.yml中的 <a href="http://metadata.name">metadata.name</a>: nfs-client</p></blockquote><ul><li><p>查看状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">nebula-exporter-66457984-w6zpn            1/1     Running   0          31m</span><br><span class="line">nebula-graphd-0                           2/2     Running   0          31m</span><br><span class="line">nebula-metad-0                            2/2     Running   0          35m</span><br><span class="line">nebula-storaged-0                         2/2     Running   0          35m</span><br><span class="line">nebula-storaged-1                         0/2     Pending   0          35m</span><br><span class="line">nebula-storaged-2                         0/2     Pending   0          35m</span><br><span class="line">nfs-client-provisioner-6bd7f48698-m4v94   1/1     Running   0          57m</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h2 id="十五，连接nebula">十五，连接nebula</h2><ul><li><p>按照官网提供的模板修改</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    # modify the cluster name</span><br><span class="line">    app.kubernetes.io/cluster: &quot;nebula&quot;</span><br><span class="line">    app.kubernetes.io/component: graphd</span><br><span class="line">    app.kubernetes.io/managed-by: nebula-operator</span><br><span class="line">    app.kubernetes.io/name: nebula-graph</span><br><span class="line">  name: nebula-graphd-nodeport-svc</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  externalTrafficPolicy: Cluster #改为local，无法连接到数据库，这里改为Cluster</span><br><span class="line">  ports:</span><br><span class="line">  - name: thrift</span><br><span class="line">    port: 9669</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9669</span><br><span class="line">  - name: http</span><br><span class="line">    port: 19669</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 19669</span><br><span class="line">  selector:</span><br><span class="line">    # modify the cluster name</span><br><span class="line">    app.kubernetes.io/cluster: &quot;nebula&quot;</span><br><span class="line">    app.kubernetes.io/component: graphd</span><br><span class="line">    app.kubernetes.io/managed-by: nebula-operator</span><br><span class="line">    app.kubernetes.io/name: nebula-graph</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure></li><li><p>执行以下命令使 Service 服务在集群中生效。</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f graphd-nodeport-service.yaml</span><br></pre></td></tr></table></figure><ul><li>查看 Service 中NebulaGraph映射至集群节点的端口。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get services -l app.kubernetes.io/cluster=&lt;nebula&gt;  #&lt;nebula&gt;为变量值，请用实际集群名称替换。</span><br></pre></td></tr></table></figure><ul><li>返回：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NAME                           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                                          AGE</span><br><span class="line">nebula-graphd-svc-nodeport     NodePort    10.107.153.129 &lt;none&gt;        9669:32236/TCP,19669:31674/TCP,19670:31057/TCP   24h</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><code>NodePort</code>类型的 Service 中，映射至集群节点的端口为<code>32236</code>。</p><ol><li><p>使用节点 IP 和上述映射的节点端口连接 NebulaGraph。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run -ti --image vesoft/nebula-console:v3.5.0 --restart=Never -- &lt;nebula_console_name&gt; -addr &lt;node_ip&gt; -port &lt;node_port&gt; -u &lt;username&gt; -p &lt;password&gt;</span><br></pre></td></tr></table></figure><p>示例如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl run -ti --image vesoft/nebula-console:v3.5.0 --restart=Never -- nebula-console -addr 192.168.8.24 -port 32236 -u root -p vesoft</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line"></span><br><span class="line">(root@nebula) [(none)]&gt;</span><br></pre></td></tr></table></figure><ul><li><code>--image</code>：为连接NebulaGraph的工具 NebulaGraph Console 的镜像。</li><li><code>&lt;nebula-console&gt;</code>：自定义的 Pod 名称。本示例为<code>nebula-console</code>。</li><li><code>-addr</code>：NebulaGraph集群中任一节点 IP 地址。本示例为<code>192.168.8.24</code>。</li><li><code>-port</code>：NebulaGraph映射至节点的端口。本示例为<code>32236</code>。</li><li><code>-u</code>：NebulaGraph账号的用户名。未启用身份认证时，可以使用任意已存在的用户名（默认为 root）。</li><li><code>-p</code>：用户名对应的密码。未启用身份认证时，密码可以填写任意字符。</li></ul></li></ol></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;k8s集群安装&amp;amp;nebulaGraph部署&lt;/h1&gt;
&lt;h2 id=&quot;一，集群环境准备&quot;&gt;一，集群环境准备&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;集群规划&lt;/p&gt;
&lt;figure class=&quot;highli</summary>
      
    
    
    
    <category term="数据库" scheme="https://0914ds.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>mysql执行计划</title>
    <link href="https://0914ds.github.io/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/"/>
    <id>https://0914ds.github.io/2023/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/</id>
    <published>2023-05-09T18:45:12.000Z</published>
    <updated>2023-06-22T07:13:57.276Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>mysql执行计划</h1><p>​       在企业的应用场景中，为了知道优化SQL语句的执行，需要查看SQL语句的具体执行过程，以加快SQL语句的执行效率。</p><p>​       可以使用explain+SQL语句来模拟优化器执行SQL查询语句，从而知道mysql是如何处理sql语句的。</p><p>​       官网地址： <a href="https://dev.mysql.com/doc/refman/5.5/en/explain-output.html">https://dev.mysql.com/doc/refman/5.5/en/explain-output.html</a></p><h3 id="1、执行计划中包含的信息">1、执行计划中包含的信息</h3><table><thead><tr><th style="text-align:center">Column</th><th style="text-align:center">Meaning</th></tr></thead><tbody><tr><td style="text-align:center">id</td><td style="text-align:center">The <code>SELECT</code> identifier</td></tr><tr><td style="text-align:center">select_type</td><td style="text-align:center">The <code>SELECT</code> type</td></tr><tr><td style="text-align:center">table</td><td style="text-align:center">The table for the output row</td></tr><tr><td style="text-align:center">partitions</td><td style="text-align:center">The matching partitions</td></tr><tr><td style="text-align:center">type</td><td style="text-align:center">The join type</td></tr><tr><td style="text-align:center">possible_keys</td><td style="text-align:center">The possible indexes to choose</td></tr><tr><td style="text-align:center">key</td><td style="text-align:center">The index actually chosen</td></tr><tr><td style="text-align:center">key_len</td><td style="text-align:center">The length of the chosen key</td></tr><tr><td style="text-align:center">ref</td><td style="text-align:center">The columns compared to the index</td></tr><tr><td style="text-align:center">rows</td><td style="text-align:center">Estimate of rows to be examined</td></tr><tr><td style="text-align:center">filtered</td><td style="text-align:center">Percentage of rows filtered by table condition</td></tr><tr><td style="text-align:center">extra</td><td style="text-align:center">Additional information</td></tr></tbody></table><p><strong>id</strong></p><p>select查询的序列号，包含一组数字，表示查询中执行select子句或者操作表的顺序</p><p>id号分为三种情况：</p><p>​        1、如果id相同，那么执行顺序从上到下</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp e <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno <span class="keyword">join</span> salgrade sg <span class="keyword">on</span> e.sal <span class="keyword">between</span> sg.losal <span class="keyword">and</span> sg.hisal;</span><br></pre></td></tr></table></figure><p>​        2、如果id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp e <span class="keyword">where</span> e.deptno <span class="keyword">in</span> (<span class="keyword">select</span> d.deptno <span class="keyword">from</span> dept d <span class="keyword">where</span> d.dname <span class="operator">=</span> <span class="string">&#x27;SALES&#x27;</span>);</span><br></pre></td></tr></table></figure><p>​        3、id相同和不同的，同时存在：相同的可以认为是一组，从上往下顺序执行，在所有组中，id值越大，优先级越高，越先执行</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp e <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno <span class="keyword">join</span> salgrade sg <span class="keyword">on</span> e.sal <span class="keyword">between</span> sg.losal <span class="keyword">and</span> sg.hisal <span class="keyword">where</span> e.deptno <span class="keyword">in</span> (<span class="keyword">select</span> d.deptno <span class="keyword">from</span> dept d <span class="keyword">where</span> d.dname <span class="operator">=</span> <span class="string">&#x27;SALES&#x27;</span>);</span><br></pre></td></tr></table></figure><p><strong>select_type</strong></p><p>主要用来分辨查询的类型，是普通查询还是联合查询还是子查询</p><table><thead><tr><th style="text-align:center"><code>select_type</code> Value</th><th style="text-align:center">Meaning</th></tr></thead><tbody><tr><td style="text-align:center">SIMPLE</td><td style="text-align:center">Simple SELECT (not using UNION or subqueries)</td></tr><tr><td style="text-align:center">PRIMARY</td><td style="text-align:center">Outermost SELECT</td></tr><tr><td style="text-align:center">UNION</td><td style="text-align:center">Second or later SELECT statement in a UNION</td></tr><tr><td style="text-align:center">DEPENDENT UNION</td><td style="text-align:center">Second or later SELECT statement in a UNION, dependent on outer query</td></tr><tr><td style="text-align:center">UNION RESULT</td><td style="text-align:center">Result of a UNION.</td></tr><tr><td style="text-align:center">SUBQUERY</td><td style="text-align:center">First SELECT in subquery</td></tr><tr><td style="text-align:center">DEPENDENT SUBQUERY</td><td style="text-align:center">First SELECT in subquery, dependent on outer query</td></tr><tr><td style="text-align:center">DERIVED</td><td style="text-align:center">Derived table</td></tr><tr><td style="text-align:center">UNCACHEABLE SUBQUERY</td><td style="text-align:center">A subquery for which the result cannot be cached and must be re-evaluated for each row of the outer query</td></tr><tr><td style="text-align:center">UNCACHEABLE UNION</td><td style="text-align:center">The second or later select in a UNION that belongs to an uncacheable subquery (see UNCACHEABLE SUBQUERY)</td></tr></tbody></table><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--sample:简单的查询，不包含子查询和union</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line"></span><br><span class="line"><span class="comment">--primary:查询中若包含任何复杂的子查询，最外层查询则被标记为Primary</span></span><br><span class="line">explain <span class="keyword">select</span> staname,ename supname <span class="keyword">from</span> (<span class="keyword">select</span> ename staname,mgr <span class="keyword">from</span> emp) t <span class="keyword">join</span> emp <span class="keyword">on</span> t.mgr<span class="operator">=</span>emp.empno ;</span><br><span class="line"></span><br><span class="line"><span class="comment">--union:若第二个select出现在union之后，则被标记为union</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> deptno <span class="operator">=</span> <span class="number">10</span> <span class="keyword">union</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="operator">&gt;</span><span class="number">2000</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--dependent union:跟union类似，此处的depentent表示union或union all联合而成的结果会受外部表影响</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp e <span class="keyword">where</span> e.empno  <span class="keyword">in</span> ( <span class="keyword">select</span> empno <span class="keyword">from</span> emp <span class="keyword">where</span> deptno <span class="operator">=</span> <span class="number">10</span> <span class="keyword">union</span> <span class="keyword">select</span> empno <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="operator">&gt;</span><span class="number">2000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">--union result:从union表获取结果的select</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> deptno <span class="operator">=</span> <span class="number">10</span> <span class="keyword">union</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="operator">&gt;</span><span class="number">2000</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--subquery:在select或者where列表中包含子查询</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="operator">&gt;</span> (<span class="keyword">select</span> <span class="built_in">avg</span>(sal) <span class="keyword">from</span> emp) ;</span><br><span class="line"></span><br><span class="line"><span class="comment">--dependent subquery:subquery的子查询要受到外部表查询的影响</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp e <span class="keyword">where</span> e.deptno <span class="keyword">in</span> (<span class="keyword">select</span> <span class="keyword">distinct</span> deptno <span class="keyword">from</span> dept);</span><br><span class="line"></span><br><span class="line"><span class="comment">--DERIVED: from子句中出现的子查询，也叫做派生类，</span></span><br><span class="line">explain <span class="keyword">select</span> staname,ename supname <span class="keyword">from</span> (<span class="keyword">select</span> ename staname,mgr <span class="keyword">from</span> emp) t <span class="keyword">join</span> emp <span class="keyword">on</span> t.mgr<span class="operator">=</span>emp.empno ;</span><br><span class="line"></span><br><span class="line"><span class="comment">--UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被缓存</span></span><br><span class="line"> explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> empno <span class="operator">=</span> (<span class="keyword">select</span> empno <span class="keyword">from</span> emp <span class="keyword">where</span> deptno<span class="operator">=</span>@<span class="variable">@sort_buffer_size</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">--uncacheable union:表示union的查询结果不能被缓存：sql语句未验证</span></span><br></pre></td></tr></table></figure><p><strong>table</strong></p><p>对应行正在访问哪一个表，表名或者别名，可能是临时表或者union合并结果集<br>1、如果是具体的表名，则表明从实际的物理表中获取数据，当然也可以是表的别名</p><p>​        2、表名是derivedN的形式，表示使用了id为N的查询产生的衍生表</p><p>​        3、当有union result的时候，表名是union n1,n2等的形式，n1,n2表示参与union的id</p><p><strong>type</strong></p><p>type显示的是访问类型，访问类型表示我是以何种方式去访问我们的数据，最容易想的是全表扫描，直接暴力的遍历一张表去寻找需要的数据，效率非常低下，访问的类型有很多，效率从最好到最坏依次是：</p><p>system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL</p><p>一般情况下，得保证查询至少达到range级别，最好能达到ref</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--all:全表扫描，一般情况下出现这样的sql语句而且数据量比较大的话那么就需要进行优化。</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line"></span><br><span class="line"><span class="comment">--index：全索引扫描这个比all的效率要好，主要有两种情况，一种是当前的查询时覆盖索引，即我们需要的数据在索引中就可以索取，或者是使用了索引进行排序，这样就避免数据的重排序</span></span><br><span class="line">explain  <span class="keyword">select</span> empno <span class="keyword">from</span> emp;</span><br><span class="line"></span><br><span class="line"><span class="comment">--range：表示利用索引查询的时候限制了范围，在指定范围内进行查询，这样避免了index的全索引扫描，适用的操作符： =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, BETWEEN, LIKE, or IN() </span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> empno <span class="keyword">between</span> <span class="number">7000</span> <span class="keyword">and</span> <span class="number">7500</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--index_subquery：利用索引来关联子查询，不再扫描全表</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> emp.job <span class="keyword">in</span> (<span class="keyword">select</span> job <span class="keyword">from</span> t_job);</span><br><span class="line"></span><br><span class="line"><span class="comment">--unique_subquery:该连接类型类似与index_subquery,使用的是唯一索引</span></span><br><span class="line"> explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp e <span class="keyword">where</span> e.deptno <span class="keyword">in</span> (<span class="keyword">select</span> <span class="keyword">distinct</span> deptno <span class="keyword">from</span> dept);</span><br><span class="line"></span><br><span class="line"><span class="comment">--index_merge：在查询过程中需要多个索引组合使用，没有模拟出来</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--ref_or_null：对于某个字段即需要关联条件，也需要null值的情况下，查询优化器会选择这种访问方式</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp e <span class="keyword">where</span>  e.mgr <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">or</span> e.mgr<span class="operator">=</span><span class="number">7369</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--ref：使用了非唯一性索引进行数据的查找</span></span><br><span class="line"> <span class="keyword">create</span> index idx_3 <span class="keyword">on</span> emp(deptno);</span><br><span class="line"> explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp e,dept d <span class="keyword">where</span> e.deptno <span class="operator">=</span>d.deptno;</span><br><span class="line"></span><br><span class="line"><span class="comment">--eq_ref ：使用唯一性索引进行数据查找</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp,emp2 <span class="keyword">where</span> emp.empno <span class="operator">=</span> emp2.empno;</span><br><span class="line"></span><br><span class="line"><span class="comment">--const：这个表至多有一个匹配行，</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> empno <span class="operator">=</span> <span class="number">7369</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现</span></span><br></pre></td></tr></table></figure><p><strong>possible_keys</strong></p><p>​        显示可能应用在这张表中的索引，一个或多个，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp,dept <span class="keyword">where</span> emp.deptno <span class="operator">=</span> dept.deptno <span class="keyword">and</span> emp.deptno <span class="operator">=</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure><p><strong>key</strong></p><p>​        实际使用的索引，如果为null，则没有使用索引，查询中若使用了覆盖索引，则该索引和查询的select字段重叠。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp,dept <span class="keyword">where</span> emp.deptno <span class="operator">=</span> dept.deptno <span class="keyword">and</span> emp.deptno <span class="operator">=</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure><p><strong>key_len</strong></p><p>表示索引中使用的字节数，可以通过key_len计算查询中使用的索引长度，在不损失精度的情况下长度越短越好。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp,dept <span class="keyword">where</span> emp.deptno <span class="operator">=</span> dept.deptno <span class="keyword">and</span> emp.deptno <span class="operator">=</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure><p><strong>ref</strong></p><p>显示索引的哪一列被使用了，如果可能的话，是一个常数</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp,dept <span class="keyword">where</span> emp.deptno <span class="operator">=</span> dept.deptno <span class="keyword">and</span> emp.deptno <span class="operator">=</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure><p><strong>rows</strong></p><p>根据表的统计信息及索引使用情况，大致估算出找出所需记录需要读取的行数，此参数很重要，直接反应的sql找了多少数据，在完成目的的情况下越少越好</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure><p><strong>extra</strong></p><p>包含额外的信息。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--using filesort:说明mysql无法利用索引进行排序，只能利用排序算法进行排序，会消耗额外的位置</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> sal;</span><br><span class="line"></span><br><span class="line"><span class="comment">--using temporary:建立临时表来保存中间结果，查询完成之后把临时表删除</span></span><br><span class="line">explain <span class="keyword">select</span> ename,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> emp <span class="keyword">where</span> deptno <span class="operator">=</span> <span class="number">10</span> <span class="keyword">group</span> <span class="keyword">by</span> ename;</span><br><span class="line"></span><br><span class="line"><span class="comment">--using index:这个表示当前的查询时覆盖索引的，直接从索引中读取数据，而不用访问数据表。如果同时出现using where 表名索引被用来执行索引键值的查找，如果没有，表面索引被用来读取数据，而不是真的查找</span></span><br><span class="line">explain <span class="keyword">select</span> deptno,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno limit <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--using where:使用where进行条件过滤</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_user <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--using join buffer:使用连接缓存，情况没有模拟出来</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--impossible where：where语句的结果总是false</span></span><br><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> empno <span class="operator">=</span> <span class="number">7469</span>;</span><br></pre></td></tr></table></figure></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;mysql执行计划&lt;/h1&gt;
&lt;p&gt;​       在企业的应用场景中，为了知道优化SQL语句的执行，需要查看SQL语句的具体执行过程，以加快SQL语句的执行效率。&lt;/p&gt;
&lt;p&gt;​       可以使用expl</summary>
      
    
    
    
    <category term="数据库" scheme="https://0914ds.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>jvm系列(二):JVM内存结构</title>
    <link href="https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/"/>
    <id>https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/</id>
    <published>2022-03-10T18:45:12.000Z</published>
    <updated>2023-07-02T05:39:09.152Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>jvm系列(二):JVM内存结构</h1><p>所有的Java开发人员可能会遇到这样的困惑？我该为堆内存设置多大空间呢？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域？该怎么解决呢？其实如果你经常解决服务器性能问题，那么这些问题就会变的非常常见，了解JVM内存也是为了服务器出现性能问题的时候可以快速的了解那块的内存区域出现问题，以便于快速的解决生产故障。</p><p>先看一张图，这张图能很清晰的说明JVM内存结构布局。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122127.png" title="微信截图_20230702122127" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122127.png" alt="微信截图_20230702122127"></a></p><p>JVM内存结构主要有三大块：<strong>堆内存</strong>、<strong>方法区</strong>和<strong>栈</strong>。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，<strong>Eden空间</strong>、<strong>From Survivor空间</strong>、<strong>To Survivor空间</strong>,默认情况下年轻代按照<strong>8:1:1</strong>的比例来分配；</p><p>方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。</p><p>在通过一张图来了解如何通过参数来控制各区域的内存大小</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122241.png" title="微信截图_20230702122241" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122241.png" alt="微信截图_20230702122241"></a></p><p>控制参数</p><ul><li>-Xms设置堆的最小空间大小。</li><li>-Xmx设置堆的最大空间大小。</li><li>-XX:NewSize设置新生代最小空间大小。</li><li>-XX:MaxNewSize设置新生代最大空间大小。</li><li>-XX:PermSize设置永久代最小空间大小。</li><li>-XX:MaxPermSize设置永久代最大空间大小。</li><li>-Xss设置每个线程的堆栈大小。</li></ul><p>没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。</p><blockquote><p>老年代空间大小=堆空间大小-年轻代大空间大小</p></blockquote><p>从更高的一个维度再次来看JVM和系统调用之间的关系</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122343.png" title="微信截图_20230702122343" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122343.png" alt="微信截图_20230702122343"></a></p><p>方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。</p><p>下面我们详细介绍每个区域的作用</p><h2 id="Java堆（Heap）">Java堆（Heap）</h2><p>对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中<strong>最大</strong>的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，<strong>几乎所有的对象实例都在这里分配内存</strong>。</p><p>Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“<strong>GC堆</strong>”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：<strong>新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。</strong></p><p>根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。</p><p>如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。</p><h2 id="方法区（Method-Area）">方法区（Method Area）</h2><p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，**它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。**虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。</p><p>对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。</p><p>Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。</p><p>根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。</p><p>方法区有时被称为持久代（PermGen）。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122437.png" title="微信截图_20230702122437" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122437.png" alt="微信截图_20230702122437"></a></p><p>所有的对象在实例化后的整个运行周期内，都被存放在堆内存中。堆内存又被划分成不同的部分：伊甸区(Eden)，幸存者区域(Survivor Sapce)，老年代（Old Generation Space）。</p><p>方法的执行都是伴随着线程的。原始类型的本地变量以及引用都存放在线程栈中。而引用关联的对象比如String，都存在在堆中。为了更好的理解上面这段话，我们可以看一个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import java.text.SimpleDateFormat;import java.util.Date;import org.apache.log4j.Logger;public class HelloWorld &#123;    private static Logger LOGGER = Logger.getLogger(HelloWorld.class.getName());    public void sayHello(String message) &#123;        SimpleDateFormat formatter = new SimpleDateFormat(&quot;dd.MM.YYYY&quot;);        String today = formatter.format(new Date());        LOGGER.info(today + &quot;: &quot; + message);    &#125;&#125;</span><br></pre></td></tr></table></figure><p>这段程序的数据在内存中的存放如下：</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122529.png" title="微信截图_20230702122529" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122529.png" alt="微信截图_20230702122529"></a></p><p>通过JConsole工具可以查看运行中的Java程序（比如Eclipse）的一些信息：堆内存的分配，线程的数量以及加载的类的个数</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122635.png" title="微信截图_20230702122635" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702122635.png" alt="微信截图_20230702122635"></a></p><h2 id="程序计数器（Program-Counter-Register）">程序计数器（Program Counter Register）</h2><p>程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p><p>由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。</p><p>如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。</p><p><strong>此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。</strong></p><h2 id="JVM栈（JVM-Stacks）">JVM栈（JVM Stacks）</h2><p>与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，**它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：**每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。<strong>每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</strong></p><p>局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。</p><p>其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</p><p>在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。</p><h2 id="本地方法栈（Native-Method-Stacks）">本地方法栈（Native Method Stacks）</h2><p>本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而**本地方法栈则是为虚拟机使用到的Native方法服务。**虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。</p><h2 id="哪儿的OutOfMemoryError">哪儿的OutOfMemoryError</h2><p>对内存结构清晰的认识同样可以帮助理解不同OutOfMemoryErrors：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space</span><br></pre></td></tr></table></figure><p>原因：对象不能被分配到堆内存中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space</span><br></pre></td></tr></table></figure><p>原因：类或者方法不能被加载到老年代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit</span><br></pre></td></tr></table></figure><p>原因：创建的数组大于堆内存的空间</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: request &lt;size&gt; bytes for &lt;reason&gt;. Out of swap space?</span><br></pre></td></tr></table></figure><p>原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main”: java.lang.OutOfMemoryError: &lt;reason&gt; &lt;stack trace&gt;（Native method）</span><br></pre></td></tr></table></figure><p>原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者Java虚拟机发现</p><h2 id="维基百科对JVM的介绍">维基百科对JVM的介绍</h2><p>Overview of a Java virtual machine (JVM) architecture based on The Java Virtual Machine Specification Java SE 7 Edition</p><p>A <strong>Java virtual machine</strong> (<strong>JVM</strong>) is an abstract computing machine that enables a computer to run a Java program. There are three notions of the JVM: specification, implementation, and instance. The specification is a document that formally describes what is required of a JVM implementation. Having a single specification ensures all implementations are interoperable. A JVM implementation is a computer program that meets the requirements of the JVM specification. An instance of a JVM is an implementation running in a process that executes a computer program compiled into Java bytecode.</p><p><strong>Java Runtime Environment</strong> (<strong>JRE</strong>) is a software package that contains what is required to run a Java program. It includes a Java Virtual Machine implementation together with an implementation of the Java Class Library. The Oracle Corporation, which owns the Java trademark, distributes a Java Runtime environment with their Java Virtual Machine called HotSpot.</p><p><strong>Java Development Kit</strong> (<strong>JDK</strong>) is a superset of a JRE and contains tools for Java programmers, e.g. a javaccompiler. The Java Development Kit is provided free of charge either by Oracle Corporation directly, or by the OpenJDK open source project, which is governed by Oracle.</p></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;jvm系列(二):JVM内存结构&lt;/h1&gt;
&lt;p&gt;所有的Java开发人员可能会遇到这样的困惑？我该为堆内存设置多大空间呢？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域？该怎么解决呢？其实如</summary>
      
    
    
    
    <category term="JVM调优合集" scheme="https://0914ds.github.io/categories/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/"/>
    
    
  </entry>
  
  <entry>
    <title>jvm系列(五):Java GC 分析</title>
    <link href="https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90/"/>
    <id>https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90/</id>
    <published>2022-03-10T18:45:12.000Z</published>
    <updated>2023-07-02T05:37:26.737Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>jvm系列(五):Java GC 分析</h1><p>Java GC就是JVM记录仪，书画了JVM各个分区的表演</p><h2 id="什么是-Java-GC">什么是 Java GC</h2><p>Java GC（Garbage Collection，垃圾收集，垃圾回收）机制，是Java与C++/C的主要区别之一，作为Java开发者，一般不需要专门编写内存回收和垃圾清理代码，对内存泄露和溢出的问题，也不需要像C程序员那样战战兢兢。这是因为在Java虚拟机中，存在自动内存管理和垃圾清扫机制。概括地说，该机制对JVM（Java Virtual Machine）中的内存进行标记，并确定哪些内存需要回收，根据一定的回收策略，自动的回收内存，永不停息（Nerver Stop）的保证JVM中的内存空间，防止出现内存泄露和溢出问题。</p><p>在Java语言出现之前，就有GC机制的存在，如Lisp语言），Java GC机制已经日臻完善，几乎可以自动的为我们做绝大多数的事情。然而，如果我们从事较大型的应用软件开发，曾经出现过内存优化的需求，就必定要研究Java GC机制。</p><p>简单总结一下，Java GC就是通过GC收集器回收不在存活的对象，保证JVM更加高效的运转。如果不了解GC算法和垃圾回收器可以参考这篇文章：<a href="http://mp.weixin.qq.com/s?__biz=MzI4NDY5Mjc1Mg==&amp;mid=2247483952&amp;idx=1&amp;sn=ea12792a9b7c67baddfaf425d8272d33&amp;chksm=ebf6da4fdc815359869107a4acd15538b3596ba006b4005b216688b69372650dbd18c0184643&amp;scene=21#wechat_redirect">jvm系列(三):GC算法 垃圾收集器。</a></p><h2 id="如何获取-Java-GC日志">如何获取 Java GC日志</h2><p>一般情况可以通过两种方式来获取GC日志，一种是使用命令动态查看，一种是在容器中设置相关参数打印GC日志。</p><h3 id="命令动态查看">命令动态查看</h3><p>Java 自动的工具行命令，jstat可以用来动态监控JVM内存的使用，统计垃圾回收的各项信息。</p><p>比如常用命令， <code>jstat-gc</code> 统计垃圾回收堆的行为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gc 1262 S0C    S1C     S0U     S1U   EC       EU        OC         OU        PC       PU         YGC    YGCT    FGC    FGCT     GCT   26112.0 24064.0 6562.5  0.0   564224.0 76274.5   434176.0   388518.3  524288.0 42724.7    320    6.417   1      0.398    6.815</span><br></pre></td></tr></table></figure><p>也可以设置间隔固定时间来打印：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gc 1262 2000 20</span><br></pre></td></tr></table></figure><p>这个命令意思就是每隔2000ms输出1262的gc情况，一共输出20次</p><p>更详细的内容参考这篇文章：<a href="http://mp.weixin.qq.com/s?__biz=MzI4NDY5Mjc1Mg==&amp;mid=2247483966&amp;idx=1&amp;sn=dfa3375d36aa2c0c25a775522e381e62&amp;chksm=ebf6da41dc815357e0d53c73865a23f41219e75bac5a4d510bfa31cc51594b59a20e2e4f6cb8&amp;scene=21#wechat_redirect">jvm系列(四):jvm调优-命令篇</a></p><h3 id="GC参数">GC参数</h3><p>JVM的GC日志的主要参数包括如下几个：</p><ul><li><code>-XX:+PrintGC</code> 输出GC日志</li><li><code>-XX:+PrintGCDetails</code> 输出GC的详细日志</li><li><code>-XX:+PrintGCTimeStamps</code> 输出GC的时间戳（以基准时间的形式）</li><li><code>-XX:+PrintGCDateStamps</code> 输出GC的时间戳（以日期的形式，如 2017-09-04T21:53:59.234+0800）</li><li><code>-XX:+PrintHeapAtGC</code> 在进行GC的前后打印出堆的信息</li><li><code>-Xloggc:../logs/gc.log</code> 日志文件的输出路径</li></ul><p>在生产环境中，根据需要配置相应的参数来监控JVM运行情况。</p><h3 id="Tomcat-设置示例">Tomcat 设置示例</h3><p>我们经常在tomcat的启动参数中添加JVM相关参数，这里有一个典型的示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-server -Xms2000m -Xmx2000m -Xmn800m -XX:PermSize=64m -XX:MaxPermSize=256m -XX:SurvivorRatio=4-verbose:gc -Xloggc:$CATALINA_HOME/logs/gc.log -Djava.awt.headless=true -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Dsun.rmi.dgc.server.gcInterval=600000 -Dsun.rmi.dgc.client.gcInterval=600000-XX:+UseConcMarkSweepGC -XX:MaxTenuringThreshold=15&quot;</span><br></pre></td></tr></table></figure><p>根据上面的参数我们来做一下解析：</p><p><code>-Xms2000m-Xmx2000m-Xmn800m-XX:PermSize=64m-XX:MaxPermSize=256m</code><br>Xms，即为jvm启动时得JVM初始堆大小,Xmx为jvm的最大堆大小，xmn为新生代的大小，permsize为永久代的初始大小，MaxPermSize为永久代的最大空间。</p><p><code>-XX:SurvivorRatio=4</code><br>SurvivorRatio为新生代空间中的Eden区和救助空间Survivor区的大小比值，默认是32，也就是说Eden区是 Survivor区的32倍大小，要注意Survivo是有两个区的，因此Surivivor其实占整个young genertation的1/34。调小这个参数将增大survivor区，让对象尽量在survitor区呆长一点，减少进入年老代的对象。去掉救助空间的想法是让大部分不能马上回收的数据尽快进入年老代，加快年老代的回收频率，减少年老代暴涨的可能性，这个是通过将-XX:SurvivorRatio 设置成比较大的值（比如65536)来做到。</p><p><code>-verbose:gc-Xloggc:$CATALINA_HOME/logs/gc.log</code><br>将虚拟机每次垃圾回收的信息写到日志文件中，文件名由file指定，文件格式是平文件，内容和-verbose:gc输出内容相同。</p><p><code>-Djava.awt.headless=true</code> Headless模式是系统的一种配置模式。在该模式下，系统缺少了显示设备、键盘或鼠标。</p><p><code>-XX:+PrintGCTimeStamps-XX:+PrintGCDetails</code><br>设置gc日志的格式</p><p><code>-Dsun.rmi.dgc.server.gcInterval=600000-Dsun.rmi.dgc.client.gcInterval=600000</code><br>指定rmi调用时gc的时间间隔</p><p><code>-XX:+UseConcMarkSweepGC-XX:MaxTenuringThreshold=15</code> 采用并发gc方式，经过15次minor gc 后进入年老代</p><h2 id="如何分析GC日志">如何分析GC日志</h2><p>摘录GC日志一部分</p><p>Young GC回收日志:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2016-07-05T10:43:18.093+0800: 25.395: [GC [PSYoungGen: 274931K-&gt;10738K(274944K)] 371093K-&gt;147186K(450048K), 0.0668480 secs] [Times: user=0.17 sys=0.08, real=0.07 secs]</span><br></pre></td></tr></table></figure><p>Full GC回收日志:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2016-07-05T10:43:18.160+0800: 25.462: [Full GC [PSYoungGen: 10738K-&gt;0K(274944K)] [ParOldGen: 136447K-&gt;140379K(302592K)] 147186K-&gt;140379K(577536K) [PSPermGen: 85411K-&gt;85376K(171008K)], 0.6763541 secs] [Times: user=1.75 sys=0.02, real=0.68 secs]</span><br></pre></td></tr></table></figure><p>通过上面日志分析得出，PSYoungGen、ParOldGen、PSPermGen属于Parallel收集器。其中PSYoungGen表示gc回收前后年轻代的内存变化；ParOldGen表示gc回收前后老年代的内存变化；PSPermGen表示gc回收前后永久区的内存变化。young gc 主要是针对年轻代进行内存回收比较频繁，耗时短；full gc 会对整个堆内存进行回城，耗时长，因此一般尽量减少full gc的次数</p><p>通过两张图非常明显看出gc日志构成：</p><p>Young GC日志:</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702125921.png" title="微信截图_20230702125921" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702125921.png" alt="微信截图_20230702125921"></a></p><p>Full GC日志:</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130000.png" title="微信截图_20230702130000" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130000.png" alt="微信截图_20230702130000"></a></p><h2 id="GC分析工具">GC分析工具</h2><h3 id="GChisto">GChisto</h3><p>GChisto是一款专业分析gc日志的工具，可以通过gc日志来分析：Minor GC、full gc的时间、频率等等，通过列表、报表、图表等不同的形式来反应gc的情况。虽然界面略显粗糙，但是功能还是不错的。</p><p>配置好本地的jdk环境之后，双击GChisto.jar,在弹出的输入框中点击 add 选择gc.log日志</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130036.png" title="微信截图_20230702130036" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130036.png" alt="微信截图_20230702130036"></a></p><p>GC Pause Stats:可以查看GC 的次数、GC的时间、GC的开销、最大GC时间和最小GC时间等，以及相应的柱状图</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130112.png" title="微信截图_20230702130112" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130112.png" alt="微信截图_20230702130112"></a></p><p>GC Pause Distribution:查看GC停顿的详细分布，x轴表示垃圾收集停顿时间，y轴表示是停顿次数。</p><p>GC Timeline：显示整个时间线上的垃圾收集</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130156.png" title="微信截图_20230702130156" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130156.png" alt="微信截图_20230702130156"></a></p><p>不过这款工具已经不再维护</p><h3 id="GC-Easy">GC Easy</h3><p>这是一个web工具,在线使用非常方便.</p><p>地址: <a href="http://gceasy.io">http://gceasy.io</a></p><p>进入官网，讲打包好的zip或者gz为后缀的压缩包上传，过一会就会拿到分析结果。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130237.png" title="微信截图_20230702130237" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130237.png" alt="微信截图_20230702130237"></a></p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130259.png" title="微信截图_20230702130259" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130259.png" alt="微信截图_20230702130259"></a></p><p>推荐使用此工具进行gc分析。</p></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;jvm系列(五):Java GC 分析&lt;/h1&gt;
&lt;p&gt;Java GC就是JVM记录仪，书画了JVM各个分区的表演&lt;/p&gt;
&lt;h2 id=&quot;什么是-Java-GC&quot;&gt;什么是 Java GC&lt;/h2&gt;
&lt;p&gt;Jav</summary>
      
    
    
    
    <category term="JVM调优合集" scheme="https://0914ds.github.io/categories/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/"/>
    
    
  </entry>
  
  <entry>
    <title>jvm系列(三):GC算法 垃圾收集器</title>
    <link href="https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/"/>
    <id>https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/</id>
    <published>2022-03-10T18:45:12.000Z</published>
    <updated>2023-07-02T05:38:22.717Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>jvm系列(三):GC算法 垃圾收集器</h1><h2 id="概述">概述</h2><p>垃圾收集 Garbage Collection 通常被称为“GC”，它诞生于1960年 MIT 的 Lisp 语言，经过半个多世纪，目前已经十分成熟了。 jvm 中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈帧随着方法的进入和退出做入栈和出栈操作，实现了自动的内存清理，因此，我们的内存垃圾回收主要集中于 java 堆和方法区中，在程序运行期间，这部分内存的分配和使用都是动态的.</p><h2 id="对象存活判断">对象存活判断</h2><p>判断对象是否存活一般有两种方式：</p><p><strong>引用计数</strong>：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。<br><strong>可达性分析</strong>（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。不可达对象。</p><p>在Java语言中，GC Roots包括：</p><ul><li>虚拟机栈中引用的对象。</li><li>方法区中类静态属性实体引用的对象。</li><li>方法区中常量引用的对象。</li><li>本地方法栈中JNI引用的对象。</li></ul><h2 id="垃圾收集算法">垃圾收集算法</h2><h3 id="标记-清除算法">标记 -清除算法</h3><p>“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。</p><p>它的主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123629.png" title="微信截图_20230702123629" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123629.png" alt="微信截图_20230702123629"></a></p><h3 id="复制算法">复制算法</h3><p>“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。</p><p>这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为原来的一半，持续复制长生存期的对象则导致效率降低。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123740.png" title="微信截图_20230702123740" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123740.png" alt="微信截图_20230702123740"></a></p><h3 id="标记-压缩算法">标记-压缩算法</h3><p>复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。</p><p>根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123823.png" title="微信截图_20230702123823" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123823.png" alt="微信截图_20230702123823"></a></p><h3 id="分代收集算法">分代收集算法</h3><p>GC分代的基本假设：绝大部分对象的生命周期都非常短暂，存活时间短。</p><p>“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。</p><h2 id="垃圾收集器">垃圾收集器</h2><blockquote><p>如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现</p></blockquote><h3 id="Serial收集器">Serial收集器</h3><p>串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。新生代、老年代使用串行回收；新生代复制算法、老年代标记-压缩；垃圾收集的过程中会Stop The World（服务暂停）</p><p>参数控制： <code>-XX:+UseSerialGC</code> 串行收集器</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123859.png" title="微信截图_20230702123859" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123859.png" alt="微信截图_20230702123859"></a></p><p>ParNew收集器 ParNew收集器其实就是Serial收集器的多线程版本。新生代并行，老年代串行；新生代复制算法、老年代标记-压缩</p><p>参数控制：</p><p><code>-XX:+UseParNewGC</code> ParNew收集器<br><code>-XX:ParallelGCThreads</code> 限制线程数量</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123937.png" title="微信截图_20230702123937" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702123937.png" alt="微信截图_20230702123937"></a></p><h3 id="Parallel收集器">Parallel收集器</h3><p>Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩</p><p>参数控制： <code>-XX:+UseParallelGC</code> 使用Parallel收集器+ 老年代串行</p><h3 id="Parallel-Old-收集器">Parallel Old 收集器</h3><p>Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。这个收集器是在JDK 1.6中才开始提供</p><p>参数控制： <code>-XX:+UseParallelOldGC</code> 使用Parallel收集器+ 老年代并行</p><h3 id="CMS收集器">CMS收集器</h3><p>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。</p><p>从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括：</p><ul><li>初始标记（CMS initial mark）</li><li>并发标记（CMS concurrent mark）</li><li>重新标记（CMS remark）</li><li>并发清除（CMS concurrent sweep）</li></ul><p>其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。</p><p>由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。老年代收集器（新生代使用ParNew）</p><p><strong>优点</strong>: 并发收集、低停顿<br><strong>缺点</strong>: 产生大量空间碎片、并发阶段会降低吞吐量</p><p>参数控制：</p><p><code>-XX:+UseConcMarkSweepGC</code> 使用CMS收集器<br><code>-XX:+ UseCMSCompactAtFullCollection</code> Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长<br><code>-XX:+CMSFullGCsBeforeCompaction</code> 设置进行几次Full GC后，进行一次碎片整理<br><code>-XX:ParallelCMSThreads</code> 设定CMS的线程数量（一般情况约等于可用CPU数量）</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124017.png" title="微信截图_20230702124017" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124017.png" alt="微信截图_20230702124017"></a></p><h3 id="G1收集器">G1收集器</h3><p>G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。与CMS收集器相比G1收集器有以下特点：</p><ol><li><strong>空间整合</strong>，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。</li><li><strong>可预测停顿</strong>，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。</li></ol><p>上面提到的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124101.png" title="微信截图_20230702124101" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124101.png" alt="微信截图_20230702124101"></a></p><p>G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。和CMS类似，G1收集器收集老年代对象会有短暂停顿。</p><p>收集步骤：</p><p>1、标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark)</p><p>2、Root Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。</p><p>3、Concurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124135.png" title="微信截图_20230702124135" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124135.png" alt="微信截图_20230702124135"></a></p><p>4、Remark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。</p><p>5、Copy/Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124210.png" title="微信截图_20230702124210" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124210.png" alt="微信截图_20230702124210"></a></p><p>6、复制/清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124248.png" title="微信截图_20230702124248" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702124248.png" alt="微信截图_20230702124248"></a></p><h2 id="常用的收集器组合">常用的收集器组合</h2><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">新生代GC策略</th><th style="text-align:left">老年老代GC策略</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">组合1</td><td style="text-align:left">Serial</td><td style="text-align:left">Serial Old</td><td style="text-align:left">Serial和Serial Old都是单线程进行GC，特点就是GC时暂停所有应用线程。</td></tr><tr><td style="text-align:left">组合2</td><td style="text-align:left">Serial</td><td style="text-align:left">CMS+Serial Old</td><td style="text-align:left">CMS（Concurrent Mark Sweep）是并发GC，实现GC线程和应用线程并发工作，不需要暂停所有应用线程。另外，当CMS进行GC失败时，会自动使用Serial Old策略进行GC。</td></tr><tr><td style="text-align:left">组合3</td><td style="text-align:left">ParNew</td><td style="text-align:left">CMS</td><td style="text-align:left">使用 <code>-XX:+UseParNewGC</code>选项来开启。ParNew是Serial的并行版本，可以指定GC线程数，默认GC线程数为CPU的数量。可以使用-XX:ParallelGCThreads选项指定GC的线程数。如果指定了选项 <code>-XX:+UseConcMarkSweepGC</code>选项，则新生代默认使用ParNew GC策略。</td></tr><tr><td style="text-align:left">组合4</td><td style="text-align:left">ParNew</td><td style="text-align:left">Serial Old</td><td style="text-align:left">使用 <code>-XX:+UseParNewGC</code>选项来开启。新生代使用ParNew GC策略，年老代默认使用Serial Old GC策略。</td></tr><tr><td style="text-align:left">组合5</td><td style="text-align:left">Parallel Scavenge</td><td style="text-align:left">Serial Old</td><td style="text-align:left">Parallel Scavenge策略主要是关注一个可控的吞吐量：应用程序运行时间 / (应用程序运行时间 + GC时间)，可见这会使得CPU的利用率尽可能的高，适用于后台持久运行的应用程序，而不适用于交互较多的应用程序。</td></tr><tr><td style="text-align:left">组合6</td><td style="text-align:left">Parallel Scavenge</td><td style="text-align:left">Parallel Old</td><td style="text-align:left">Parallel Old是Serial Old的并行版本</td></tr><tr><td style="text-align:left">组合7</td><td style="text-align:left">G1GC</td><td style="text-align:left">G1GC</td><td style="text-align:left"><code>-XX:+UnlockExperimentalVMOptions</code> <code>-XX:+UseG1GC</code> #开启； <code>-XX:MaxGCPauseMillis=50</code> #暂停时间目标； <code>-XX:GCPauseIntervalMillis=200</code> #暂停间隔目标； <code>-XX:+G1YoungGenSize=512m</code> #年轻代大小； <code>-XX:SurvivorRatio=6</code> #幸存区比例</td></tr></tbody></table></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;jvm系列(三):GC算法 垃圾收集器&lt;/h1&gt;
&lt;h2 id=&quot;概述&quot;&gt;概述&lt;/h2&gt;
&lt;p&gt;垃圾收集 Garbage Collection 通常被称为“GC”，它诞生于1960年 MIT 的 Lisp 语言，</summary>
      
    
    
    
    <category term="JVM调优合集" scheme="https://0914ds.github.io/categories/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/"/>
    
    
  </entry>
  
  <entry>
    <title>jvm系列(六):jvm调优-工具篇</title>
    <link href="https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87/"/>
    <id>https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87/</id>
    <published>2022-03-10T18:45:12.000Z</published>
    <updated>2023-07-02T05:38:42.932Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>jvm系列(六):jvm调优-工具篇</h1><p>16年的时候花了一些时间整理了一些关于jvm的介绍文章,到现在回顾起来还是一些还没有补充全面，其中就包括如何利用工具来监控调优前后的性能变化。工具做为图形化界面来展示更能直观的发现问题，另一方面一些耗费性能的分析（dump文件分析）一般也不会在生产直接分析，往往dump下来的文件达1G左右，人工分析效率较低，因此利用工具来分析jvm相关问题，长长可以到达事半功倍的效果来。</p><p>jvm监控分析工具一般分为两类，一种是jdk自带的工具，一种是第三方的分析工具。jdk自带工具一般在jdk bin目录下面，以exe的形式直接点击就可以使用，其中包含分析工具已经很强大，几乎涉及了方方面面，但是我们最常使用的只有两款：jconsole.exe和jvisualvm.exe；第三方的分析工具有很多，各自的侧重点不同，比较有代表性的：MAT(Memory Analyzer Tool)、GChisto等。</p><p>对于大型 JAVA 应用程序来说，再精细的测试也难以堵住所有的漏洞，即便我们在测试阶段进行了大量卓有成效的工作，很多问题还是会在生产环境下暴露出来，并且很难在测试环境中进行重现。JVM 能够记录下问题发生时系统的部分运行状态，并将其存储在堆转储 (Heap Dump) 文件中，从而为我们分析和诊断问题提供了重要的依据。其中VisualVM和MAT是dump文件的分析利器。</p><h2 id="jdk自带的工具">jdk自带的工具</h2><h3 id="jconsole">jconsole</h3><p>Jconsole（Java Monitoring and Management Console）是从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控，是一个基于JMX（java management extensions）的GUI性能监测工具。jconsole使用jvm的扩展机制获取并展示虚拟机中运行的应用程序的性能和资源消耗等信息。</p><p>直接在jdk/bin目录下点击jconsole.exe即可启动，界面如下:</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131022.png" title="微信截图_20230702131022" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131022.png" alt="微信截图_20230702131022"></a></p><p>在弹出的框中可以选择本机的监控本机的java应用，也可以选择远程的java服务来监控，如果监控远程服务需要在tomcat启动脚本中添加如下代码：</p><blockquote><p>-Dcom.sun.management.jmxremote.port=6969</p><p>-Dcom.sun.management.jmxremote.ssl=false</p><p>-Dcom.sun.management.jmxremote.authenticate=false</p></blockquote><p>连接进去之后，就可以看到jconsole概览图和主要的功能：概述、内存、线程、类、VM、MBeans</p><ul><li>概述，以图表的方式显示出堆内存使用量，活动线程数，已加载的类，CUP占用率的折线图，可以非常清晰的观察在程序执行过程中的变动情况。</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131109.png" title="微信截图_20230702131109" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131109.png" alt="微信截图_20230702131109"></a></p><ul><li>内存，主要展示了内存的使用情况，同时可以查看堆和非堆内存的变化值对比，也可以点击执行GC来处罚GC的执行</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131138.png" title="微信截图_20230702131138" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131138.png" alt="微信截图_20230702131138"></a></p><ul><li>线程，主界面展示线程数的活动数和峰值，同时点击左下方线程可以查看线程的详细信息，比如线程的状态是什么，堆栈内容等，同时也可以点击“检测死锁”来检查线程之间是否有死锁的情况。</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131215.png" title="微信截图_20230702131215" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131215.png" alt="微信截图_20230702131215"></a></p><ul><li>类，主要展示已加载类的相关信息。</li><li>VM 概要，展示JVM所有信息总览，包括基本信息、线程相关、堆相关、操作系统、VM参数等。</li><li>Mbean,查看Mbean的属性，方法等。</li></ul><h3 id="VisualVM">VisualVM</h3><p><strong>简介</strong></p><p>VisualVM 是一个工具，它提供了一个可视界面，用于查看 Java 虚拟机 (Java Virtual Machine, JVM) 上运行的基于 Java 技术的应用程序（Java 应用程序）的详细信息。VisualVM 对 Java Development Kit (JDK) 工具所检索的 JVM 软件相关数据进行组织，并通过一种使您可以快速查看有关多个 Java 应用程序的数据的方式提供该信息。您可以查看本地应用程序以及远程主机上运行的应用程序的相关数据。此外，还可以捕获有关 JVM 软件实例的数据，并将该数据保存到本地系统，以供后期查看或与其他用户共享。</p><p>VisualVM 是javajdk自带的最牛逼的调优工具了吧，也是我平时使用最多调优工具，几乎涉及了jvm调优的方方面面。同样是在jdk/bin目录下面双击jvisualvm.exe既可使用，启动起来后和jconsole 一样同样可以选择本地和远程，如果需要监控远程同样需要配置相关参数，主界面如下；</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131301.png" title="微信截图_20230702131301" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131301.png" alt="微信截图_20230702131301"></a></p><p>VisualVM可以根据需要安装不同的插件，每个插件的关注点都不同，有的主要监控GC，有的主要监控内存，有的监控线程等。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131341.png" title="微信截图_20230702131341" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131341.png" alt="微信截图_20230702131341"></a></p><p>如何安装：</p><blockquote><p>1、从主菜单中选择“工具”&gt;“插件”。<br>2、在“可用插件”标签中，选中该插件的“安装”复选框。单击“安装”。<br>3、逐步完成插件安装程序。</p></blockquote><p>我这里以 Eclipse(pid 22296)为例，双击后直接展开，主界面展示了系统和jvm两大块内容，点击右下方jvm参数和系统属性可以参考详细的参数信息.</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131410.png" title="微信截图_20230702131410" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131410.png" alt="微信截图_20230702131410"></a></p><p>因为VisualVM的插件太多，我这里主要介绍三个我主要使用几个：监控、线程、Visual GC</p><p>监控的主页其实也就是，cpu、内存、类、线程的图表</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131445.png" title="微信截图_20230702131445" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131445.png" alt="微信截图_20230702131445"></a></p><p>线程和jconsole功能没有太大的区别</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131520.png" title="微信截图_20230702131520" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131520.png" alt="微信截图_20230702131520"></a></p><p>Visual GC 是常常使用的一个功能，可以明显的看到年轻代、老年代的内存变化，以及gc频率、gc的时间等。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131559.png" title="微信截图_20230702131559" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131559.png" alt="微信截图_20230702131559"></a></p><p>以上的功能其实jconsole几乎也有，VisualVM更全面更直观一些，另外VisualVM非常多的其它功能，可以分析dump的内存快照，dump出来的线程快照并且进行分析等，还有其它很多的插件大家可以去探索</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131630.png" title="微信截图_20230702131630" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131630.png" alt="微信截图_20230702131630"></a></p><h2 id="第三方调优工具">第三方调优工具</h2><h3 id="MAT">MAT</h3><p><strong>MAT是什么？</strong></p><p>MAT(Memory Analyzer Tool)，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗。使用内存分析工具从众多的对象中进行分析，快速的计算出在内存中对象的占用大小，看看是谁阻止了垃圾收集器的回收工作，并可以通过报表直观的查看到可能造成这种结果的对象。</p><p>通常内存泄露分析被认为是一件很有难度的工作，一般由团队中的资深人士进行。不过要介绍的 MAT（Eclipse Memory Analyzer）被认为是一个“傻瓜式“的堆转储文件分析工具，你只需要轻轻点击一下鼠标就可以生成一个专业的分析报告。和其他内存泄露分析工具相比，MAT 的使用非常容易，基本可以实现一键到位，即使是新手也能够很快上手使用。</p><p>MAT以eclipse 插件的形式来安装，具体的安装过程就不在描述了，可以利用visualvm或者是 jmap命令生产堆文件，导入eclipse mat中生成分析报告：</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131714.png" title="微信截图_20230702131714" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131714.png" alt="微信截图_20230702131714"></a></p><p>生产这会报表的同时也会在dump文件的同级目录下生成三份（dump_Top_Consumers.zip、dump_Leak_Suspects.zip、dump_Top_Components.zip）分析结果的html文件，方便发送给相关同事来查看。</p><p>需要关注的是下面的Actions、Reports、Step by Step区域：</p><ul><li>Histogram：列出内存中的对象，对象的个数以及大小，支持正则表达式查找，也可以计算出该类所有对象的retained size</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131742.png" title="微信截图_20230702131742" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131742.png" alt="微信截图_20230702131742"></a></p><ul><li>Dominator Tree：列出最大的对象以及其依赖存活的Object （大小是以Retained Heap为标准排序的）</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131822.png" title="微信截图_20230702131822" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131822.png" alt="微信截图_20230702131822"></a></p><ul><li>Top Consumers ： 通过图形列出最大的object</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131852.png" title="微信截图_20230702131852" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131852.png" alt="微信截图_20230702131852"></a></p><ul><li>duplicate classes ：检测由多个类装载器加载的类</li><li>Leak Suspects ：内存泄漏分析</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131931.png" title="微信截图_20230702131931" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131931.png" alt="微信截图_20230702131931"></a></p><ul><li>Top Components: 列出大于总堆数的百分之1的报表。</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131959.png" title="微信截图_20230702131959" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702131959.png" alt="微信截图_20230702131959"></a></p><ul><li>Component Report:分析对象属于同一个包或者被同一个类加载器加载</li></ul><p>以上只是一个初级的介绍，mat还有更强大的使用，比如对比堆内存，在生产环境中往往为了定位问题，每隔几分钟dump出一下内存快照，随后在对比不同时间的堆内存的变化来发现问题。</p><h3 id="GChisto">GChisto</h3><p>GChisto是一款专业分析gc日志的工具，可以通过gc日志来分析：Minor GC、full gc的时间、频率等等，通过列表、报表、图表等不同的形式来反应gc的情况。虽然界面略显粗糙，但是功能还是不错的。</p><p>配置好本地的jdk环境之后，双击GChisto.jar,在弹出的输入框中点击 add 选择gc.log日志</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702132030.png" title="微信截图_20230702132030" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702132030.png" alt="微信截图_20230702132030"></a></p><ul><li>GC Pause Stats:可以查看GC 的次数、GC的时间、GC的开销、最大GC时间和最小GC时间等，以及相应的柱状图</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702132056.png" title="微信截图_20230702132056" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702132056.png" alt="微信截图_20230702132056"></a></p><ul><li>GC Pause Distribution:查看GC停顿的详细分布，x轴表示垃圾收集停顿时间，y轴表示是停顿次数。</li><li>GC Timeline：显示整个时间线上的垃圾收集</li></ul><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702132132.png" title="微信截图_20230702132132" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702132132.png" alt="微信截图_20230702132132"></a></p><p>不过这款工具已经不再维护，不能识别最新jdk的日志文件。</p><h3 id="gcviewer">gcviewer</h3><p>GCViewer也是一款分析小工具，用于可视化查看由Sun / Oracle, IBM, HP 和 BEA Java 虚拟机产生的垃圾收集器的日志，gcviewer个人感觉显示 的界面比较乱没有GChisto更专业一些。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702132155.png" title="微信截图_20230702132155" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%85%AD)jvm%E8%B0%83%E4%BC%98-%E5%B7%A5%E5%85%B7%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702132155.png" alt="微信截图_20230702132155"></a></p><h3 id="GC-Easy">GC Easy</h3><p>这是一个web工具,在线使用非常方便.</p><p>地址: <a href="http://gceasy.io">http://gceasy.io</a></p><p>进入官网，讲打包好的zip或者gz为后缀的压缩包上传，过一会就会拿到分析结果。</p></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;jvm系列(六):jvm调优-工具篇&lt;/h1&gt;
&lt;p&gt;16年的时候花了一些时间整理了一些关于jvm的介绍文章,到现在回顾起来还是一些还没有补充全面，其中就包括如何利用工具来监控调优前后的性能变化。工具做为图形化界</summary>
      
    
    
    
    <category term="JVM调优合集" scheme="https://0914ds.github.io/categories/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/"/>
    
    
  </entry>
  
  <entry>
    <title>jvm系列(四):jvm调优-命令篇</title>
    <link href="https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%9B%9B)jvm%E8%B0%83%E4%BC%98-%E5%91%BD%E4%BB%A4%E7%AF%87/"/>
    <id>https://0914ds.github.io/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%9B%9B)jvm%E8%B0%83%E4%BC%98-%E5%91%BD%E4%BB%A4%E7%AF%87/</id>
    <published>2022-03-10T18:45:12.000Z</published>
    <updated>2023-07-02T05:38:07.043Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>jvm系列(四):jvm调优-命令篇</h1><p>运用jvm自带的命令可以方便的在生产监控和打印堆栈的日志信息帮忙我们来定位问题！虽然jvm调优成熟的工具已经有很多：jconsole、大名鼎鼎的VisualVM，IBM的Memory Analyzer等等，但是在生产环境出现问题的时候，一方面工具的使用会有所限制，另一方面喜欢装X的我们，总喜欢在出现问题的时候在终端输入一些命令来解决。所有的工具几乎都是依赖于jdk的接口和底层的这些命令，研究这些命令的使用也让我们更能了解jvm构成和特性。</p><p>Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo下面做一一介绍</p><h2 id="jps">jps</h2><p>JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。</p><h3 id="命令格式">命令格式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps [options] [hostid]</span><br></pre></td></tr></table></figure><h3 id="option参数">option参数</h3><blockquote><ul><li>-l : 输出主类全名或jar路径</li><li>-q : 只输出LVMID</li><li>-m : 输出JVM启动时传递给main()的参数</li><li>-v : 输出JVM启动时显示指定的JVM参数</li></ul></blockquote><p>其中[option]、[hostid]参数也可以不写。</p><h3 id="示例">示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jps -l -m  28920 org.apache.catalina.startup.Bootstrap start  11589 org.apache.catalina.startup.Bootstrap start  25816 sun.tools.jps.Jps -l -m</span><br></pre></td></tr></table></figure><h2 id="jstat">jstat</h2><p>jstat(JVM statistics Monitoring)是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。</p><h3 id="命令格式-2">命令格式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstat [option] LVMID [interval] [count]</span><br></pre></td></tr></table></figure><h3 id="参数">参数</h3><blockquote><ul><li>[option] : 操作参数</li><li>LVMID : 本地虚拟机进程ID</li><li>[interval] : 连续输出的时间间隔</li><li>[count] : 连续输出的次数</li></ul></blockquote><h4 id="option-参数总览">option 参数总览</h4><table><thead><tr><th style="text-align:left">Option</th><th style="text-align:left">Displays…</th></tr></thead><tbody><tr><td style="text-align:left">class</td><td style="text-align:left">class loader的行为统计。Statistics on the behavior of the class loader.</td></tr><tr><td style="text-align:left">compiler</td><td style="text-align:left">HotSpt JIT编译器行为统计。Statistics of the behavior of the HotSpot Just-in-Time compiler.</td></tr><tr><td style="text-align:left">gc</td><td style="text-align:left">垃圾回收堆的行为统计。Statistics of the behavior of the garbage collected heap.</td></tr><tr><td style="text-align:left">gccapacity</td><td style="text-align:left">各个垃圾回收代容量(young,old,perm)和他们相应的空间统计。Statistics of the capacities of the generations and their corresponding spaces.</td></tr><tr><td style="text-align:left">gcutil</td><td style="text-align:left">垃圾回收统计概述。Summary of garbage collection statistics.</td></tr><tr><td style="text-align:left">gccause</td><td style="text-align:left">垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因。Summary of garbage collection statistics (same as -gcutil), with the cause of the last and</td></tr><tr><td style="text-align:left">gcnew</td><td style="text-align:left">新生代行为统计。Statistics of the behavior of the new generation.</td></tr><tr><td style="text-align:left">gcnewcapacity</td><td style="text-align:left">新生代与其相应的内存空间的统计。Statistics of the sizes of the new generations and its corresponding spaces.</td></tr><tr><td style="text-align:left">gcold</td><td style="text-align:left">年老代和永生代行为统计。Statistics of the behavior of the old and permanent generations.</td></tr><tr><td style="text-align:left">gcoldcapacity</td><td style="text-align:left">年老代行为统计。Statistics of the sizes of the old generation.</td></tr><tr><td style="text-align:left">gcpermcapacity</td><td style="text-align:left">永生代行为统计。Statistics of the sizes of the permanent generation.</td></tr><tr><td style="text-align:left">printcompilation</td><td style="text-align:left">HotSpot编译方法统计。HotSpot compilation method statistics.</td></tr></tbody></table><h4 id="option-参数详解">option 参数详解</h4><h5 id="class">-class</h5><p>监视类装载、卸载数量、总空间以及耗费的时间</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -class 11589 Loaded  Bytes  Unloaded  Bytes     Time     7035  14506.3     0     0.0       3.67</span><br></pre></td></tr></table></figure><blockquote><ul><li>Loaded : 加载class的数量</li><li>Bytes : class字节大小</li><li>Unloaded : 未加载class的数量</li><li>Bytes : 未加载class的字节大小</li><li>Time : 加载时间</li></ul></blockquote><h5 id="compiler">-compiler</h5><p>输出JIT编译过的方法数量耗时等</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -compiler 1262Compiled Failed Invalid   Time   FailedType FailedMethod    2573      1       0    47.60          1 org/apache/catalina/loader/WebappClassLoader findResourceInternal  </span><br></pre></td></tr></table></figure><blockquote><ul><li>Compiled : 编译数量</li><li>Failed : 编译失败数量</li><li>Invalid : 无效数量</li><li>Time : 编译耗时</li><li>FailedType : 失败类型</li><li>FailedMethod : 失败方法的全限定名</li></ul></blockquote><h5 id="gc">-gc</h5><p>垃圾回收堆的行为统计，<strong>常用命令</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gc 1262 S0C    S1C     S0U     S1U   EC       EU        OC         OU        PC       PU         YGC    YGCT    FGC    FGCT     GCT   26112.0 24064.0 6562.5  0.0   564224.0 76274.5   434176.0   388518.3  524288.0 42724.7    320    6.417   1      0.398    6.815</span><br></pre></td></tr></table></figure><p><strong>C即Capacity 总容量，U即Used 已使用的容量</strong></p><blockquote><ul><li>S0C : survivor0区的总容量</li><li>S1C : survivor1区的总容量</li><li>S0U : survivor0区已使用的容量</li><li>S1C : survivor1区已使用的容量</li><li>EC : Eden区的总容量</li><li>EU : Eden区已使用的容量</li><li>OC : Old区的总容量</li><li>OU : Old区已使用的容量</li><li>PC 当前perm的容量 (KB)</li><li>PU perm的使用 (KB)</li><li>YGC : 新生代垃圾回收次数</li><li>YGCT : 新生代垃圾回收时间</li><li>FGC : 老年代垃圾回收次数</li><li>FGCT : 老年代垃圾回收时间</li><li>GCT : 垃圾回收总消耗时间</li></ul></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gc 1262 2000 20</span><br></pre></td></tr></table></figure><p>这个命令意思就是每隔2000ms输出1262的gc情况，一共输出20次</p><h5 id="gccapacity">-gccapacity</h5><p>同-gc，不过还会输出Java堆各区域使用到的最大、最小空间</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gccapacity 1262 NGCMN    NGCMX     NGC    S0C   S1C       EC         OGCMN      OGCMX      OGC        OC       PGCMN    PGCMX     PGC      PC         YGC    FGC 614400.0 614400.0 614400.0 26112.0 24064.0 564224.0   434176.0   434176.0   434176.0   434176.0 524288.0 1048576.0 524288.0 524288.0    320     1  </span><br></pre></td></tr></table></figure><blockquote><ul><li>NGCMN : 新生代占用的最小空间</li><li>NGCMX : 新生代占用的最大空间</li><li>OGCMN : 老年代占用的最小空间</li><li>OGCMX : 老年代占用的最大空间</li><li>OGC：当前年老代的容量 (KB)</li><li>OC：当前年老代的空间 (KB)</li><li>PGCMN : perm占用的最小空间</li><li>PGCMX : perm占用的最大空间</li></ul></blockquote><h5 id="gcutil">-gcutil</h5><p>同-gc，不过输出的是已使用空间占总空间的百分比</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gcutil 28920  S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT    12.45   0.00  33.85   0.00   4.44  4       0.242     0    0.000    0.242</span><br></pre></td></tr></table></figure><h5 id="gccause">-gccause</h5><p>垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gccause 28920  S0     S1     E      O      P       YGC     YGCT    FGC    FGCT     GCT    LGCC                 GCC                  12.45   0.00  33.85   0.00   4.44      4    0.242     0    0.000    0.242   Allocation Failure   No GC  </span><br></pre></td></tr></table></figure><blockquote><ul><li>LGCC：最近垃圾回收的原因</li><li>GCC：当前垃圾回收的原因</li></ul></blockquote><h5 id="gcnew">-gcnew</h5><p>统计新生代的行为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gcnew 28920 S0C      S1C      S0U        S1U  TT  MTT  DSS      EC        EU         YGC     YGCT   419392.0 419392.0 52231.8    0.0  6   6    209696.0 3355520.0 1172246.0  4       0.242</span><br></pre></td></tr></table></figure><blockquote><ul><li>TT：Tenuring threshold(提升阈值)</li><li>MTT：最大的tenuring threshold</li><li>DSS：survivor区域大小 (KB)</li></ul></blockquote><h5 id="gcnewcapacity">-gcnewcapacity</h5><p>新生代与其相应的内存空间的统计</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gcnewcapacity 28920  NGCMN      NGCMX       NGC      S0CMX     S0C     S1CMX     S1C       ECMX        EC        YGC   FGC  4194304.0  4194304.0  4194304.0 419392.0 419392.0 419392.0 419392.0  3355520.0  3355520.0     4     0</span><br></pre></td></tr></table></figure><blockquote><ul><li>NGC:当前年轻代的容量 (KB)</li><li>S0CMX:最大的S0空间 (KB)</li><li>S0C:当前S0空间 (KB)</li><li>ECMX:最大eden空间 (KB)</li><li>EC:当前eden空间 (KB)</li></ul></blockquote><h5 id="gcold">-gcold</h5><p>统计旧生代的行为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gcold 28920   PC       PU        OC           OU       YGC    FGC    FGCT     GCT   1048576.0  46561.7   6291456.0     0.0      4      0      0.000    0.242</span><br></pre></td></tr></table></figure><h5 id="gcoldcapacity">-gcoldcapacity</h5><p>统计旧生代的大小和空间</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gcoldcapacity 28920   OGCMN       OGCMX        OGC         OC         YGC   FGC    FGCT     GCT     6291456.0   6291456.0   6291456.0   6291456.0     4     0    0.000    0.242</span><br></pre></td></tr></table></figure><h5 id="gcpermcapacity">-gcpermcapacity</h5><p>永生代行为统计</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -gcpermcapacity 28920    PGCMN      PGCMX       PGC         PC      YGC   FGC    FGCT     GCT    1048576.0  2097152.0  1048576.0  1048576.0     4     0    0.000    0.242</span><br></pre></td></tr></table></figure><h5 id="printcompilation">-printcompilation</h5><p>hotspot编译方法统计</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -printcompilation 28920    Compiled  Size  Type Method    1291      78     1    java/util/ArrayList indexOf</span><br></pre></td></tr></table></figure><blockquote><ul><li>Compiled：被执行的编译任务的数量</li><li>Size：方法字节码的字节数</li><li>Type：编译类型</li><li>Method：编译方法的类名和方法名。类名使用&quot;/&quot; 代替 “.” 作为空间分隔符. 方法名是给出类的方法名. 格式是一致于HotSpot - XX:+PrintComplation 选项</li></ul></blockquote><h2 id="jmap">jmap</h2><p>jmap(JVM Memory Map)命令用于生成heap dump文件，如果不使用这个命令，还阔以使用-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候·自动生成dump文件。 jmap不仅能生成dump文件，还阔以查询finalize执行队列、Java堆和永久代的详细信息，如当前使用率、当前使用的是哪种收集器等。</p><h3 id="命令格式-3">命令格式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap [option] LVMID</span><br></pre></td></tr></table></figure><h3 id="option参数-2">option参数</h3><blockquote><ul><li>dump : 生成堆转储快照</li><li>finalizerinfo : 显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象</li><li>heap : 显示Java堆详细信息</li><li>histo : 显示堆中对象的统计信息</li><li>permstat : to print permanent generation statistics</li><li>F : 当-dump没有响应时，强制生成dump快照</li></ul></blockquote><h3 id="示例-2">示例</h3><h5 id="dump">-dump</h5><p>常用格式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-dump::live,format=b,file=&lt;filename&gt; pid </span><br></pre></td></tr></table></figure><p>dump堆到文件,format指定输出格式，live指明是活着的对象,file指定文件名</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jmap -dump:live,format=b,file=dump.hprof 28920  Dumping heap to /home/xxx/dump.hprof ...  Heap dump file created</span><br></pre></td></tr></table></figure><p>dump.hprof这个后缀是为了后续可以直接用MAT(Memory Anlysis Tool)打开。</p><h5 id="finalizerinfo">-finalizerinfo</h5><p>打印等待回收对象的信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jmap -finalizerinfo 28920  Attaching to process ID 28920, please wait...  Debugger attached successfully.  Server compiler detected.  JVM version is 24.71-b01  Number of objects pending for finalization: 0</span><br></pre></td></tr></table></figure><p>可以看到当前F-QUEUE队列中并没有等待Finalizer线程执行finalizer方法的对象。</p><h5 id="heap">-heap</h5><p>打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况,可以用此来判断内存目前的使用情况以及垃圾回收情况</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jmap -heap 28920  Attaching to process ID 28920, please wait...  Debugger attached successfully.  Server compiler detected.  JVM version is 24.71-b01    using thread-local object allocation.  Parallel GC with 4 thread(s)//GC 方式    Heap Configuration: //堆内存初始化配置     MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40)     MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70)     MaxHeapSize      = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小     NewSize          = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小     MaxNewSize       = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小     OldSize          = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小     NewRatio         = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率     SurvivorRatio    = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值      PermSize         = 21757952 (20.75MB)  //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小     MaxPermSize      = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小     G1HeapRegionSize = 0 (0.0MB)    Heap Usage://堆内存使用情况  PS Young Generation  Eden Space://Eden区内存分布     capacity = 33030144 (31.5MB)//Eden区总容量     used     = 1524040 (1.4534378051757812MB)  //Eden区已使用     free     = 31506104 (30.04656219482422MB)  //Eden区剩余容量     4.614088270399305% used //Eden区使用比率  From Space:  //其中一个Survivor区的内存分布     capacity = 5242880 (5.0MB)     used     = 0 (0.0MB)     free     = 5242880 (5.0MB)     0.0% used  To Space:  //另一个Survivor区的内存分布     capacity = 5242880 (5.0MB)     used     = 0 (0.0MB)     free     = 5242880 (5.0MB)     0.0% used  PS Old Generation //当前的Old区内存分布     capacity = 86507520 (82.5MB)     used     = 0 (0.0MB)     free     = 86507520 (82.5MB)     0.0% used  PS Perm Generation//当前的 “永生代” 内存分布     capacity = 22020096 (21.0MB)     used     = 2496528 (2.3808746337890625MB)     free     = 19523568 (18.619125366210938MB)     11.337498256138392% used    670 interned Strings occupying 43720 bytes.</span><br></pre></td></tr></table></figure><p>可以很清楚的看到Java堆中各个区域目前的情况。</p><h5 id="histo">-histo</h5><p>打印堆的对象统计，包括对象数、内存大小等等 （因为在dump:live前会进行full gc，如果带上live则只统计活对象，因此不加live的堆大小要大于加live堆的大小 ）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jmap -histo:live 28920 | more num     #instances         #bytes  class name----------------------------------------------   1:         83613       12012248  &lt;constMethodKlass&gt;   2:         23868       11450280  [B   3:         83613       10716064  &lt;methodKlass&gt;   4:         76287       10412128  [C   5:          8227        9021176  &lt;constantPoolKlass&gt;   6:          8227        5830256  &lt;instanceKlassKlass&gt;   7:          7031        5156480  &lt;constantPoolCacheKlass&gt;   8:         73627        1767048  java.lang.String   9:          2260        1348848  &lt;methodDataKlass&gt;  10:          8856         849296  java.lang.Class  ....</span><br></pre></td></tr></table></figure><p>仅仅打印了前10行</p><p>xml class name是对象类型，说明如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B  byteC  charD  doubleF  floatI  intJ  longZ  boolean[  数组，如[I表示int[][L+类名 其他对象</span><br></pre></td></tr></table></figure><h5 id="permstat">-permstat</h5><p>打印Java堆内存的永久保存区域的类加载器的智能统计信息。对于每个类加载器而言，它的名称、活跃度、地址、父类加载器、它所加载的类的数量和大小都会被打印。此外，包含的字符串数量和大小也会被打印。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jmap -permstat 28920  Attaching to process ID 28920, please wait...  Debugger attached successfully.  Server compiler detected.  JVM version is 24.71-b01  finding class loader instances ..done.  computing per loader stat ..done.  please wait.. computing liveness.liveness analysis may be inaccurate ...  class_loader            classes bytes   parent_loader           alive?  type    &lt;bootstrap&gt;             3111    18154296          null          live    &lt;internal&gt;  0x0000000600905cf8      1       1888    0x0000000600087f08      dead    sun/reflect/DelegatingClassLoader@0x00000007800500a0  0x00000006008fcb48      1       1888    0x0000000600087f08      dead    sun/reflect/DelegatingClassLoader@0x00000007800500a0  0x00000006016db798      0       0       0x00000006008d3fc0      dead    java/util/ResourceBundle$RBClassLoader@0x0000000780626ec0  0x00000006008d6810      1       3056      null          dead    sun/reflect/DelegatingClassLoader@0x00000007800500a0</span><br></pre></td></tr></table></figure><h5 id="F">-F</h5><p>强制模式。如果指定的pid没有响应，请使用jmap -dump或jmap -histo选项。此模式下，不支持live子选项。</p><h2 id="jhat">jhat</h2><p>jhat(JVM Heap Analysis Tool)命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看。在此要注意，一般不会直接在服务器上进行分析，因为jhat是一个耗时并且耗费硬件资源的过程，一般把服务器生成的dump文件复制到本地或其他机器上进行分析。</p><h3 id="命令格式-4">命令格式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jhat [dumpfile]</span><br></pre></td></tr></table></figure><h3 id="参数-2">参数</h3><blockquote><ul><li>-stack false|true 关闭对象分配调用栈跟踪(tracking object allocation call stack)。 如果分配位置信息在堆转储中不可用. 则必须将此标志设置为 false. 默认值为 true.&gt;</li><li>-refs false|true 关闭对象引用跟踪(tracking of references to objects)。 默认值为 true. 默认情况下, 返回的指针是指向其他特定对象的对象,如反向链接或输入引用(referrers or incoming references), 会统计/计算堆中的所有对象。&gt;</li><li>-port port-number 设置 jhat HTTP server 的端口号. 默认值 7000.&gt;</li><li>-exclude exclude-file 指定对象查询时需要排除的数据成员列表文件(a file that lists data members that should be excluded from the reachable objects query)。 例如, 如果文件列列出了 java.lang.String.value , 那么当从某个特定对象 Object o 计算可达的对象列表时, 引用路径涉及 java.lang.String.value 的都会被排除。&gt;</li><li>-baseline exclude-file 指定一个基准堆转储(baseline heap dump)。 在两个 heap dumps 中有相同 object ID 的对象会被标记为不是新的(marked as not being new). 其他对象被标记为新的(new). 在比较两个不同的堆转储时很有用.&gt;</li><li>-debug int 设置 debug 级别. 0 表示不输出调试信息。 值越大则表示输出更详细的 debug 信息.&gt;</li><li>-version 启动后只显示版本信息就退出&gt;</li><li>-J&lt; flag &gt; 因为 jhat 命令实际上会启动一个JVM来执行, 通过 -J 可以在启动JVM时传入一些启动参数. 例如, -J-Xmx512m 则指定运行 jhat 的Java虚拟机使用的最大堆内存为 512 MB. 如果需要使用多个JVM启动参数,则传入多个 -Jxxxxxx.</li></ul></blockquote><h3 id="示例-3">示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jhat -J-Xmx512m dump.hprof  eading from dump.hprof...  Dump file created Fri Mar 11 17:13:42 CST 2016  Snapshot read, resolving...  Resolving 271678 objects...  Chasing references, expect 54 dots......................................................  Eliminating duplicate references......................................................  Snapshot resolved.  Started HTTP server on port 7000  Server is ready.</span><br></pre></td></tr></table></figure><p>中间的-J-Xmx512m是在dump快照很大的情况下分配512M内存去启动HTTP服务器，运行完之后就可在浏览器打开Http://localhost:7000进行快照分析 堆快照分析主要在最后面的Heap Histogram里，里面根据class列出了dump的时候所有存活对象。</p><p><strong>分析同样一个dump快照，MAT需要的额外内存比jhat要小的多的多，所以建议使用MAT来进行分析，当然也看个人偏好。</strong></p><h3 id="分析">分析</h3><p>打开浏览器<a href="Http://localhost:7000">Http://localhost:7000</a>，该页面提供了几个查询功能可供使用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">All classes including platformShow all members of the rootsetShow instance counts for all classes (including platform)Show instance counts for all classes (excluding platform)Show heap histogramShow finalizer summaryExecute Object Query Language (OQL) query</span><br></pre></td></tr></table></figure><p>一般查看堆异常情况主要看这个两个部分： Show instance counts for all classes (excluding platform)，平台外的所有对象信息。如下图：</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130632.png" title="微信截图_20230702130632" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%9B%9B)jvm%E8%B0%83%E4%BC%98-%E5%91%BD%E4%BB%A4%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130632.png" alt="微信截图_20230702130632"></a></p><p>Show heap histogram 以树状图形式展示堆情况。如下图：</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130713.png" title="微信截图_20230702130713" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/11/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E5%9B%9B)jvm%E8%B0%83%E4%BC%98-%E5%91%BD%E4%BB%A4%E7%AF%87//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702130713.png" alt="微信截图_20230702130713"></a></p><p>具体排查时需要结合代码，观察是否大量应该被回收的对象在一直被引用或者是否有占用内存特别大的对象无法被回收。<br><strong>一般情况，会down到客户端用工具来分析</strong></p><h2 id="jstack">jstack</h2><p>jstack用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。</p><h3 id="命令格式-5">命令格式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstack [option] LVMID</span><br></pre></td></tr></table></figure><h3 id="option参数-3">option参数</h3><blockquote><ul><li>-F : 当正常输出请求不被响应时，强制输出线程堆栈</li><li>-l : 除堆栈外，显示关于锁的附加信息</li><li>-m : 如果调用到本地方法的话，可以显示C/C++的堆栈</li></ul></blockquote><h3 id="示例-4">示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstack -l 11494|more2016-07-28 13:40:04Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.71-b01 mixed mode):&quot;Attach Listener&quot; daemon prio=10 tid=0x00007febb0002000 nid=0x6b6f waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;http-bio-8005-exec-2&quot; daemon prio=10 tid=0x00007feb94028000 nid=0x7b8c waiting on condition [0x00007fea8f56e000]   java.lang.Thread.State: WAITING (parking)        at sun.misc.Unsafe.park(Native Method)        - parking to wait for  &lt;0x00000000cae09b80&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)        at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:104)        at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:32)        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)        at java.lang.Thread.run(Thread.java:745)   Locked ownable synchronizers:        - None      .....</span><br></pre></td></tr></table></figure><h3 id="分析-2">分析</h3><p>这里有一篇文章解释的很好 分析打印出的文件内容</p><h2 id="jinfo">jinfo</h2><p>jinfo(JVM Configuration info)这个命令作用是实时查看和调整虚拟机运行参数。 之前的jps -v口令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用jinfo口令</p><h3 id="命令格式-6">命令格式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jinfo [option] [args] LVMID</span><br></pre></td></tr></table></figure><h3 id="option参数-4">option参数</h3><blockquote><ul><li>-flag : 输出指定args参数的值</li><li>-flags : 不需要args参数，输出所有JVM参数的值</li><li>-sysprops : 输出系统属性，等同于System.getProperties()</li></ul></blockquote><h3 id="示例-5">示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jinfo -flag 11494-XX:CMSInitiatingOccupancyFraction=80</span><br></pre></td></tr></table></figure></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;jvm系列(四):jvm调优-命令篇&lt;/h1&gt;
&lt;p&gt;运用jvm自带的命令可以方便的在生产监控和打印堆栈的日志信息帮忙我们来定位问题！虽然jvm调优成熟的工具已经有很多：jconsole、大名鼎鼎的VisualV</summary>
      
    
    
    
    <category term="JVM调优合集" scheme="https://0914ds.github.io/categories/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/"/>
    
    
  </entry>
  
  <entry>
    <title>jvm系列(一):java类的加载机制</title>
    <link href="https://0914ds.github.io/2022/03/10/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%80)java%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"/>
    <id>https://0914ds.github.io/2022/03/10/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%80)java%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</id>
    <published>2022-03-09T18:45:12.000Z</published>
    <updated>2023-07-02T05:31:45.016Z</updated>
    
    <content type="html"><![CDATA[<div class=".article-gallery"><h1>一，jvm系列(一):java类的加载机制</h1><h2 id="1、什么是类的加载">1、什么是类的加载</h2><p>类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个 <code>java.lang.Class</code>对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的 <code>Class</code>对象， <code>Class</code>对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702120310.png" title="微信截图_20230702120310" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/10/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%80)java%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702120310.png" alt="微信截图_20230702120310"></a></p><p>类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误</p><p><strong>加载.class文件的方式</strong></p><ul><li>从本地系统中直接加载</li><li>通过网络下载.class文件</li><li>从zip，jar等归档文件中加载.class文件</li><li>从专有数据库中提取.class文件</li><li>将Java源文件动态编译为.class文件</li></ul><h2 id="2、类的生命周期">2、类的生命周期</h2><p>其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。</p><h3 id="加载">加载</h3><p>查找并加载类的二进制数据加载时类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情：</p><ul><li>通过一个类的全限定名来获取其定义的二进制字节流。</li><li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</li><li>在Java堆中生成一个代表这个类的 <code>java.lang.Class</code>对象，作为对方法区中这些数据的访问入口。</li></ul><p>相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。</p><p>加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个 <code>java.lang.Class</code>类的对象，这样便可以通过该对象访问方法区中的这些数据。</p><h3 id="连接">连接</h3><p><strong>验证：确保被加载的类的正确性</strong></p><p>验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作：</p><ul><li><strong>文件格式验证</strong>：验证字节流是否符合Class文件格式的规范；例如：是否以 <code>0xCAFEBABE</code>开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。</li><li><strong>元数据验证</strong>：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了 <code>java.lang.Object</code>之外。</li><li><strong>字节码验证</strong>：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。</li><li><strong>符号引用验证</strong>：确保解析动作能正确执行。</li></ul><p>验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用 <code>-Xverifynone</code>参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。</p><p><strong>准备：为类的 <code>静态变量分</code>配内存，并将其初始化为默认值</strong></p><p>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：</p><ul><li>1、这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。</li><li>2、这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。</li></ul><p>假设一个类变量的定义为： <code>publicstaticintvalue=3</code>；</p><p>那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的 <code>publicstatic</code>指令是在程序编译后，存放于类构造器 <code>&lt;clinit&gt;（）</code>方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。</p><blockquote><p>这里还需要注意如下几点：</p><ul><li>对基本数据类型来说，对于类变量（static）和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。</li><li>对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。</li><li>对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。</li><li>如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。</li></ul></blockquote><ul><li>3、如果类字段的字段属性表中存在 <code>ConstantValue</code>属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。</li></ul><p>假设上面的类变量value被定义为： <code>publicstaticfinalintvalue=3</code>；</p><p>编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据 <code>ConstantValue</code>的设置将value赋值为3。我们可以理解为static final常量在编译期就将其结果放入了调用它的类的常量池中</p><p><strong>解析：把类中的符号引用转换为直接引用</strong></p><p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。</p><p>直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。</p><p><strong>初始化</strong></p><p>初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式：</p><ul><li>①声明类变量是指定初始值</li><li>②使用静态代码块为类变量指定初始值</li></ul><p>JVM初始化步骤</p><ul><li>1、假如这个类还没有被加载和连接，则程序先加载并连接该类</li><li>2、假如该类的直接父类还没有被初始化，则先初始化其直接父类</li><li>3、假如类中有初始化语句，则系统依次执行这些初始化语句</li></ul><p>类初始化时机：只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种：</p><ul><li>创建类的实例，也就是new的方式</li><li>访问某个类或接口的静态变量，或者对该静态变量赋值</li><li>调用类的静态方法</li><li>反射（如 <code>Class.forName(“com.shengsiyuan.Test”)</code>）</li><li>初始化某个类的子类，则其父类也会被初始化</li><li>Java虚拟机启动时被标明为启动类的类（ <code>JavaTest</code>），直接使用 <code>java.exe</code>命令来运行某个主类</li></ul><p><strong>结束生命周期</strong></p><p>在如下几种情况下，Java虚拟机将结束生命周期</p><ul><li>执行了 <code>System.exit()</code>方法</li><li>程序正常执行结束</li><li>程序在执行过程中遇到了异常或错误而异常终止</li><li>由于操作系统出现错误而导致Java虚拟机进程终止</li></ul><h2 id="3、类加载器">3、类加载器</h2><p>寻找类加载器，先来一个小例子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">package com.neo.classloader;public class ClassLoaderTest &#123;     public static void main(String[] args) &#123;        ClassLoader loader = Thread.currentThread().getContextClassLoader();        System.out.println(loader);        System.out.println(loader.getParent());        System.out.println(loader.getParent().getParent());    &#125;&#125;</span><br></pre></td></tr></table></figure><p>运行后，输出结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sun.misc.Launcher$AppClassLoader@64fef26asun.misc.Launcher$ExtClassLoader@1ddd40f3null</span><br></pre></td></tr></table></figure><p>从上面的结果可以看出，并没有获取到 <code>ExtClassLoader</code>的父Loader，原因是 <code>BootstrapLoader</code>（引导类加载器）是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。</p><p>这几种类加载器的层次关系如下图所示：</p><p><a href="%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702121042.png" title="微信截图_20230702121042" class="gallery-item" style="box-shadow: none;"> <img src="/2022/03/10/JVM/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/jvm%E7%B3%BB%E5%88%97(%E4%B8%80)java%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6//%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230702121042.png" alt="微信截图_20230702121042"></a></p><blockquote><p>注意：这里父类加载器并不是通过继承关系来实现的，而是采用组合实现的。</p></blockquote><p>站在Java虚拟机的角度来讲，只存在两种不同的类加载器：启动类加载器：它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分；所有其它的类加载器：这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类 <code>java.lang.ClassLoader</code>，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。</p><p>站在Java开发人员的角度来看，类加载器可以大致划分为以下三类：</p><p><strong>启动类加载器</strong>： <code>BootstrapClassLoader</code>，负责加载存放在 <code>JDK\jre\lib</code>(JDK代表JDK的安装目录，下同)下，或被 <code>-Xbootclasspath</code>参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.开头的类均被 <code>BootstrapClassLoader</code>加载）。启动类加载器是无法被Java程序直接引用的。<br><strong>扩展类加载器</strong>： <code>ExtensionClassLoader</code>，该加载器由 <code>sun.misc.Launcher$ExtClassLoader</code>实现，它负责加载 <code>JDK\jre\lib\ext</code>目录中，或者由 <code>java.ext.dirs</code>系统变量指定的路径中的所有类库（如javax.开头的类），开发者可以直接使用扩展类加载器。<br><strong>应用程序类加载器</strong>： <code>ApplicationClassLoader</code>，该类加载器由 <code>sun.misc.Launcher$AppClassLoader</code>来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</p><p>应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点：</p><ul><li>1、在执行非置信代码之前，自动验证数字签名。</li><li>2、动态地创建符合用户特定需要的定制化构建类。</li><li>3、从特定的场所取得java class，例如数据库中和网络中。</li></ul><p><strong>JVM类加载机制</strong></p><ul><li><strong>全盘负责</strong>，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入</li><li><strong>父类委托</strong>，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类</li><li><strong>缓存机制</strong>，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效</li></ul><h2 id="4、类的加载">4、类的加载</h2><p>类加载有三种方式：</p><ul><li>1、命令行启动应用时候由JVM初始化加载</li><li>2、通过Class.forName()方法动态加载</li><li>3、通过ClassLoader.loadClass()方法动态加载</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">package com.neo.classloader;public class loaderTest &#123;         public static void main(String[] args) throws ClassNotFoundException &#123;                 ClassLoader loader = HelloWorld.class.getClassLoader();                 System.out.println(loader);                 //使用ClassLoader.loadClass()来加载类，不会执行初始化块                 loader.loadClass(&quot;Test2&quot;);                 //使用Class.forName()来加载类，默认会执行初始化块                 //Class.forName(&quot;Test2&quot;);                 //使用Class.forName()来加载类，并指定ClassLoader，初始化时不执行静态块                 //Class.forName(&quot;Test2&quot;, false, loader);         &#125; &#125;</span><br></pre></td></tr></table></figure><p>demo类</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public class Test2 &#123;         static &#123;                 System.out.println(&quot;静态初始化块执行了！&quot;);         &#125; &#125;</span><br></pre></td></tr></table></figure><p>分别切换加载方式，会有不同的输出结果。</p><p><strong>Class.forName()和ClassLoader.loadClass()区别</strong></p><ul><li><code>Class.forName()</code>：将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块；</li><li><code>ClassLoader.loadClass()</code>：只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。</li><li><code>Class.forName(name,initialize,loader)</code>带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。</li></ul><h2 id="5、双亲委派模型">5、双亲委派模型</h2><p>双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。</p><p>双亲委派机制:</p><ul><li>1、当 <code>AppClassLoader</code>加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器<code>ExtClassLoader</code>去完成。</li><li>2、当 <code>ExtClassLoader</code>加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader```去完成。</li><li>3、如果 <code>BootStrapClassLoader</code>加载失败（例如在 <code>$JAVA_HOME/jre/lib</code>里未查找到该class），会使用 <code>ExtClassLoader</code>来尝试加载；</li><li>4、若ExtClassLoader也加载失败，则会使用 <code>AppClassLoader</code>来加载，如果 <code>AppClassLoader</code>也加载失败，则会报出异常 <code>ClassNotFoundException</code>。</li></ul><p>ClassLoader源码分析：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public Class&lt;?&gt; loadClass(String name)throws ClassNotFoundException &#123;        return loadClass(name, false);&#125;protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException &#123;        // 首先判断该类型是否已经被加载        Class c = findLoadedClass(name);        if (c == null) &#123;            //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载            try &#123;                if (parent != null) &#123;                     //如果存在父类加载器，就委派给父类加载器加载                    c = parent.loadClass(name, false);                &#125; else &#123;                //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name)                    c = findBootstrapClass0(name);                &#125;            &#125; catch (ClassNotFoundException e) &#123;             // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能                c = findClass(name);            &#125;        &#125;        if (resolve) &#123;            resolveClass(c);        &#125;        return c;    &#125;</span><br></pre></td></tr></table></figure><p>双亲委派模型意义：</p><ul><li>系统类防止内存中出现多份同样的字节码</li><li>保证Java程序安全稳定运行</li></ul><h2 id="6、自定义类加载器">6、自定义类加载器</h2><p>通常情况下，我们都是直接使用系统类加载器。但是，有的时候，我们也需要自定义类加载器。比如应用是通过网络来传输 Java类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承自 <code>ClassLoader</code>类，从上面对 <code>loadClass</code>方法来分析来看，我们只需要重写 findClass 方法即可。下面我们通过一个示例来演示自定义类加载器的流程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">package com.neo.classloader;import java.io.*;public class MyClassLoader extends ClassLoader &#123;    private String root;    protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;        byte[] classData = loadClassData(name);        if (classData == null) &#123;            throw new ClassNotFoundException();        &#125; else &#123;            return defineClass(name, classData, 0, classData.length);        &#125;    &#125;    private byte[] loadClassData(String className) &#123;        String fileName = root + File.separatorChar                + className.replace(&#x27;.&#x27;, File.separatorChar) + &quot;.class&quot;;        try &#123;            InputStream ins = new FileInputStream(fileName);            ByteArrayOutputStream baos = new ByteArrayOutputStream();            int bufferSize = 1024;            byte[] buffer = new byte[bufferSize];            int length = 0;            while ((length = ins.read(buffer)) != -1) &#123;                baos.write(buffer, 0, length);            &#125;            return baos.toByteArray();        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;        return null;    &#125;    public String getRoot() &#123;        return root;    &#125;    public void setRoot(String root) &#123;        this.root = root;    &#125;    public static void main(String[] args)  &#123;        MyClassLoader classLoader = new MyClassLoader();        classLoader.setRoot(&quot;E:\\temp&quot;);        Class&lt;?&gt; testClass = null;        try &#123;            testClass = classLoader.loadClass(&quot;com.neo.classloader.Test2&quot;);            Object object = testClass.newInstance();            System.out.println(object.getClass().getClassLoader());        &#125; catch (ClassNotFoundException e) &#123;            e.printStackTrace();        &#125; catch (InstantiationException e) &#123;            e.printStackTrace();        &#125; catch (IllegalAccessException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</span><br></pre></td></tr></table></figure><p>自定义类加载器的核心在于对字节码文件的获取，如果是加密的字节码则需要在该类中对文件进行解密。由于这里只是演示，我并未对class文件进行加密，因此没有解密的过程。这里有几点需要注意：</p><ul><li>1、这里传递的文件名需要是类的全限定性名称，即 <code>com.paddx.test.classloading.Test</code>格式的，因为 defineClass 方法是按这种格式进行处理的。</li><li>2、最好不要重写loadClass方法，因为这样容易破坏双亲委托模式。</li><li>3、这类Test 类本身可以被 <code>AppClassLoader</code>类加载，因此我们不能把 <code>com/paddx/test/classloading/Test.class</code>放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由 <code>AppClassLoader</code>加载，而不会通过我们自定义类加载器来加载。</li></ul></div>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;.article-gallery&quot;&gt;&lt;h1&gt;一，jvm系列(一):java类的加载机制&lt;/h1&gt;
&lt;h2 id=&quot;1、什么是类的加载&quot;&gt;1、什么是类的加载&lt;/h2&gt;
&lt;p&gt;类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区</summary>
      
    
    
    
    <category term="JVM调优合集" scheme="https://0914ds.github.io/categories/JVM%E8%B0%83%E4%BC%98%E5%90%88%E9%9B%86/"/>
    
    
  </entry>
  
</feed>
