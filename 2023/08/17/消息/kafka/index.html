<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>kafka | blog</title>
  <meta name="author" content="albert dong">
  
  <meta name="description" content="kafkaKafka 本质上是⼀个消息队列。与zeromq不同的是，Kafka是一个独立的框架而不是一个库。这里主要介绍其原理，至于具体的安装等操作不做介绍，只是提示一下，第一次运行时，先设置前台运行，看会不会报错。
架构注意下图没有画上zookeeper，请自行脑补。kafka需要连接到zooke">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="kafka"/>
  <meta property="og:site_name" content="blog"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/atom.xml" title="blog" type="application/atom+xml">
  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">  
  <link rel="stylesheet" href="/css/sidenav.css" media="screen" type="text/css">  
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body id="body" data-spy="scroll" data-target=".toc">
  <div class="container" id="container">
	<div class="content">
	  <div class="page-header">		
  <h1><a class="brand" href="/">blog</a><span class="split"></span><span class="title">kafka</span><span class="date" id="title-date"><i class="fa fa-clock-o"></i> 2023-08-17</span></h1>
</div>		

<div class="row page">
  <!-- cols -->	
  
  <div class="col-xs-12 col-sm-3 col-md-3 toc"> 
	<!-- toc -->
<script type="text/javascript">
		jQuery(document).ready(function() {
 		   generateWikiTOC('.note', '.toc',  2 , 2 );
		});
</script>
  </div><!-- col-md-3 -->
  
  

  
  <div class="col-xs-12 col-sm-9 col-md-9 note">
	

	  <!-- content -->
	  <h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h1><p><a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=Kafka&spm=1001.2101.3001.7020">Kafka</a> 本质上是⼀个消息队列。与zeromq不同的是，Kafka是一个独立的框架而不是一个库。这里主要介绍其原理，至于具体的安装等操作不做介绍，只是提示一下，第一次运行时，先设置前台运行，看会不会报错。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>注意下图没有画上zookeeper，请自行脑补。kafka需要连接到zookeeper，来完成注册发现等集群操作。broker都是由zookeeper管理。</p>
<p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\微信截图_20230706220539.png" alt="微信截图_20230706220539"></p>
<p>先给出 Kafka ⼀些重要概念，让⼤家对 Kafka 有个整体的认识和感知，后⾯还会详细的解析每⼀个概念的作⽤以及更深⼊的原理：</p>
<ul>
<li>Producer：消息⽣产者，向 Kafka Broker 发消息的客户端。</li>
<li>Consumer：消息消费者，从 Kafka Broker 取消息的客户端。Kafka支持持久化，生产者退出后，未消费的消息仍可被消费</li>
<li>Consumer Group：消费者组（CG），消费者组内每个消费者负责消费不同分区的数据，提⾼消费能⼒。⼀个分区只能由组内⼀个费者消费，消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的⼀个订阅者</li>
<li>Broker：⼀台 Kafka 机器就是⼀个 Broker。⼀个集群(kafka cluster)由多个 Broker 组成。⼀个 Broker 可以容纳多个 Topic</li>
<li>Controller：由zookeeper选举其中一个Broker产生。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。</li>
<li>Topic：可以理解为⼀个队列，Topic 将消息分类，⽣产者和消费者⾯向的是同⼀个 Topic。</li>
<li>Partition：为了实现扩展性，提⾼并发能⼒，⼀个⾮常⼤的 Topic 可以分布到多个 Broker上，⼀个 Topic 可以分为多个 Partition，同⼀个topic在不同的分区的数据是不重复的，每个 Partition 是⼀个有序的队列，其表现形式就是⼀个⼀个的⽂件夹。不同Partition可以部署在同一台机器上，但不建议这么做。</li>
<li>Replication：每⼀个分区都有多个副本，副本的作⽤是做备胎。当主分区（Leader）故障的时候会选择⼀个备胎（Follower）上位，成为Leader。在kafka中默认副本的最⼤数量是10个，且副本的数量不能⼤于Broker的数量，follower和leader绝对是在不同的机器，同⼀机器对同⼀个分区也只可能存放⼀个副本（包括⾃⼰）。</li>
<li>Message：每⼀条发送的消息主体。</li>
<li>Leader：每个分区多个副本的“主”副本，⽣产者发送数据的对象，以及消费者消费数据的对象，都是 Leader。</li>
<li>Follower：每个分区多个副本的“从”副本，使用发布订阅模式主动拉取Leader的数据（与redis不同），实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发⽣故障时，某个 Follower 还会成为新的 Leader。</li>
<li>Offset：消费者消费的位置信息，监控数据消费到什么位置，当消费者挂掉再重新恢复的时候，可以从消费位置继续消费。</li>
<li>ZooKeeper：Kafka 集群能够正常⼯作，需要依赖于 ZooKeeper，ZooKeeper 帮助 Kafka存储和管理集群信息。<br>High Level API 和Low Level API ：高水平API，kafka本身定义的行为，屏蔽细节管理，使用方便；低水平API细节需要自己处理，较为灵活但是复杂。</li>
<li>kafka 存储的消息来⾃任意多被称为 Producer ⽣产者的进程。数据从⽽可以被发布到不同的Topic 主题下的不同 Partition 分区。在⼀个分区内，这些消息被索引并连同时间戳存储在⼀起。其它被称为 Consumer 消费者的进程可以从分区订阅消息。<br>Kafka 运⾏在⼀个由⼀台或多台服务器组成的集群上，并且分区可以跨集群结点分布。</li>
</ul>
<h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\微信截图_20230706220948.png" alt="微信截图_20230706220948"></p>
<p>Kafka集群将 Record 流存储在称为 Topic 的类中，每个记录由⼀个键、⼀个值和⼀个时间戳组成。<br>Kafka 中消息是以 Topic 进⾏分类的，⽣产者⽣产消息，消费者消费消息，⾯向的都是同⼀个Topic。Topic 是逻辑上的概念，⽽ Partition 是物理上的概念，每个 Partition 对应于⼀个 log ⽂件，该log ⽂件中存储的就是 Producer ⽣产的数据。Producer ⽣产的数据会不断追加到该 log ⽂件末端，且每条数据都有⾃⼰的 Offset。消费者组中的每个消费者，都会实时记录⾃⼰消费到了哪个 Offset，以便出错恢复时，从上次的位置继续消费。</p>
<p>Kafka集群将 Record 流存储在称为 Topic 的类中，每个记录由⼀个键、⼀个值和⼀个时间戳组成。<br>Kafka 中消息是以 Topic 进⾏分类的，⽣产者⽣产消息，消费者消费消息，⾯向的都是同⼀个Topic。Topic 是逻辑上的概念，⽽ Partition 是物理上的概念，每个 Partition 对应于⼀个 log ⽂件，该log ⽂件中存储的就是 Producer ⽣产的数据。Producer ⽣产的数据会不断追加到该 log ⽂件末端，且每条数据都有⾃⼰的 Offset。消费者组中的每个消费者，都会实时记录⾃⼰消费到了哪个 Offset，以便出错恢复时，从上次的位置继续消费。</p>
<p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\9a196aac8d47479f82b0046b6b51aa65.jpg" alt="9a196aac8d47479f82b0046b6b51aa65"></p>
<p>这些⽂件位于同⼀⽂件下，该⽂件夹的命名规则为：topic 名-分区号。例如，test这个 topic 有三个分区，则其对应的⽂件夹为 test-0，test-1，test-2。</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$</span> <span class="built_in">ls</span> /tmp/kafka<span class="literal">-logs</span>/<span class="built_in">test-1</span></span><br><span class="line"><span class="number">00000000000000009014</span>.index</span><br><span class="line"><span class="number">00000000000000009014</span>.log</span><br><span class="line"><span class="number">00000000000000009014</span>.timeindex</span><br><span class="line">leader<span class="literal">-epoch-checkpoint</span></span><br></pre></td></tr></table></figure>

<p>index 和 log ⽂件以当前 Segment 的第⼀条消息的 Offset 命名。下图为 index ⽂件和 log ⽂件的结构示意图</p>
<p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\60904efb05104cdea48f0e38cb134cbd.jpg" alt="60904efb05104cdea48f0e38cb134cbd"></p>
<p>“.index” ⽂件存储⼤量的索引信息，“.log” ⽂件存储⼤量的数据，索引⽂件中的元数据指向对应数据⽂件中 Message 的物理偏移量。<br>使用shell命令查看索引</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka<span class="literal">-dump-log</span>.sh <span class="literal">--files</span> /tmp/kafka<span class="literal">-logs</span>/<span class="built_in">test-1</span>/<span class="number">00000000000000000000</span>.index</span><br></pre></td></tr></table></figure>

<h2 id="分区机制"><a href="#分区机制" class="headerlink" title="分区机制"></a>分区机制</h2><p>分区原因：</p>
<p>⽅便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，⽽⼀个 Topic ⼜可以有多个 Partition 组成，因此可以以 Partition 为单位读写了。<br>可以提⾼并发，避免两个分区持久化的时候争夺资源。<br>备份的问题。防止一台机器宕机后数据丢失的问题。<br>分区原则：我们需要将 Producer 发送的数据封装成⼀个 ProducerRecord 对象。该对象需要指定⼀些参数：</p>
<p>topic：string 类型，NotNull。<br>partition：int 类型，可选。<br>timestamp：long 类型，可选。<br>key：string 类型，可选。<br>value：string 类型，可选。<br>headers：array 类型，Nullable。<br>指明 Partition 的情况下，直接将给定的 Value 作为 Partition 的值；没有指明 Partition 但有 Key 的情况下，将 Key 的 Hash 值与分区数取余得到 Partition 值；既没有 Partition 又没有 Key 的情况下，第⼀次调⽤时随机⽣成⼀个整数（后⾯每次调⽤都在这个整数上⾃增），将这个值与可⽤的分区数取余，得到 Partition 值，也就是常说的 Round-Robin轮询算法。</p>
<h2 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h2><p>Producer⽣产者，是数据的⼊⼝。Producer在写⼊数据的时候永远的找leader，不会直接将数据写⼊follower。下图很好地阐释了生产者的工作流程。</p>
<p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\9715111fbe814854b01de917a3c4632d.jpg" alt="9715111fbe814854b01de917a3c4632d"></p>
<p>这里获取分区信息，是从zookeeper中获取的。<br>生产者不会每个消息都调用一次send()，这样效率太低，默认是数据攒到16K或是超时（如10ms）会send()一次。注意这里发消息是异步操作。</p>
<h2 id="ack机制"><a href="#ack机制" class="headerlink" title="ack机制"></a>ack机制</h2><p>producer端设置request.required.acks&#x3D;0；只要请求已发送出去，就算是发送完了，不关心有没有写成功。性能很好，如果是对一些日志进行分析，可以承受丢数据的情况，用这个参数，性能会很好。<br>request.required.acks&#x3D;1；发送一条消息，当leader partition写入成功以后，才算写入成功。不过这种方式也有丢数据的可能。<br>request.required.acks&#x3D;-1；需要ISR列表里面，所有副本都写完以后，这条消息才算写入成功。<br>设计一个不丢数据的方案：数据不丢失的方案：1)分区副本 &gt;&#x3D;2 2)acks &#x3D; -1 3)min.insync.replicas &gt;&#x3D;2。<br>下面给出此时leader出现故障的情况，可以看出，此时数据可能重复。</p>
<p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\5ee45a5558bd4528a47a5a3b82749828.jpg" alt="5ee45a5558bd4528a47a5a3b82749828"></p>
<p>解释上面出现的几个名词。Leader维护了⼀个动态的 in-sync replica set（ISR）：和 Leader 保持同步的 Follower 集合。当 ISR 集合中的 Follower 完成数据的同步之后，Leader 就会给 Follower 发送 ACK。如果 Follower ⻓时间未向 Leader 同步数据，则该 Follower 将被踢出 ISR 集合，该时间阈值由replica.lag.time.max.ms 参数设定。Leader 发⽣故障后，就会从 ISR 中选举出新的 Leader。<br>kafka服务端中min.insync.replicas。 如果我们不设置的话，默认这个值是1。一个leader partition会维护一个ISR列表，这个值就是限制ISR列表里面 至少得有几个副本，比如这个值是2，那么当ISR列表里面只有一个副本的时候，往这个分区插入数据的时候会报错。</p>
<h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><p>Consumer 采⽤ Pull（拉取）模式从 Broker 中读取数据。Pull 模式则可以根据 Consumer 的消费能⼒以适当的速率消费消息。Pull 模式不⾜之处是，如果Kafka 没有数据，消费者可能会陷⼊循环中，⼀直返回空数据。因为消费者从 Broker 主动拉取数据，需要维护⼀个⻓轮询，针对这⼀点， Kafka 的消费者在消费数据时会传⼊⼀个时⻓参数 timeout。如果当前没有数据可供消费，Consumer 会等待⼀段时间之后再返回，这段时⻓即为 timeout。</p>
<h2 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h2><p>⼀个 Consumer Group 中有多个 Consumer，⼀个 Topic 有多个 Partition。不同组间的消费者是相互独立的，相同组内的消费者才会协作，这就必然会涉及到Partition 的分配问题，即确定哪个 Partition 由哪个 Consumer 来消费。<br>Kafka 有三种分配策略：</p>
<p>RoundRobin<br>Range，默认为Range<br>Sticky<br>当消费者组内消费者发⽣变化时，会触发分区分配策略（⽅法重新分配），在分配完成前，kafka会暂停对外服务。注意为了尽量确保消息的有序执行，一个分区只能对应一个消费者，这也说明消费者的数量不能超过分区的数量。</p>
<h4 id="range方式"><a href="#range方式" class="headerlink" title="range方式"></a>range方式</h4><p>Range ⽅式是按照主题来分的，不会产⽣轮询⽅式的消费混乱问题，但是也有不足。</p>
<p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\2e8e7674b862451b95355ef670e259db.jpg" alt="2e8e7674b862451b95355ef670e259db"></p>
<p>注意图文不符，图片是一个例子，文字再给一个例子，以便理解。假设我们有10个分区，3个消费者，排完序的分区将会是0,1,2,3,4,5,6,7,8,9；消费者线程排完序将会是C1-0,C2-0,C3-0。然后将partitions的个数除于消费者线程的总数来决定每个消费者线程消费⼏个分区。如果除不尽，那么前⾯⼏个消费者线程将会多消费⼀个分区。<br>在我们的例⼦⾥⾯，我们有10个分区，3个消费者线程， 10&#x2F;3 &#x3D; 3，⽽且除不尽，那么消费者线程 C1-0将会多消费⼀个分区：C1-0 将消费 0, 1, 2, 3 分区；C2-0将消费 4,5,6分区；C3-0将消费 7,8,9分区。<br>假如我们有11个分区，那么最后分区分配的结果看起来是这样的：<br>C1-0将消费 0,1,2,3分区；C2-0将消费 4,5,6,7分区；C3-0 将消费 8, 9, 10 分区。<br>假如我们有2个主题(T1和T2)，分别有10个分区，那么最后分区分配的结果看起来是这样的：<br>C1-0 将消费 T1主题的 0, 1, 2, 3 分区以及 T2主题的 0, 1, 2, 3分区<br>C2-0将消费 T1主题的 4,5,6分区以及 T2主题的 4,5,6分区<br>C3-0将消费 T1主题的 7,8,9分区以及 T2主题的 7,8,9分区</p>
<p>这就可以看出，C1-0 消费者线程⽐其他消费者线程多消费了2个分区，这就是Range strategy的⼀个很明显的弊端。如下图所示，Consumer0、Consumer1 同时订阅了主题 A 和 B，可能造成消息分配不对等问题，当消费者组内订阅的主题越多，分区分配可能越不均衡。</p>
<p>RoundRobin<br>RoundRobin 轮询⽅式将分区所有作为⼀个整体进⾏ Hash 排序，消费者组内分配分区个数最⼤差别为 1，是按照组来分的，可以解决多个消费者消费数据不均衡的问题。<br>轮询分区策略是把所有partition和所有consumer线程都列出来，然后按照hashcode进⾏排序。最后通过轮询算法分配partition给消费线程。如果所有consumer实例的订阅是相同的，那么partition会均匀分布。<br>在上面的例⼦⾥⾯，假如按照 hashCode排序完的topic-partitions组依次为T1-5,T1-3,T1-0,T1-8,T1-2,T1-1,T1-4,T1-7,T1-6,T1-9，我们的消费者线程排序为C1-0,C1-1,C2-0,C2-1，最后分区分配的结果为：<br>C1-0将消费 T1-5,T1-2,T1-6分区；<br>C1-1将消费 T1-3,T1-1,T1-9分区；<br>C2-0将消费 T1-0,T1-4分区；<br>C2-1将消费 T1-8,T1-7分区。</p>
<p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\0e3ff9f5402f43c8a7424a1c4bcdfddd.jpg" alt="0e3ff9f5402f43c8a7424a1c4bcdfddd"></p>
<p>图文不符。<br>但是，当消费者组内订阅不同主题时，可能造成消费混乱，如下图所示，Consumer0 订阅主题A，Consumer1 订阅主题 B。</p>
<p><img src="/2023/08/17/%E6%B6%88%E6%81%AF/kafka//personalBlog\source_posts\消息\kafka\3d63a1c330944ccbb834619c7ec32243.jpg" alt="3d63a1c330944ccbb834619c7ec32243"></p>
<p>将 A、B 主题的分区排序后分配给消费者组，TopicB 分区中的数据可能分配到 Consumer0 中。<br>因此，使⽤轮询分区策略必须满⾜两个条件：</p>
<p>每个主题的消费者实例具有相同数量的流；<br>每个消费者订阅的主题必须是相同的。<br>注意，其实对于生产者而言，可以自定义push但哪个分区中，也可以使用如hash等方法。</p>
<p>Sticky<br>前两种rebalance方式需要重新映射，代价较大，特别是由于rebalance期间会暂停服务，这就要求该过程尽量短。Sticky在没有rebalance时采用轮询方式，发生rebalance时，尽量保持原映射关系，只是改变与宕机相关的映射，依然采用轮询的方式。</p>
<p>可靠性保证<br>在前面ack保障消息到了broker之后，消费者也需要有⼀定的保证，因为消费者也可能出现某些问题导致消息没有消费到。<br>这里介绍一下偏移量。每个consumer内存里数据结构保存对每个topic的每个分区的消费offset，定期会提交offset，0.9版本以后，提交offset发送给kafka内部额外生成的一个topic：__consumer_offsets，提交过去的时候， key是group.id+topic+分区号，value就是当前offset的值，每隔一段时间，kafka内部会对这个topic进行compact(合并)，也就是每个group.id+topic+分区号就保留最新数据。<br>这里引入enable.auto.commit，默认为true，也就是⾃动提交offset，⾃动提交是批量执⾏的，有⼀个时间窗⼝，这种⽅式会带来重复提交或者消息丢失的问题，所以对于⾼可靠性要求的程序，要使⽤⼿动提交。对于⾼可靠要求的应⽤来说，宁愿重复消费也不应该因为消费异常⽽导致消息丢失。当然，我们也可以使用策略来避免消息的重复消费与丢失，比如使用事务，将offset与消息执行放在同一数据库中。</p>
<p>最后再简单介绍一个应用。kafka可以用在分布式延时队列中。创建一个额外的主题和一个定时进程，检测这个主题中是否有消息过期，过期后放在常规的消息队列中，消费者从这个常规的队列中获取消息来消费。</p>
	  

	  <div>
  		<center>
		  <div class="pagination">
<ul class="pagination">
	
	
	
	
	
	
		
			
			
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
	
	
		<li class="prev disabled"><a><i class="fa fa-arrow-circle-o-left"></i>prev</a></li>
	
	<li><a href="/"><i class="fa fa-archive"></i>Home</a></li>
	
		<li class="next disabled"><a>next<i class="fa fa-arrow-circle-o-right"></i></a></li>
	
</ul>
</div>

		</center>
	  </div>
	  
	</div> <!-- col-md-9/col-md-12 -->
	
  </div><!-- row -->

	</div>
  </div>
  <div class="container-narrow">
	<footer> <p>
  &copy; 2023 albert dong
  
      with help from <a href="http://zespia.tw/hexo/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Please inform us of any infringement by 517916466@qq.com
</p> </footer>
  </div> <!-- container-narrow -->
  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/jquery.tableofcontents.min.js"></script>
<script src="/js/tocgenerator.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>




</body>
</html>
